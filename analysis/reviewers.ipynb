{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T02:26:02.416909856Z",
     "start_time": "2025-07-22T02:26:02.414234597Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                               repo helpers                                  #\n",
    "# --------------------------------------------------------------------------- #\n",
    "from helper import (  # noqa: E402  pylint: disable=wrong-import-position\n",
    "    CLEAN_DIR,\n",
    "    CSV_DIR,\n",
    "    SCOPE_DIR,\n",
    "    FIG_DIR,\n",
    "    NAME_MAPPING,\n",
    "    PREFER_ORDER,\n",
    "    COLOR_MAP,\n",
    "    read_json,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                              global constants                               #\n",
    "# --------------------------------------------------------------------------- #\n",
    "SUMMARY_LABEL = \"All_Agents\"           # internal key\n",
    "SUMMARY_LABEL_DISPLAY = \"All Agents\"   # label shown in plots/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                               I/O helpers                                   #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def _load_json(filename: str):\n",
    "    \"\"\"Load *filename* from CLEAN_DIR with prototype fallback.\"\"\"\n",
    "    fp = CLEAN_DIR / filename\n",
    "    return read_json(fp)\n",
    "\n",
    "\n",
    "def _load_real_users() -> pd.DataFrame:\n",
    "    \"\"\"Return dataframe mapping PR ids to real users if available.\"\"\"\n",
    "    fp = CSV_DIR / \"real_users.csv\"\n",
    "    if not fp.exists():\n",
    "        return pd.DataFrame(columns=[\"agent\", \"pr_id\", \"user\"])\n",
    "    return pd.read_csv(fp, dtype={\"pr_id\": str})\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                              core analytics                                 #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def _categorize(login: str, user_type: str | None, pr_user: str | None) -> str:\n",
    "    norm = login.lower()\n",
    "    if pr_user and norm == pr_user.lower():\n",
    "        return \"PR Author\"\n",
    "    if user_type == \"Bot\" or norm.endswith(\"[bot]\"):\n",
    "        return \"Agent/Bot\"\n",
    "    if user_type == \"User\":\n",
    "        return \"Human Developer\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def analyze_agent_reviews(\n",
    "        agent: str,\n",
    "        real_users: pd.DataFrame | None = None,\n",
    "        reviews: dict[str, list] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Flatten review JSON into DataFrame.\"\"\"\n",
    "    if reviews is None:\n",
    "        reviews = _load_json(f\"{agent}_pr_reviews.json\")\n",
    "    if not reviews:\n",
    "        return pd.DataFrame(columns=[\"agent\", \"pr_id\", \"reviewer\", \"type\", \"category\"])\n",
    "\n",
    "    prs = _load_json(f\"{agent}_all_prs.json\")\n",
    "    pr_author = {str(pr.get(\"id\")): pr.get(\"user\", {}).get(\"login\") for pr in prs}\n",
    "    if real_users is not None and not real_users.empty:\n",
    "        subset = real_users[real_users[\"agent\"].str.lower() == agent.lower()]\n",
    "        for _, row in subset.iterrows():\n",
    "            pr_author[str(row[\"pr_id\"])] = row[\"user\"]\n",
    "\n",
    "    rows: list[dict[str, str]] = []\n",
    "    for pr_file, review_list in reviews.items():\n",
    "        pr_id = pr_file.replace(\".json\", \"\")\n",
    "        author = pr_author.get(pr_id)\n",
    "        for review in review_list:\n",
    "            login = review.get(\"user\", {}).get(\"login\")\n",
    "            if not login:\n",
    "                continue\n",
    "            utype = review.get(\"user\", {}).get(\"type\")\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"agent\": agent,\n",
    "                    \"pr_id\": pr_id,\n",
    "                    \"reviewer\": login,\n",
    "                    \"type\": utype,\n",
    "                    \"category\": _categorize(login, utype, author),\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_prs(\n",
    "        agent: str, reviews: dict[str, list], reviews_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return PR-level classification flags.\"\"\"\n",
    "    rows = []\n",
    "    for pr_file in reviews.keys():\n",
    "        pr_id = pr_file.replace(\".json\", \"\")\n",
    "        sub = reviews_df[reviews_df[\"pr_id\"] == pr_id]\n",
    "        has_h = np.logical_or(\n",
    "            sub[\"category\"] == \"Human Developer\", sub[\"category\"] == \"PR Author\"\n",
    "        ).any()\n",
    "        has_a = (sub[\"category\"] == \"Agent/Bot\").any()\n",
    "        if has_h and not has_a:\n",
    "            cls = \"only_human\"\n",
    "        elif has_a and not has_h:\n",
    "            cls = \"only_bot\"\n",
    "        elif has_h and has_a:\n",
    "            cls = \"both\"\n",
    "        else:\n",
    "            cls = \"none\"\n",
    "        rows.append(\n",
    "            {\n",
    "                \"agent\": agent,\n",
    "                \"pr_id\": pr_id,\n",
    "                \"has_human\": has_h,\n",
    "                \"has_agent\": has_a,\n",
    "                \"classification\": cls,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def build_popular_agent_bot_table(\n",
    "        agent_bot_counts: dict[str, pd.Series],\n",
    "        agent_total_bot_reviews: dict[str, int],\n",
    "        top_n: int = 10,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return MultiIndex column table of raw counts and %.\"\"\"\n",
    "    df_counts = pd.DataFrame(agent_bot_counts).fillna(0).astype(int)\n",
    "    df_perc = df_counts.div(pd.Series(agent_total_bot_reviews), axis=1) * 100\n",
    "\n",
    "    top_reviewers = df_counts.sum(axis=1).nlargest(top_n).index\n",
    "    df_counts, df_perc = df_counts.loc[top_reviewers], df_perc.loc[top_reviewers]\n",
    "\n",
    "    agents = df_counts.columns.tolist()\n",
    "    cols = [(a, \"Count\") for a in agents] + [(a, \"\\\\%\") for a in agents]\n",
    "    combo = pd.DataFrame(index=top_reviewers, columns=pd.MultiIndex.from_tuples(cols))\n",
    "    for a in agents:\n",
    "        combo[(a, \"Count\")] = df_counts[a]\n",
    "        combo[(a, \"\\\\%\")] = df_perc[a].round(1)\n",
    "    combo.index.name = \"Reviewer\"\n",
    "    return combo\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                               visualisation                                 #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def _best_text_color(bg_hex: str) -> str:\n",
    "    \"\"\"Return 'white' or 'black' depending on background luminance.\"\"\"\n",
    "    bg_hex = bg_hex.lstrip(\"#\")\n",
    "    r, g, b = tuple(int(bg_hex[i:i+2], 16) for i in (0, 2, 4))\n",
    "    luminance = (0.299 * r + 0.587 * g + 0.114 * b) / 255\n",
    "    return \"black\" if luminance > 0.5 else \"white\"\n",
    "\n",
    "\n",
    "def plot_classification_stacked(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Horizontal 100 % stacked bars with in-bar percentages and separator line.\"\"\"\n",
    "    special_agents = [a for a in [\"Human\", SUMMARY_LABEL] if a in df.index]\n",
    "    other_agents = df.index.difference(special_agents)\n",
    "    sorted_agents = (\n",
    "        df.loc[other_agents].sort_values(\"only_human\", ascending=False).index.tolist()\n",
    "    )\n",
    "    order = special_agents + sorted_agents\n",
    "    df = df.loc[order, [\"only_human\", \"only_bot\", \"both\", \"none\"]]\n",
    "\n",
    "    labels = {\n",
    "        \"only_human\": \"Only Human\",\n",
    "        \"only_bot\": \"Only Bot\",\n",
    "        \"both\": \"Human + Bot\",\n",
    "        \"none\": \"No Reviews\",\n",
    "    }\n",
    "    colors = {\n",
    "        \"only_human\": COLOR_MAP[\"Copilot\"],\n",
    "        \"only_bot\": COLOR_MAP[\"Claude_Code\"],\n",
    "        \"both\": COLOR_MAP.get(\"Devin\", \"#009E73\"),\n",
    "        \"none\": \"#999999\",\n",
    "    }\n",
    "\n",
    "    ylabels = [\n",
    "        NAME_MAPPING.get(a, SUMMARY_LABEL_DISPLAY if a == SUMMARY_LABEL else a).replace(\n",
    "            \"_\", \" \"\n",
    "        )\n",
    "        for a in df.index.to_list()\n",
    "    ]\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    left = pd.Series([0] * len(df), index=df.index)\n",
    "\n",
    "    # Draw bars\n",
    "    for col in [\"only_human\", \"both\", \"only_bot\", \"none\"]:\n",
    "        ax.barh(\n",
    "            ylabels,\n",
    "            df[col],\n",
    "            left=left,\n",
    "            color=colors[col],\n",
    "            label=labels[col],\n",
    "            height=0.6,\n",
    "        )\n",
    "        left += df[col]\n",
    "\n",
    "    # Annotate percentages in-bar\n",
    "    for row_idx, agent in enumerate(df.index):\n",
    "        cum_x = 0.0\n",
    "        for col in [\"only_human\", \"both\", \"only_bot\", \"none\"]:\n",
    "            width = df.loc[agent, col]\n",
    "            if width <= 0:\n",
    "                continue\n",
    "            x_center = cum_x + width / 2\n",
    "            width = round(width, 1)\n",
    "            pct_txt = f\"{width:.1f}\"\n",
    "            text_color = _best_text_color(colors[col])\n",
    "            ax.text(\n",
    "                x_center,\n",
    "                row_idx,\n",
    "                pct_txt,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                color=text_color,\n",
    "            )\n",
    "            cum_x += width\n",
    "\n",
    "    # Axes, legend, separator\n",
    "    ax.set_xlabel(\"Share of PRs (%)\")\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(title=\"Reviewer Type\", loc=\"upper right\", ncol=1, frameon=True)\n",
    "\n",
    "    sep_y = len(special_agents) - 0.5\n",
    "    ax.axhline(sep_y, color=\"black\", linewidth=1.2, linestyle=\"--\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_fp = FIG_DIR / \"reviewer_classification_stacked.pdf\"\n",
    "    fig.savefig(out_fp, dpi=300)\n",
    "    fig.savefig(out_fp.with_suffix(\".png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Wrote\", out_fp)\n",
    "\n",
    "def plot_bot_heatmap(popular_df: pd.DataFrame) -> None:\n",
    "    \"\"\"Percentage heat-map with manual row/column ordering for interpretability.\"\"\"\n",
    "    if popular_df.empty:\n",
    "        return\n",
    "\n",
    "    perc = popular_df.xs(\"\\\\%\", level=1, axis=1).astype(float)\n",
    "\n",
    "    # --- Step 1: MANUAL ordering ---\n",
    "    manual_column_order = [\n",
    "        \"Human\",\n",
    "        \"OpenAI_Codex\",\n",
    "        \"Claude_Code\",\n",
    "        \"Cursor\",\n",
    "        \"Devin\",\n",
    "        \"Copilot\",\n",
    "    ]\n",
    "    manual_row_order = [\n",
    "        \"copilot-swe-agent[bot]\",\n",
    "        \"cursor[bot]\",\n",
    "        \"gemini-code-assist[bot]\",\n",
    "        \"copilot-pull-request-reviewer[bot]\",\n",
    "        \"coderabbitai[bot]\",\n",
    "        \"ellipsis-dev[bot]\",\n",
    "        \"greptile-apps[bot]\",\n",
    "        \"entelligence-ai-pr-reviews[bot]\",\n",
    "        \"Copilot\",\n",
    "        \"github-advanced-security[bot]\",\n",
    "    ]\n",
    "\n",
    "    # --- Step 2: Apply order ---\n",
    "    # Filter for rows/columns that actually exist\n",
    "    manual_column_order = [c for c in manual_column_order if c in perc.columns]\n",
    "    manual_row_order = [r for r in manual_row_order if r in perc.index]\n",
    "\n",
    "    perc = perc.loc[manual_row_order, manual_column_order]\n",
    "\n",
    "    # Optional: pretty names\n",
    "    perc.columns = [NAME_MAPPING.get(c, c).replace(\"_\", \" \") for c in perc.columns]\n",
    "\n",
    "    # --- Step 3: Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        perc,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap=\"Blues\",\n",
    "        ax=ax,\n",
    "        cbar_kws={\"label\": \"Share of Bot Reviews (%)\"},\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "    )\n",
    "\n",
    "    ax.tick_params(axis=\"both\", length=0)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Reviewer Bot\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_fp = FIG_DIR / \"bot_heatmap.pdf\"\n",
    "    fig.savefig(out_fp, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.savefig(out_fp.with_suffix(\".png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Wrote\", out_fp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T02:26:13.210146544Z",
     "start_time": "2025-07-22T02:26:13.182934601Z"
    }
   },
   "id": "4cb2e3d53be964f7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                                    main                                     #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def main() -> None:\n",
    "    USE_SCOPE = True\n",
    "    CSV_DIR.mkdir(exist_ok=True)\n",
    "    real_users = _load_real_users()\n",
    "\n",
    "    # --------------- gather sources ---------------- #\n",
    "    sources: list[tuple[str, dict[str, list]]] = []\n",
    "    if USE_SCOPE:\n",
    "        for subdir in SCOPE_DIR.iterdir():\n",
    "            if not subdir.is_dir():\n",
    "                continue\n",
    "            agent = subdir.name\n",
    "            fp = subdir / \"pr_reviews.json\"\n",
    "            if fp.exists():\n",
    "                sources.append((agent, read_json(fp)))\n",
    "            else:\n",
    "                print(f\"[scope] no pr_reviews.json for {agent}, skipping\")\n",
    "\n",
    "    # --------------- processing -------------------- #\n",
    "    all_summaries = []\n",
    "    overall_counts = {\"only_human\": 0, \"only_bot\": 0, \"both\": 0, \"none\": 0}\n",
    "    overall_total = 0\n",
    "    agent_bot_counts: dict[str, pd.Series] = {}\n",
    "    agent_total_bot_reviews: dict[str, int] = {}\n",
    "\n",
    "    for agent, reviews in sources:\n",
    "        reviews_df = analyze_agent_reviews(agent, real_users, reviews)\n",
    "        if reviews_df.empty and all(len(lst) == 0 for lst in reviews.values()):\n",
    "            print(f\"[skip] no reviews data for {agent}\")\n",
    "            continue\n",
    "\n",
    "        pr_summary = summarize_prs(agent, reviews, reviews_df)\n",
    "        pr_summary.to_csv(CSV_DIR / f\"{agent}_pr_summary.csv\", index=False)\n",
    "\n",
    "        bot_only = reviews_df[reviews_df[\"category\"] == \"Agent/Bot\"]\n",
    "        counts = bot_only[\"reviewer\"].value_counts()\n",
    "        agent_bot_counts[agent] = counts\n",
    "        agent_total_bot_reviews[agent] = len(bot_only)\n",
    "\n",
    "        total = len(pr_summary)\n",
    "        vc = pr_summary[\"classification\"].value_counts().to_dict()\n",
    "        all_summaries.append(\n",
    "            {\n",
    "                \"agent\": agent,\n",
    "                \"only_human\": vc.get(\"only_human\", 0) / total * 100,\n",
    "                \"only_bot\": vc.get(\"only_bot\", 0) / total * 100,\n",
    "                \"both\": vc.get(\"both\", 0) / total * 100,\n",
    "                \"none\": vc.get(\"none\", 0) / total * 100,\n",
    "            }\n",
    "        )\n",
    "        if agent != \"Human\":\n",
    "            for key in overall_counts:\n",
    "                overall_counts[key] += vc.get(key, 0)\n",
    "            overall_total += total\n",
    "\n",
    "    if overall_total > 0:\n",
    "        all_summaries.append(\n",
    "            {\n",
    "                \"agent\": SUMMARY_LABEL,\n",
    "                \"only_human\": overall_counts[\"only_human\"] / overall_total * 100,\n",
    "                \"only_bot\": overall_counts[\"only_bot\"] / overall_total * 100,\n",
    "                \"both\": overall_counts[\"both\"] / overall_total * 100,\n",
    "                \"none\": overall_counts[\"none\"] / overall_total * 100,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not all_summaries:\n",
    "        print(\"No review data found.\")\n",
    "        return\n",
    "\n",
    "    summary_df = pd.DataFrame(all_summaries).set_index(\"agent\")\n",
    "\n",
    "    print(\n",
    "        summary_df.to_latex(\n",
    "            float_format=\"%.1f\",\n",
    "            caption=(\n",
    "                \"Percentage breakdown of reviewer types for each coding agent.\"\n",
    "            ),\n",
    "            escape=False,\n",
    "            na_rep=\"--\",\n",
    "            multicolumn=True,\n",
    "            multicolumn_format=\"c\",\n",
    "            index_names=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    summary_df.to_csv(CSV_DIR / \"agent_pr_reviewer_classification_percentages.csv\")\n",
    "\n",
    "    popular_df = build_popular_agent_bot_table(agent_bot_counts, agent_total_bot_reviews)\n",
    "\n",
    "    plot_classification_stacked(summary_df)\n",
    "    plot_bot_heatmap(popular_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T02:26:20.555291614Z",
     "start_time": "2025-07-22T02:26:20.540858226Z"
    }
   },
   "id": "3b176e672bc9aa81"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scope] no pr_reviews.json for Cursor, skipping\n",
      "[scope] no pr_reviews.json for Claude_Code, skipping\n",
      "[scope] no pr_reviews.json for Human, skipping\n",
      "[scope] no pr_reviews.json for OpenAI_Codex, skipping\n",
      "[scope] no pr_reviews.json for Copilot, skipping\n",
      "[scope] no pr_reviews.json for Devin, skipping\n",
      "No review data found.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T02:26:27.060588401Z",
     "start_time": "2025-07-22T02:26:27.040401395Z"
    }
   },
   "id": "9f4958f89f561125"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "73e4848533bd5887"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
