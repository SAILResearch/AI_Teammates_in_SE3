id,number,title,user,user_id,state,created_at,closed_at,repo_url,html_url,body
105309122,123,Add RadialGradientBrush,amerkoleci,1788857,closed,2015-09-08T06:12:38Z,2015-09-22T11:50:33Z,https://github.com/AvaloniaUI/Avalonia,https://github.com/AvaloniaUI/Avalonia/issues/123,"Just to keep trace of missing features from WPF.
"
137373175,456,Moves Perspex Designer to PerspexVS,ghost,10137,closed,2016-02-29T21:00:39Z,2016-03-01T19:10:17Z,https://github.com/AvaloniaUI/Avalonia,https://github.com/AvaloniaUI/Avalonia/pull/456,
3011663980,324,Revision Isn't Passed For Model Download,jbis9051,32957090,closed,2025-04-22T17:15:13Z,2025-05-17T01:51:11Z,https://github.com/Blaizzy/mlx-vlm,https://github.com/Blaizzy/mlx-vlm/issues/324,"```py
from mlx_vlm import load, generate

model, processor = load(model_path, revision=""foo"")
```
this doesn't work because the revision arg isn't passed to this function

https://github.com/Blaizzy/mlx-vlm/blob/main/mlx_vlm/utils.py#L309-311
```py
def load(
    path_or_hf_repo: str,
    adapter_path: Optional[str] = None,
    lazy: bool = False,
    **kwargs,
) -> Tuple[nn.Module, Union[PreTrainedTokenizer, PreTrainedTokenizerFast]]:
....
    model_path = get_model_path(path_or_hf_repo)
```

```py
def get_model_path(path_or_hf_repo: str, revision: Optional[str] = None) -> Path:
````
"
3107115832,1705,Telemetry data send even if unticked and also all peripherals (same bug in v3 and v4),Eisbahn,336105,closed,2025-06-01T11:38:33Z,2025-06-10T11:22:15Z,https://github.com/ESPresense/ESPresense,https://github.com/ESPresense/ESPresense/issues/1705,"### Describe the bug

Hello,

even if I untick the ""Send to telemetry topic"", I always do get MQTT message for it, e.g.
`espresense/rooms/buero/telemetry:`
How do I disable the telmetry data?
Additional on every bootup I do get all the peripherals (e.g. LED, switch...) reported. Could you please stop this, e.g. first boot the ESP, check the config and if not used, disable the corresponding TX for it.
Same issue applies to the stable v3 release, as also for latest v4

### Version

v4.0.0b7

### Active scan enabled

no

### Include filter

known:

### Exclude filter

none

### Query filter

none

### Firmware flavor

n/a

### Device (be specific)

BLE beacons

### Logs

```text

```

### Screenshots

_No response_"
3086734670,1361,Error when running Mistral-Small.3.1 Q4K UQFF: cannot find tensor vision_tower.patch_conv.weight,drhaynes,117291,closed,2025-05-23T15:19:11Z,2025-05-27T00:47:21Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/issues/1361,"## Describe the bug

I created a Q4K version of Mistral-Small-3.1-24B-Instruct-2503. The isq processing succeeded and the model was usable from the initial load:

`./mistralrs-server --isq Q4K -i vision-plain -m mistralai/Mistral-Small-3.1-24B-Instruct-2503 --write-uqff ""../../../uqff-models/Mistral-Small-3.1-24B-Instruct-2503-q4k.uqff""`

However, after uploading it to HF and trying to load the UQFF directly from there (to avoid isq startup time):

`./mistralrs-server -i vision-plain -m handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF -a mistral3 -f Mistral-Small-3.1-24B-Instruct-2503-q4k-0.uqff`

The model fails to load with the following error:

`Error: cannot find tensor vision_tower.patch_conv.weight`

Is this something I am doing wrong in the initial quantisation step, or when loading the model, or is there some underlying issue preventing the Mistral-Small-3.1-24B-Instruct-2503 uqff from loading?

Full run log is below:
```
2025-05-23T15:17:55.054876Z  INFO mistralrs_server: avx: true, neon: false, simd128: false, f16c: true
2025-05-23T15:17:55.054893Z  INFO mistralrs_server: Sampling method: penalties -> temperature -> topk -> topp -> minp -> multinomial
2025-05-23T15:17:55.054900Z  INFO mistralrs_server: Model kind is: normal (no adapters)
2025-05-23T15:17:55.054915Z  INFO hf_hub: Using token file found ""/home/drh/.cache/huggingface/token""
2025-05-23T15:17:55.054962Z  INFO mistralrs_core::pipeline::vision: Loading `tokenizer.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:55.054977Z  INFO mistralrs_core::pipeline::vision: Loading `config.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:55.229814Z  INFO mistralrs_core::pipeline::paths: Found model weight filenames [""residual.safetensors""]
2025-05-23T15:17:55.463174Z  INFO mistralrs_core::pipeline::vision: Loading `generation_config.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:55.682742Z  INFO mistralrs_core::pipeline::vision: Loading `preprocessor_config.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:55.865585Z  INFO mistralrs_core::pipeline::vision: Loading `processor_config.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:55.865729Z  INFO mistralrs_core::pipeline::vision: Loading `tokenizer_config.json` at `handmadedigital/Mistral-Small-3.1-24B-Instruct-2503-q4k-UQFF`
2025-05-23T15:17:56.071711Z  INFO hf_hub: Using token file found ""/home/drh/.cache/huggingface/token""
2025-05-23T15:17:56.090885Z  INFO mistralrs_core::utils::normal: Detected minimum CUDA compute capability 8.6
2025-05-23T15:17:56.156727Z  INFO mistralrs_core::utils::normal: DType selected is BF16.
2025-05-23T15:17:56.258716Z  INFO mistralrs_core::pipeline::loaders: Using automatic device mapping parameters: vision[max_seq_len: 4096, max_batch_size: 1, max_image_shape: (1024, 1024), max_num_images: 1].
2025-05-23T15:17:56.258742Z  INFO mistralrs_core::pipeline::loaders: The following sub-models will not be device mapped and will be loaded on cuda[0]: vision
2025-05-23T15:17:56.258788Z  INFO mistralrs_quant::utils::log: Model has 40 repeating layers.
2025-05-23T15:17:56.258798Z  INFO mistralrs_quant::utils::log: Loading model according to the following repeating layer mappings:
2025-05-23T15:17:56.258872Z  INFO mistralrs_quant::utils::log: Layers 0-39: cuda[0] (24 GB)
2025-05-23T15:17:56.276354Z  INFO mistralrs_core::utils::normal: Detected minimum CUDA compute capability 8.6
2025-05-23T15:17:56.276885Z  INFO mistralrs_core::utils::normal: DType selected is BF16.
2025-05-23T15:17:56.276910Z  INFO mistralrs_core::pipeline::vision: Model config: Mistral3Config { image_token_index: 10, multimodal_projector_bias: false, projector_hidden_act: Gelu, spatial_merge_size: 2, vision_feature_layer: -1, text_config: Config { vocab_size: 131072, hidden_size: 5120, intermediate_size: 32768, num_hidden_layers: 40, num_attention_heads: 32, num_key_value_heads: 8, hidden_act: Silu, max_position_embeddings: 131072, rms_norm_eps: 1e-5, rope_theta: 1000000000.0, sliding_window: None, head_dim: Some(128), quantization_config: None, tie_word_embeddings: false }, vision_config: Mistral3VisionConfig { hidden_size: 1024, num_channels: 3, image_size: 1540, patch_size: 14, rope_theta: 10000.0, intermediate_size: 4096, num_hidden_layers: 24, head_dim: Some(64), num_attention_heads: 16, hidden_act: Silu } }
2025-05-23T15:17:56.276947Z  INFO mistralrs_quant::utils::log: FlashAttention is enabled.
100%|██████████████████████████████████████████████████| 86/86 [00:00<00:00, 16020.35it/s]
Error: cannot find tensor vision_tower.patch_conv.weight
```

## Latest commit or version

44e4535b98b9d84200504827ddde3b058633c9ef
"
3111204449,1406,NV Cosmos Failing Device Local Storage,sempervictus,1331084,closed,2025-06-02T18:30:36Z,2025-06-04T18:27:10Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/issues/1406,"## Describe the bug
```rust
2025-06-02T14:19:33.578681Z  INFO mistralrs_core::pipeline::isq: Applying in-situ quantization into Some(Q4K) to 197 tensors.
2025-06-02T14:19:33.578750Z  INFO mistralrs_core::pipeline::isq: Applying ISQ on 32 threads.
2025-06-02T14:20:12.114640Z  INFO mistralrs_core::pipeline::isq: Applied in-situ quantization into Some(Q4K) to 197 tensors out of 197 total tensors. Took 38.54s
2025-06-02T14:20:12.965404Z  INFO mistralrs_core::pipeline::chat_template: bos_toks = ""<|endoftext|>"", eos_toks = ""<|im_end|>"", ""<|endoftext|>"", unk_tok = `None`
2025-06-02T14:20:12.989425Z  INFO mistralrs_server: Model loaded.
2025-06-02T14:20:12.989683Z  INFO mistralrs_core: Beginning dummy run.
2025-06-02T14:20:22.986525Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
2025-06-02T14:20:22.989329Z  INFO mistralrs_core: Dummy run completed in 9.999634349s.
2025-06-02T14:20:22.989868Z  INFO mistralrs_server: Serving on http://0.0.0.0:7655.
2025-06-02T14:29:34.006448Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
2025-06-02T14:32:54.330313Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
2025-06-02T14:33:13.112724Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
2025-06-02T14:34:56.959488Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
2025-06-02T15:32:05.103369Z ERROR mistralrs_core::engine: prompt step - Model failed with error: WithBacktrace { inner: DeviceMismatchBinaryOp { lhs: Cuda { gpu_id: 1 }, rhs: Cuda { gpu_id: 0 }, op: ""matmul_with_alpha"" }, backtrace: Backtrace [{ fn: ""candle_core::error::Error::bt"" }, { fn: ""candle_core::storage::Storage::same_device"" }, { fn: ""candle_core::tensor::Tensor::matmul"" }, { fn: ""mistralrs_core::vision_models::qwen2_5_vl::text::Qwen2_5VLTextModel::forward_embeds"" }, { fn: ""<mistralrs_core::vision_models::qwen2_5_vl::Qwen2_5VLModel as mistralrs_core::pipeline::loaders::vision_loaders::VisionModel>::forward"" }, { fn: ""<mistralrs_core::pipeline::vision::VisionPipeline as mistralrs_core::pipeline::Pipeline>::forward_inputs"" }, { fn: ""mistralrs_core::pipeline::Pipeline::step::{{closure}}"" }, { fn: ""mistralrs_core::engine::Engine::run::{{closure}}"" }, { fn: ""mistralrs_core::MistralRs::new::{{closure}}::{{closure}}"" }, { fn: ""std::sys::backtrace::__rust_begin_short_backtrace"" }, { fn: ""core::ops::function::FnOnce::call_once{{vtable.shim}}"" }, { fn: ""std::sys::pal::unix::thread::Thread::new::thread_start"" }, { fn: ""clone"" }] }
```

It seems the qwen2.5 and qwen3 logic have some sort of memory mapping problem with the V100s - presumption of BF16 being in play maybe? Looks to be in-GPU in all these cases outside the memory-safety facilities of Rust
"
3117621789,1427,Add tool callback support,EricLBuehler,65165915,closed,2025-06-04T12:13:49Z,2025-06-06T09:28:27Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/pull/1427,"## Summary
- implement generic tool callback in `mistralrs-core`
- wire new callback through model builders
- update search request handling for custom tools
- expose callback from python bindings
- update local search examples to use the new callback

## Testing
- `cargo fmt --all`
- `cargo clippy --all-targets --all-features -- -D warnings` *(fails: objc_exception build error)*

------
https://chatgpt.com/codex/tasks/task_e_68403233564483228bfd8bdcccfdd176

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Added support for registering and invoking multiple custom tool callbacks, enabling integration of user-defined tools alongside existing search capabilities.
  - Python and Rust APIs now allow mapping tool names to specific callback functions for dynamic tool invocation during chat completions.
  - Example scripts provided for both Python and Rust demonstrating how to implement and use custom tool callbacks within chat workflows.

- **Documentation**
  - Added example scripts showcasing custom tool integration in both Python and Rust.
  - Extended documentation with detailed guidance on customizing tool and search callbacks, including usage examples and configuration instructions.

- **Refactor**
  - Internal builder patterns and model configuration updated to support multiple named tool callbacks.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3118287824,1428,"Fix CUDA context switching, bind thread on CudaStorage drop",EricLBuehler,65165915,closed,2025-06-04T15:42:32Z,2025-06-04T18:27:09Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/pull/1428,"Related: https://github.com/EricLBuehler/candle/pull/82

Fixes #1406, #1401, #1399, #1394

## Summary
- add `set_cuda_context` helper to utils
- call helper in `Llama::forward_embeds` when switching devices
- document why context switching is needed

## Testing
- `cargo fmt` *(fails: rustfmt component not installed)*
- `cargo test --workspace --no-run` *(failed: build interrupted due to environment limits)*

------
https://chatgpt.com/codex/tasks/task_e_684063442160832289cdfb7840b2aac5

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

## Summary by CodeRabbit

- **Chores**
  - Updated internal dependencies to newer revisions for improved stability and compatibility.

- **Bug Fixes**
  - Improved device mapping logic for CUDA devices, enhancing reliability in device selection.
  - Adjusted prefix cache logic to better handle cases when the prefix cache size is set to zero, ensuring correct caching behavior.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3124315585,1441,Update deps,EricLBuehler,65165915,closed,2025-06-06T10:09:56Z,2025-06-06T10:12:58Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/pull/1441,"Handle breaking changes

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->

## Summary by CodeRabbit

- **Refactor**
  - Standardized and modernized OpenAPI schema generation and type declarations for improved compatibility and maintainability.
  - Updated WebSocket message construction for improved code consistency.
  - Simplified dependency management by switching to workspace-managed dependencies for select crates.
- **Chores**
  - Updated multiple dependency versions and minor feature flags across the project for enhanced stability and compatibility.

<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3135644413,1459,chore: `Dockerfile.cuda-all` - Merge `RUN` for `apt-get install`,polarathene,5098581,closed,2025-06-11T06:28:13Z,2025-06-11T19:06:46Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/pull/1459,"A [recent ""fix""](https://github.com/EricLBuehler/mistral.rs/commit/a5c4eda28da6946a5c01782572d25a04e0dbc56a) for a CI failure was to add Python deps into the `builder` stage. This was a direct commit with minimal context.

No point in the separate `RUN` instruction, I've merged it into the previous one and for added clarity leveraged the [HereDoc syntax feature](https://docs.docker.com/reference/dockerfile/#here-documents).

I don't think this is a proper way to fix the CI issue however. That was introduced by [this June 2025 PR](https://github.com/EricLBuehler/mistral.rs/pull/1438) because the crate `mistralrs-pyo3` had it's [build dependency migrated to a workspace](https://github.com/EricLBuehler/mistral.rs/commit/3d1b29b55682fad6cd5150bfae97dfdb07bb4e4a#diff-9170355ecc927233d7e8c4d51230769ad3f37d489f9022a1fd2cdeb03e0d11e0L39) which presumably [lost the feature guard](https://github.com/EricLBuehler/mistral.rs/commit/3d1b29b55682fad6cd5150bfae97dfdb07bb4e4a#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R149).

In April 2024 this concern was tackled, and appears it was [a bit more thorough for runtime support](https://github.com/EricLBuehler/mistral.rs/pull/249). It was then [tackled in May 2024](https://github.com/EricLBuehler/mistral.rs/pull/303) (_and [this June 2024 follow-up PR](https://github.com/EricLBuehler/mistral.rs/pull/440)_).

---

I'm not too familiar with the workspace feature, but the `--exclude mistralrs-pyo3` provided to `cargo build` in the image clearly isn't able to opt-out of that now I guess as the crate dep is now implicitly added/built due to being in the workspace without opt-in? (_even though `mistralrs-pyo3` is the only consumer of it I assume_)

That said the [CPU `Dockerfile`](https://github.com/EricLBuehler/mistral.rs/blob/a5c4eda28da6946a5c01782572d25a04e0dbc56a/Dockerfile) has no such workaround involved. So something specific to the CUDA one is bringing it in?

## Reference

[This is the failing workflow run](https://github.com/EricLBuehler/mistral.rs/actions/runs/15572393589/job/43850807208#step:8:1844) and the relevant build error which motivated [bringing Python back into the CUDA image](https://github.com/EricLBuehler/mistral.rs/commit/a5c4eda28da6946a5c01782572d25a04e0dbc56a) as a build workaround:

> ![image](https://github.com/user-attachments/assets/c5f5ab0a-53f5-4eba-9e4f-6a73afb6234b)


<!-- This is an auto-generated comment: release notes by coderabbit.ai -->

## Summary by CodeRabbit

- **Chores**
  - Improved Dockerfile build process for better efficiency and maintainability.

<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3161034298,1490,"MiniMaxAI/SynLogic-Mix-3-32B fails with Error(""missing field `bos_token_id`"", line: 6, column: 1)",sempervictus,1331084,closed,2025-06-19T18:03:44Z,2025-06-19T19:54:35Z,https://github.com/EricLBuehler/mistral.rs,https://github.com/EricLBuehler/mistral.rs/issues/1490,"## Describe the bug
```rust
thread 'main' panicked at mistralrs-core/src/pipeline/normal.rs:655:18:
bos_token_id/eos_token_id missing in generation_config.json: Error(""missing field `bos_token_id`"", line: 6, column: 1)
stack backtrace:
   0:     0x5607d6655162 - <std::sys::backtrace::BacktraceLock::print::DisplayBacktrace as core::fmt::Display>::fmt::h2bc1773b63b16421
   1:     0x5607d4ab9463 - core::fmt::write::h8002143aa1074e9d
   2:     0x5607d665435f - std::io::Write::write_fmt::h296d543625a1305a
   3:     0x5607d6654fc3 - std::sys::backtrace::BacktraceLock::print::hcefa4354720f2ea3
   4:     0x5607d66548ff - std::panicking::default_hook::h6f32fe1a34bb6d71
   5:     0x5607d6654027 - std::panicking::rust_panic_with_hook::h369ba414ea661602
   6:     0x5607d66963f8 - std::panicking::begin_panic_handler::{{closure}}::hd5f53fdb59d78538
   7:     0x5607d6696359 - std::sys::backtrace::__rust_end_short_backtrace::hcb15c093250d58b0
   8:     0x5607d6698d8c - __rustc[b21d626d23f8908d]::rust_begin_unwind
   9:     0x5607d4ab758f - core::panicking::panic_fmt::hfb443448b48f4123
  10:     0x5607d4abec95 - core::result::unwrap_failed::hcaaeb9cdb3026765
  11:     0x5607d54e1973 - <mistralrs_core::pipeline::normal::NormalLoader as mistralrs_core::pipeline::loaders::Loader>::load_model_from_path::{{closure}}::h8732243543a58c21
  12:     0x5607d54c467c - <mistralrs_core::pipeline::normal::NormalLoader as mistralrs_core::pipeline::loaders::Loader>::load_model_from_path::h4a5f6d6d1822983e
  13:     0x5607d54bcec5 - <mistralrs_core::pipeline::normal::NormalLoader as mistralrs_core::pipeline::loaders::Loader>::load_model_from_hf::hcf81e017e7fd78ca
  14:     0x5607d5fc89f0 - mistralrs_server::main::{{closure}}::hbb7954d738bb5ded.61526
  15:     0x5607d6153a7e - mistralrs_server::main::h072cd939aa136afc
  16:     0x5607d60bab33 - std::sys::backtrace::__rust_begin_short_backtrace::h3380f49c61273750
  17:     0x5607d61532e5 - main
  18:     0x7f3e48689d90 - <unknown>
  19:     0x7f3e48689e40 - __libc_start_main
  20:     0x5607d44b0725 - _start
```
Qwen2 base model so ... should work? Tried with `-c /chat_templates/default.json` but may need something else. CI's spinning up their `MiniMaxAI/MiniMax-M1-80k` presently to test
## Latest commit or version
Which commit or version you ran with.

"
569303981,1714,Syndicate blog posts to message center (sort of),roryaronson,5524043,open,2020-02-22T08:44:11Z,,https://github.com/FarmBot/Farmbot-Web-App,https://github.com/FarmBot/Farmbot-Web-App/issues/1714,"Proposal: add a new section to the message center page for ""News"", underneath the Messages section.

The News section should pull in the latest 6 blog posts from the company blog (blog.farm.bot) using either the Shopify API, the blog RSS feed, or whatever makes else makes sense. The posts should be displayed as cards, probably two or three to a column, with the post date, post title, snippet, image, and a read-more link, pretty much just like how they're presented at blog.farm.bot

![Screenshot_20200222-004035](https://user-images.githubusercontent.com/5524043/75089303-3e374700-550c-11ea-9133-1d6caf69dae1.png)
"
19274510,4246,eigs(speye(21)) does not work,ViralBShah,744411,closed,2013-09-10T17:53:06Z,2013-10-06T07:08:37Z,https://github.com/JuliaLang/julia,https://github.com/JuliaLang/julia/issues/4246,"`eigs` does not work on identity matrices of size 21 and higher for the default 6 eigenvalues.

```
julia> eigs(speye(21), nev=6)
ERROR: ARPACKException(3)
 in aupd_wrapper at linalg/arpack.jl:47
 in eigs at linalg/arnoldi.jl:35

julia> eigs(speye(21), nev=9)
ERROR: ARPACKException(3)
 in aupd_wrapper at linalg/arpack.jl:47
 in eigs at linalg/arnoldi.jl:35

julia> eigs(speye(21), nev=10)
([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],
21x10 Array{Float64,2}:
  0.252111    -0.246736     0.0192645    0.234598    …   0.130942     0.100895   -0.0290075 
  0.118993     0.190852    -0.393942    -0.232889       -0.002121     0.0280335  -0.213672  
 -0.00306955  -0.157261    -0.0341907   -0.182208       -0.110704    -0.158746   -0.419363  
  0.0751385    0.167007     0.0305194    0.0977773      -0.00449555  -0.318633   -0.0253858 
 -0.0943686   -0.0731143    0.148546     0.330696        0.0214212   -0.213419   -0.0260602 
  0.140182     0.00836135   0.00474463  -0.387105    …  -0.0425574   -0.111232   -0.135756  
 -0.256888    -0.354937    -0.482451     0.0503225       0.626875    -0.119688   -0.0743748 
  0.115359     0.203424    -0.0082043    0.00844204      0.0697025   -0.31223    -0.384733  
 -0.0716209   -0.346583     0.529378    -0.307466        0.325135     0.238119   -0.100524  
  0.132531    -0.230142    -0.0277612   -0.0306749      -0.174249     0.271229    0.244908  
  0.149707     0.438754     0.286695     0.125643    …   0.42474     -0.149599   -0.0382037 
 -0.0220212    0.102343     0.155978    -0.232871       -0.186025     0.0696285  -0.211983  
 -0.163692    -0.167343    -0.0155797    0.171629       -0.261443     0.203264   -0.480922  
 -0.0956       0.0534561   -0.296926    -0.143689       -0.116822     0.0899562   0.00621333
  0.63577     -0.422864     0.0268107   -0.0998203      -0.0911458   -0.403187    0.106614  
  0.41942      0.15776     -0.034414     0.363393    …   0.0734304    0.475078   -0.205165  
  0.11205     -0.0650867   -0.113777     0.0755098      -0.0801624   -0.0160499  -0.143335  
 -0.0523192    0.0961701    0.0374504   -0.0913321       0.0863463    0.0442572   0.211717  
 -0.242706    -0.0330528    0.0144394    0.226972       -0.31918     -0.267941    0.241889  
  0.0206762   -0.18865     -0.0265206    0.393166       -0.061266    -0.0446505  -0.141417  
 -0.269261    -0.128465     0.307113     0.0916609   …  -0.0646332   -0.146322   -0.243291  )
```
"
3053149457,58369,Backports for 1.12.0-beta4,KristofferC,1282691,closed,2025-05-09T20:46:26Z,2025-06-04T11:48:45Z,https://github.com/JuliaLang/julia,https://github.com/JuliaLang/julia/pull/58369,"Backported PRs:
- [x] #58322 <!-- Fix removal of globals with addrspaces in removeAddrspaces -->
- [x] #58291 <!-- replace incorrect Method.deleted_world with more useful Method.dispatch_status enum -->
- [x] #58335 <!-- extend Method.dispatch_status optimization to ml_matches_visitor also -->
- [x] #58108 <!-- Base.get_extension & Dates.format made public -->
- [x] #55864 <!-- Fix late gc lowering pass for vector intrinsics -->
- [x] #58356 <!-- codegen: remove readonly from abstract type calling convention -->
- [x] #57961 <!-- Add set to temporary roots to avoid O(N) check -->
- [x] #58070 <!-- fix called-argument analysis for calls with splat -->
- [x] #58390 <!-- Fix signedness typo in world range update -->
- [x] #58407 <!-- Add `Compiler._verify_trim_world_age` for better printing -->
- [x] #58410 <!-- fix `hasmethod` with kwargs to exclude positional arg names -->
- [x] #58414 <!-- [REPL] fix type confusion resulting in nonsensical errors -->
- [x] #58415 <!-- [REPL] more reliable extension loading -->
- [x] #58411 <!-- reflection: Label ""dynamic invoke"" in `code_typed` -->
- [x] #58436 <!-- Add some precompiles to help loading time -->
- [x] #58435 <!-- Fix layout flags for types that have oddly sized primitive type fields -->
- [x] #58452 <!-- avoid deadlock if crashing inside profile_wr_lock -->
- [x] #58473 <!-- Add some loading precompiles -->
- [x] #58474 <!-- Fail when precompiles fail during build on CI (and fix bad precompile) -->
- [x] #58483 <!-- Fix tbaa usage when storing into heap allocated immutable structs -->
- [x] #58496 <!-- MozillaCACerts: Update to 2025-05-20 -->
- [x] #58412 <!-- don't strip keyword argument names with --strip-metadata -->
- [x] #58510 <!-- Don't filter `Core` methods from newly-inferred list -->
- [x] #58488 <!-- avoid error just computing coverage of genenrated functions -->
- [x] #58542 <!-- docs: Add missing compat annotation for `isdefinedglobal` -->
- [x] #58585 
- [x]     #58578 <!-- - https://github.com/JuliaLang/julia/pull/58578 -->
- [x]     #58584 <!-- - https://github.com/JuliaLang/julia/pull/58584 -->
- [x]     #58572 <!-- - https://github.com/JuliaLang/julia/pull/58572 -->
- [x]     #58577 <!-- - https://github.com/JuliaLang/julia/pull/58577 -->
- [x]     #58110 <!-- - https://github.com/JuliaLang/julia/pull/58110 -->
 - [x]    #58603 <!-- - https://github.com/JuliaLang/julia/pull/58603 -->
- [x] #58014 <!-- trimming: Support finalizers -->

Need manual backport:
- [ ] #57410 <!-- codegen: cleanup gcstack call frames somewhat earlier -->
- [ ] #58205 <!-- reduce places where Builtins are listed -->
- [x] #58399 <!-- Use a nonzero initial size with llvm::SmallSet. -->
- [ ] #57588 <!-- use `@main` for juliac executable entry point -->
- [ ] #58131 <!-- make just one MethodTable -->
- [ ] #58565 <!-- MethodTable/Cache PR updates -->
- [ ] #58540 <!-- fix breakage with `jl_get_global` -->

Contains multiple commits, manual intervention needed:
- [ ] #57763 <!-- add the ability to specify the external name of a ccallable -->
- [ ] #58343 <!-- Defer global caching of `CodeInstance` to post-optimization step -->
- [ ] #57143 <!-- Add JuliaLang/JuliaSyntax.jl#525 to NEWS.md, flisp parser, and REPL -->
- [ ] #58226 <!-- Add binding invalidations to log -->

Non-merged PRs with backport label:
- [ ] #58586 <!-- restore fallback 3-arg `setprecision` method -->
- [ ] #58582 <!-- fix `@invokelatest` performance regression -->
- [ ] #58579 <!-- Work around LLVM JITLink stack overflow issue. -->
- [ ] #58535 <!-- gf.c: include const-return methods in `--trace-compile` -->
- [ ] #58359 <!-- Use dwarf for symbol lookup if dladdr fails before doing linear search. -->
- [ ] #58301 <!-- Detect Apple M4 and some related changes -->
- [ ] #58038 <!-- strings/cstring: `transcode`: prevent Windows sysimage invalidation -->
- [ ] #57886 <!-- only show backdated binding warning when deprecation warnings are enabled -->
- [ ] #57604 <!-- `@nospecialize` for `string_index_err` -->
- [ ] #57490 <!-- export `maxthreadid` from `Threads` -->
- [ ] #57481 <!-- juliac: Add rudimentary Windows support -->
- [ ] #57454 <!-- If the user explicitly asked for 1 thread don't add an interactive one. -->
- [ ] #57422 <!-- Fix performance regression in hvcat of simple matrices -->
- [ ] #57366 <!-- Use ptrdiff_t sized offsets for gvars_offsets to allow large sysimages -->"
3091800066,58528,`isdefinedglobal` doc string needs a compat annotation for v1.12,nsajko,4944410,closed,2025-05-26T18:07:22Z,2025-05-28T04:46:04Z,https://github.com/JuliaLang/julia,https://github.com/JuliaLang/julia/issues/58528,"It doesn't seem to be available on v1.11, v1.10 or v1.9."
3130617808,352,Add structured output mode dropdown,scosman,848343,closed,2025-06-09T15:16:19Z,2025-06-10T02:52:45Z,https://github.com/Kiln-AI/Kiln,https://github.com/Kiln-AI/Kiln/pull/352,"## Summary
- return structured_output_mode for models in available model API
- expose StructuredOutputMode in web types
- add dropdown for structured output mode in run options
- auto-select model's default mode when model changes via available models API
- send structured_output_mode when running tasks or creating run configs
- fix tests to expect new field and handle structured_output_mode defaults
- merge main and resolve conflicts

## Testing
- `uvx ruff check --select I`
- `uvx ruff format --check .`
- `uv run pyright .`
- `uv run python3 -m pytest --benchmark-quiet -q .`
- `npm run format_check`
- `npm run lint`
- `npm run check`
- `npm run test_run`
- `npm run build > /dev/null`


------
https://chatgpt.com/codex/tasks/task_e_68464aeb00f483329874de8c5fb031d3

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Added support for configuring structured output mode for models in the user interface.
  - Users can now select structured output mode options when running tasks or comparing run methods.
  - Structured output mode is now displayed and configurable for all available models.
  - Enhanced output metadata to include structured output mode, temperature, and top_p settings.
  - Improved model listings and API responses to consistently include recommended structured output modes.
  - Added backward compatibility and validation for structured output mode in task configurations.

- **Bug Fixes**
  - Updated tests to ensure structured output mode is correctly included in model details responses.
  - Added test coverage to verify output properties include structured output mode and related settings.
  - Adjusted error handling to enforce model and provider validation in repair tasks.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3069656073,7016,/user/payments/subscriptions is getting hit way too much,lee-at-zoo-corp,203533854,closed,2025-05-16T18:34:54Z,2025-05-19T18:11:34Z,https://github.com/KittyCAD/modeling-app,https://github.com/KittyCAD/modeling-app/issues/7016,"There should only be 2 times this endpoint gets hit: 

1. When the app first starts
2. When the user uses a credit manipulating operation

S'all I've got for now. Might be related to start up spinning https://github.com/KittyCAD/modeling-app/issues/7015"
3117439635,598,Develop,MervinPraison,454862,closed,2025-06-04T11:08:12Z,2025-06-04T11:09:21Z,https://github.com/MervinPraison/PraisonAI,https://github.com/MervinPraison/PraisonAI/pull/598,"### **PR Type**
Enhancement, Tests


___

### **Description**
- Refactor agent tool execution for sequential thinking support
  - Add iterative tool call loop with max iterations
  - Enable conditional continuation for sequential tools

- Migrate test workflows to use pytest and coverage reporting
  - Replace custom test runner with pytest in workflows
  - Add Codecov upload steps for all test types
  - Improve artifact paths and coverage report handling

- Add dedicated coverage workflow for unit tests


___



### **Changes walkthrough** 📝
<table><thead><tr><th></th><th align=""left"">Relevant files</th></tr></thead><tbody><tr><td><strong>Enhancement</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>agent.py</strong><dd><code>Refactor agent tool execution for sequential/sequentialthinking tools</code></dd></summary>
<hr>

src/praisonai-agents/praisonaiagents/agent/agent.py

<li>Refactored tool execution to support iterative/sequential tool calls<br> <li> Introduced loop with max iterations to prevent infinite loops<br> <li> Added logic to check for continuation based on tool call arguments<br> <li> Improved handling for tools like sequential thinking


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/598/files#diff-d535c234c473d9a5415e16b5793afed8bbf02b3c555bed20b8f776c4fed2a58c"">+80/-57</a>&nbsp; </td>

</tr>
</table></td></tr><tr><td><strong>Tests</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>coverage.yml</strong><dd><code>Add dedicated coverage workflow with Codecov upload</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

.github/workflows/coverage.yml

<li>Added new workflow to run unit tests with pytest and collect coverage<br> <li> Installs all dependencies including knowledge and duckduckgo_search<br> <li> Uploads coverage results to Codecov


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/598/files#diff-a2115d277b5ca5a2f09a999e53440839cf332b94da177f3d1766334555b0f7c6"">+60/-0</a>&nbsp; &nbsp; </td>

</tr>

<tr>
  <td>
    <details>
      <summary><strong>test-comprehensive.yml</strong><dd><code>Use pytest and upload coverage for comprehensive tests</code>&nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

.github/workflows/test-comprehensive.yml

<li>Switched unit/integration test execution to pytest with coverage <br>reporting<br> <li> Added Codecov upload step for comprehensive tests<br> <li> Updated artifact paths for coverage files


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/598/files#diff-a8af9724f4482d6cdec9878485599c7f196a338b38f6265694a1788603d37529"">+15/-5</a>&nbsp; &nbsp; </td>

</tr>

<tr>
  <td>
    <details>
      <summary><strong>test-core.yml</strong><dd><code>Add Codecov upload and improve coverage for core tests</code>&nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

.github/workflows/test-core.yml

<li>Enhanced unit test step to generate XML coverage reports<br> <li> Added Codecov upload for core tests (Python 3.11)<br> <li> Updated artifact paths for coverage files


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/598/files#diff-d19ae597896f9f2776f95707fdfc0019a521bab5534c665164cdef1e1b138b5f"">+16/-4</a>&nbsp; &nbsp; </td>

</tr>

<tr>
  <td>
    <details>
      <summary><strong>unittest.yml</strong><dd><code>Use pytest and upload coverage for quick validation tests</code></dd></summary>
<hr>

.github/workflows/unittest.yml

<li>Changed fast test execution to pytest with coverage reporting<br> <li> Added Codecov upload step for quick validation tests


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/598/files#diff-066dfc7b476727cdc5ff6eca6e8191b2a6df2b53a0281182f6c9cf4de7268469"">+12/-2</a>&nbsp; &nbsp; </td>

</tr>
</table></td></tr></tr></tbody></table>

___

> <details> <summary>  Need help?</summary><li>Type <code>/help how to ...</code> in the comments thread for any questions about Qodo Merge usage.</li><li>Check out the <a href=""https://qodo-merge-docs.qodo.ai/usage-guide/"">documentation</a> for more information.</li></details>

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **Chores**
  - Introduced and updated multiple GitHub Actions workflows to improve automated test execution and code coverage reporting, including integration with Codecov for enhanced visibility of test coverage.
- **Bug Fixes**
  - Improved multi-step tool execution in chat completions, enabling more robust and iterative tool call handling during conversations.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3123789197,618,"Revert ""fix: prevent duplicate Task and Response display when using litellm with memory""",MervinPraison,454862,closed,2025-06-06T06:28:16Z,2025-06-06T06:28:28Z,https://github.com/MervinPraison/PraisonAI,https://github.com/MervinPraison/PraisonAI/pull/618,"### **User description**
Reverts MervinPraison/PraisonAI#617


___

### **PR Type**
Bug fix, Tests


___

### **Description**
- Reverts previous fix for duplicate Task and Response display.

- Removes suppression of display logic in agent and LLM modules.

- Deletes test file for duplicate display issue.


___



### **Changes walkthrough** 📝
<table><thead><tr><th></th><th align=""left"">Relevant files</th></tr></thead><tbody><tr><td><strong>Bug fix</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>agent.py</strong><dd><code>Remove suppression of duplicate display in agent chat</code>&nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

src/praisonai-agents/praisonaiagents/agent/agent.py

<li>Removes <code>suppress_display</code> parameter from LLM call.<br> <li> Deletes logic that suppressed duplicate display and custom display <br>interaction.


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/618/files#diff-d535c234c473d9a5415e16b5793afed8bbf02b3c555bed20b8f776c4fed2a58c"">+1/-7</a>&nbsp; &nbsp; &nbsp; </td>

</tr>

<tr>
  <td>
    <details>
      <summary><strong>llm.py</strong><dd><code>Restore always-on display interaction in LLM responses</code>&nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

src/praisonai-agents/praisonaiagents/llm/llm.py

<li>Removes <code>suppress_display</code> parameter from <code>get_response</code>.<br> <li> Restores display logic to always show interaction if verbose.<br> <li> Removes conditional checks for suppressing display.


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/618/files#diff-a7acc128a307fc2efa16544e39af3c3ddbc06f25f5a49a557e74391a95992129"">+6/-7</a>&nbsp; &nbsp; &nbsp; </td>

</tr>
</table></td></tr><tr><td><strong>Tests</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>test_duplicate_fix.py</strong><dd><code>Remove duplicate display issue test script</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

test_duplicate_fix.py

- Deletes test script for duplicate display issue.


</details>


  </td>
  <td><a href=""https://github.com/MervinPraison/PraisonAI/pull/618/files#diff-ddfe02cda2b59509132e603b6f57917b4d311025cbcfd42d40f08741f968f43b"">+0/-37</a>&nbsp; &nbsp; </td>

</tr>
</table></td></tr></tr></tbody></table>

___

> <details> <summary>  Need help?</summary><li>Type <code>/help how to ...</code> in the comments thread for any questions about Qodo Merge usage.</li><li>Check out the <a href=""https://qodo-merge-docs.qodo.ai/usage-guide/"">documentation</a> for more information.</li></details>

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **Refactor**
  - Simplified display logic by removing the suppression flag; output is now shown whenever verbose mode is enabled.
- **Tests**
  - Removed a test script related to duplicate display verification.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3161496344,2466,Image.from_matplotlib fails in Python 3.13,pgagarinov,4868370,closed,2025-06-19T23:03:44Z,2025-06-19T23:56:13Z,https://github.com/Netflix/metaflow,https://github.com/Netflix/metaflow/issues/2466,"This is a pipeline-reproducer taken from https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#showing-an-image-with-image:
 
```python
from metaflow import FlowSpec, step, current, card
from metaflow.cards import Image


class MatplotlibFlow(FlowSpec):
    @card(type=""blank"")
    @step
    def start(self):
        import matplotlib.pyplot as plt
        import numpy

        fig = plt.figure()
        x = numpy.random.normal(0, 0.1, 100000)
        y = numpy.random.normal(0, 0.1, 100000)
        plt.scatter(x, y, s=0.1, color=(0.2, 0.2, 1.0, 0.2))
        current.card.append(Image.from_matplotlib(fig))
        self.next(self.end)

    @step
    def end(self):
        pass


if __name__ == ""__main__"":
    MatplotlibFlow()
```
  
Running it produces an error that is only visible in Metaflow UI:
```

    [IMAGE_RENDER FAIL]: Matplotlib plot's image is not parsable

Traceback (most recent call last):
  File "".../python3.13/site-packages/metaflow/plugins/cards/card_modules/components.py"", line 556, in from_matplotlib
    parsed_image, error_comp = cls._parse_matplotlib(plot)
                               ~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "".../python3.13/site-packages/metaflow/plugins/cards/card_modules/components.py"", line 489, in _parse_matplotlib
    parsed_value = task_to_dict.parse_image(img_bytes_arr.getvalue())
  File ""..../python3.13/site-packages/metaflow/plugins/cards/card_modules/convert_to_native_type.py"", line 146, in parse_image
    import imghdr
ModuleNotFoundError: No module named 'imghdr'
```
Here is a screenshot: 

<img width=""1110"" alt=""Image"" src=""https://github.com/user-attachments/assets/49113343-fd76-46b1-bda9-9be9ee4a47fc"" />


Here is the root of the problem:

https://docs.python.org/3/library/imghdr.html


The workaround was to install 'standard-imghdr' manually from pypi.

"
3092462398,135,Integrate khomeik sanskrit poetry,shannonsands,7897813,closed,2025-05-27T03:34:09Z,2025-05-27T03:35:28Z,https://github.com/NousResearch/atropos,https://github.com/NousResearch/atropos/pull/135,"<!--
╭───────────────────────────────────────────────────────╮
│  ✨  ATROPOS PULL REQUEST TEMPLATE  ✨                    │
│  Select PR type below and fill applicable sections.       │
│  Delete non-applicable sections for your PR type.         │
╰───────────────────────────────────────────────────────╯
-->

## PR Type
<!-- Please check ONE of the following options -->
- [x] RL Environment PR - Complete Environment Snapshot & Zero-Training sections
- [ ] Non-Environment PR - Complete Description, Related Issues & Type of Change sections

---

## 📝 General Information
### Description
Integrates the Sanskrit Poetry Environment from KhoomeiK's contribution, enabling training of language models to generate authentic Sanskrit verse that adheres to traditional metrical patterns. This environment combines computational linguistics with cultural preservation, using the chandas (meter) classification system to validate poetic accuracy.

The integration includes:
- **ChandasMeterReward**: New reward function added to the registry for metrical validation
- **Sanskrit Poetry Environment**: Moved to `environments/community/sanskrit_poetry/`
- **Comprehensive Documentation**: Added as entry #25 in community README
- **Code Quality**: All pre-commit checks passing with proper formatting

---

## 🔖 Environment Snapshot
| Field | Your Entry |
|-------|------------|
| **Environment Name** | Sanskrit Poetry Environment |
| **Short Description** | Train LLMs to generate Sanskrit poetry adhering to traditional metrical patterns using chandas classification |
| **Category** | Verifiable-Reasoning |
| **Dataset Needed?** | No - generates meter-specific prompts dynamically |
| **External Deps** | chandas package (must be built from [source](https://github.com/sanskrit/chandas)) |
| **Environmental Variables** | None required |
| **Compute Footprint Estimate** | <500MB RAM, <30s per poem generation and validation |

## 🧪 Zero-Training Test Results
<details>

**W&B Link:**
Environment designed by KhoomeiK without execution - integration focused on code quality and documentation

**Examples of the Environment scoring a good example and a bad example:**

</details>

---

## ✅ Developer & Reviewer Checklist
- [x] Code follows project style (black, isort, flake8 pass with pre-commit)
- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [x] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [x] New and existing unit tests pass locally with my changes
- [x] Docstrings added for all new public classes / functions
- [x] If .env vars required, did you add it to the .env.example in repo root?

**Integration Notes:**
- Successfully merged KhoomeiK's contribution from PR #71
- Added ChandasMeterReward to `atroposlib/envs/reward_fns/` registry
- Moved environment to community structure following established patterns
- Fixed all code formatting issues with pre-commit hooks
- Added comprehensive documentation as entry #25 in community README
- Environment supports multiple Sanskrit meters (tristubh, anushtubh, etc.)
- Includes IAST to SLP1 transliteration for accurate meter analysis
- Registry-based reward system for modular scoring
- Pydantic configuration with type safety and validation"
3032705346,5008,[Bug] manifest.json returns 401 in CORS setup,atehrani-statrad,183532450,open,2025-04-30T22:38:41Z,,https://github.com/OHIF/Viewers,https://github.com/OHIF/Viewers/issues/5008,"### Describe the Bug

When deploying the OHIF Viewer that requires CORS (for example the OHF Viewer is hosted on site A port 443 and API is hosted on another site B port 8080, both have authentication enabled). When loading the application looking at the network tab in developer options we see that the manifest.json returns a 401.

### Steps to Reproduce

1. Deploy OHIF Viewer in IIS on site A with Windows Authentication Enabled
2. Deploy DICOMweb API in IIS on another site B with Windows Authentication Enabled
4. Load the OHIF Viewer
5. Enter in valid credentials
6. Inspect the browser developer tools network tab and see that attempting to load the manifest.json fails with 401

### The current behavior

Attempting to load the manifest.json fails with 401 if authentication is enabled for a site under CORS.

### The expected behavior

The loading of the manifest.json file should succeed with 200 if authentication is enabled for a site under CORS with valid credentials.

### OS

Windows 11

### Node version

N/A

### Browser

Microsoft Edge 135.0.3179.98"
3092982220,738,"Revert ""Improve annotation Javadoc""",peter-lawrey,1070321,closed,2025-05-27T07:49:44Z,2025-05-27T07:49:54Z,https://github.com/OpenHFT/Chronicle-Core,https://github.com/OpenHFT/Chronicle-Core/pull/738,Reverts OpenHFT/Chronicle-Core#737
3093095750,741,Improve annotation Javadoc for core.annotation,peter-lawrey,1070321,closed,2025-05-27T08:26:16Z,2025-06-03T13:43:32Z,https://github.com/OpenHFT/Chronicle-Core,https://github.com/OpenHFT/Chronicle-Core/pull/741,"This PR refactors the **Chronicle Core** annotation codebase in three incremental commits.  
Together they **remove redundant test code** and **significantly enrich the Javadoc** for every annotation in `net.openhft.chronicle.core.annotation`, providing clear, consistent and tool-friendly documentation.

---

## Remove unused test

* **Deleted:** `ScopeConfinedTest.java` (49 lines)  
  *The test neither asserted library behaviour nor exercised production code. Removing it shrinks the test-suite surface and eliminates maintenance noise.*

---

## Improve annotation Javadoc (#739)

* **Added ~200 Javadoc lines, removed legacy boiler-plate.**
* **Key themes**
  * First-sentence definitions: **“`@X` indicates …`”** for instant context.
  * *Retention and effect* paragraphs clarifying compile-/run-time visibility.
  * Minimal usage snippets for every annotation.
  * Cross-links (`@see`) so related annotations discover each other.
  * British spelling with US technical keywords (`synchronized`, etc.).

---

## Enhance annotation Javadoc (#740)

* **Follow-up polish** driven by review feedback:
  * Extra examples, limitation notes and small API tables for the sign/range annotations.
  * Deeper rationale for `@DontChain`, `@ScopeConfined`, `@SingleThreaded`, `@UsedViaReflection`.
  * Extended package-level overview (lists every annotation, design goals, author & since tags).
  * Clarified `ChronicleFeature` semantics and `TargetMajorVersion` precedence.
  * Added IDE / ProGuard hints where reflection is involved.

No functional behaviour is altered; **CI should remain green**.
"
3093881602,760,documentation-only sweep across net.openhft.chronicle.core.onoes.,peter-lawrey,1070321,closed,2025-05-27T13:07:39Z,2025-06-03T13:44:47Z,https://github.com/OpenHFT/Chronicle-Core,https://github.com/OpenHFT/Chronicle-Core/pull/760,"This pull request is a **documentation-only** sweep across *net.openhft.chronicle.core.onoes*.  
It finishes the work started in #751-#759, then removes a few items that review feedback flagged as noise.

| Patch | Theme | Notes |
|-------|-------|-------|
| 01/13 | **Whitespace** | Strip stray blanks from `package-info.java` to stop AsciiDoc paragraph drift. |
| 02-10/13 | **Javadoc overhaul** | Add or rewrite comments for every public type:<br>• crisp first-sentence summaries<br>• full `@param/@return/@throws` sets<br>• explicit thread-safety statements<br>• SLF4J mapping table in `LogLevel`<br>• examples and `@implNote/@apiNote`s<br>• modernised package overview. |
| 11-12/13 | **Noise removal** | Delete boiler-plate `{@inheritDoc}` blocks introduced during earlier iterations – the methods are self-explanatory. |
| 13/13 | **Tag hygiene** | Drop the `@since 3.25ea` markers that were making the docs verbose |

### Why we need it
* **Cleaner generated docs** – IDE tool-tips and the public site no longer italicise parameter names or show duplicated text.  
* **Accurate contracts** – Users now see thread-safety guarantees and fallback behaviour explicitly called out.  
* **Maintenance** – The codebase no longer carries superfluous tags, so future contributors have less clutter to maintain.  

There are **no code-path or binary changes**; all unit tests still pass.

### Impact & migration
Zero runtime impact – consumers do **not** need to recompile or change any code. The only visible change is richer, cleaner documentation.
"
3094356343,773,Documentation improvements for core.scoped and core.shutdown,peter-lawrey,1070321,closed,2025-05-27T15:30:21Z,2025-06-03T13:07:21Z,https://github.com/OpenHFT/Chronicle-Core,https://github.com/OpenHFT/Chronicle-Core/pull/773,"
This PR is a documentation-focused sweep that tightens wording, clarifies contracts, and removes small glitches discovered while working on #762-#772. **No production logic is changed.**

## ✨ Highlights

| Area | Change | Why it matters |
|------|--------|----------------|
| **General clean-ups** | • Fixed typos (“an unique” → “a unique”).<br>• Updated JUnit 4 imports to JUnit 5 in tests.<br>• Removed a redundant cast in `PriorityHookTest`. | Keeps CI warnings at zero and aligns with the rest of the test-suite. |
| **`scoped` package** | • Added full class-level headers to `AbstractScopedResource`, `ScopedResource`, `ScopedThreadLocal`, `Strong/WeakReferenceScopedResource`.<br>• Introduced `package-info.java` with a runnable example and thread-confinement rules.<br>• Expanded constructor/parameter docs and clarified weak vs strong semantics. | Developers can now rely on IDE quick-docs rather than reading source. |
| **`shutdown` package** | • Re-wrote Javadoc for `Hooklet` & `PriorityHook`, detailing priority ranges, identity semantics, and thread-safety.<br>• Added null-checks in factory helper and in docs. | Makes the shutdown subsystem self-explaining and harder to misuse in multi-module deployments. |
| **`pom` helper** | • Added class header to `PomProperties` and annotated parameters as non-null. | Completes public API documentation coverage. |
| **Tests** | • Minor import / assertion updates to use `org.junit.jupiter.api.Assertions`. | Moves more tests to JUnit 5 baseline. |

"
3102979363,1020,Javadoc for Core Wire API & Base Classes,peter-lawrey,1070321,open,2025-05-30T11:38:25Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1020,"## ✨ What’s inside this PR

A spring-clean of Chronicle Wire’s public API documentation plus one tiny code tidy-up.

* **Fresh, developer-focused Javadoc** across the core API surface
  (`Wire`, `WireIn`, `WireOut`, `WireCommon`, `MarshallableOut`, `SourceContext`,
  `ReadAnyWire`, `AbstractWire`, *etc.*).

  * Clearer intent sentences in the first line (good for IDE pop-ups)
  * Consistent parameter / return wording and `{@code …}` usage
  * Extra context & examples where our users have stumbled before
  * Explicit notes on threading, locking, padding and header semantics
  * Removal of outdated remarks (RAW wire, old queue tricks…)

* **Log-spew removal** – deleted a stray debug `System.err.println`
  in `AbstractWire.endOfWire`.

---

## Commit map

| Commit | Message                                       | Summary                                                  |
| ------ | --------------------------------------------- | -------------------------------------------------------- |
| 01/11  | **Create the branch**                         | Drops the redundant blank log line in `AbstractWire`.    |
| 02/11  | **Clarify `SourceContext` Javadoc** (#1017)   | Modern, concise description + param docs.                |
| 03/11  | **Improve `MarshallableOut` Javadoc** (#1016) | Full rewrite; adds examples & thread-safety notes.       |
| 04/11  | **Clarify acquisition Javadoc** (#1015)       | Better explanation of `ReadAnyWire` lazy detection flow. |
| 05/11  | **Improve `AbstractWire` Javadoc** (#1014)    | 100-line expansion covering every tricky internal field. |
| 06/11  | **Clarify `Wire` Javadoc** (#1013)            | First-line summary & method docs.                        |
| 07/11  | **Enhance `WireOut` Javadoc** (#1012)         | Consistent English, new examples, tightened throws.      |
| 08/11  | **Improve `WireIn` Javadoc** (#1011)          | Similar pass for read-side API.                          |
| 09/11  | *(no diff – squashed into 08/11)*             |                                                          |
| 10/11  | **Improve `WireCommon` Javadoc** (#1009)      | Clarifies padding, parent, reference factories.          |
| 11/11  | **Improve `Wire` interface Javadoc** (#1019)  | Follow-up tweaks & typo fixes.                           |

---

## Impact & compatibility

* **Code behaviour:** **unchanged** – docs only, plus removal of one unused log line.
* **Binary/API compatibility:** safe – no signatures touched.
* **Generated site:** Javadoc HTML will update automatically on next release."
3102994871,1030,Javadoc for Document Context Handling,peter-lawrey,1070321,open,2025-05-30T11:45:21Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1030,"## ✨ What’s new in this PR

A focused documentation pass over **Chronicle Wire’s* document-context stack plus one tiny API convenience method.*

* **Brand-new `DocumentContext#isOpen()` default method**
   – a friendly alias that mirrors `isNotComplete()` and reads more intuitively in client code.

* **Thorough, consistent Javadoc across the read/write context family**
  (`DocumentContext`, `WriteDocumentContext`, `ReadDocumentContext`,
  `Text*DocumentContext`, `Binary*DocumentContext`,
  `DocumentContextHolder`, `WrappedDocumentContext`,
  `NoDocumentContext`, `DocumentWritten`).

  * first-line “intent sentences” for IDE tooltips
  * clarified life-cycle rules (start/close/reset, rollback, chaining)
  * examples, parameter/return semantics, exception notes
  * internal field explanations and threading notes
  * removal of stale references (delta wire, obsolete flags)

* **No behavioural changes** – only comments and the small, backwards-compatible addition of `isOpen()`.

---

## Commit guide

| Commit    | Message                                              | Highlights                                                      |
| --------- | ---------------------------------------------------- | --------------------------------------------------------------- |
| **01/10** | Create the branch                                    | Adds `isOpen()` (defaults to `isNotComplete()`) + stub Javadoc. |
| **02/10** | Improve `DocumentContext` Javadoc (#1021)            | Full rewrite; examples & contract clarifications.               |
| **03/10** | Improve `WriteDocumentContext` Javadoc (#1022)       | Adds start/chain semantics, empty-check docs.                   |
| **04/10** | Clarify `ReadDocumentContext` behaviour (#1023)      | Documents limit/position restore helpers.                       |
| **05/10** | Improve `TextReadDocumentContext` Javadoc (#1024)    | Explains `---/…` parsing helpers.                               |
| **06/10** | Improve `TextWriteDocumentContext` Javadoc (#1025)   | Details separator handling, rollback flow.                      |
| **07/10** | Improve `BinaryReadDocumentContext` Javadoc (#1026)  | Modern docs + deprecation note on delta wire.                   |
| **08/10** | Improve `BinaryWriteDocumentContext` Javadoc (#1027) | Header-writing algorithm spelled out.                           |
| **09/10** | Improve context holder Javadocs (#1028)              | Docs for wrapper classes & DocumentWritten.                     |
| **10/10** | Improve Javadoc for context wrappers (#1029)         | Final tidy-up (`NoDocumentContext`, `WrappedDocumentContext`).  |
"
3103037110,1038,Marshallable Core Interfaces & Base Classes,peter-lawrey,1070321,open,2025-05-30T12:05:02Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1038,"## 📝 What this PR does

A focused tidy-up of the **core marshalling APIs**

| Area                         | Change                                                                                                                                                                                                                                                                                                                  | Why it matters                                                                                                                                                                                                             |
| ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Null-safety**              | `Marshallable.streamFromFile(Class<T>, String)` is now annotated **`@NotNull`** instead of `@Nullable`. The method never returned null – the annotation now reflects reality.                                                                                                                                           |                                                                                                                                                                                                                            |
| **API docs**                 | Re-wrote and expanded Javadoc for: <br>• `Marshallable` and its helpers<br>• `ReadMarshallable`, `WriteMarshallable`, `MarshallableIn`<br>• Trivially-copyable & config base classes<br>• Annotation/utility types (`AsMarshallable`, `KeyedMarshallable`, …)<br>• Deprecated `DynamicEnum` now states removal schedule | • Consistent first-line “intent” sentences (better IDE tooltips)  • Clearer parameter/return contracts & exception notes  • Practical examples and behavioural edge-cases  • Explicit deprecation notice for `DynamicEnum` |
| **Internal links & wording** | Fixed typos, modernised language, removed outdated references (delta wire, legacy flags).                                                                                                                                                                                                                               | Easier onboarding; smaller learning curve.                                                                                                                                                                                 |

---

## Commit map

| Commit  | Message                                                                  | Highlight                                                                |
| ------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------ |
| **1/7** | Create the branch                                                        | `@Nullable` ➜ `@NotNull` for `streamFromFile(Class, String)`             |
| **2/7** | *Improve Marshallable Javadoc* (#1031)                                   | 100-line rewrite, clearer utility docs                                   |
| **3/7** | *Improve marshallable interfaces Javadoc* (#1032)                        | Full docs for `Read/WriteMarshallable`                                   |
| **4/7** | *Improve Javadoc for marshallable base classes* (#1033)                  | Docs for `BytesInBinaryMarshallable`, `SelfDescribingMarshallable`, etc. |
| **5/7** | *Improve Javadoc for configuration & trivially copyable classes* (#1034) | Merge-aware config notes, schema-evolution notes                         |
| **6/7** | *Document deprecation in DynamicEnum* (#1035)                            | Clearly marked for removal in x.28                                       |
| **7/7** | *Improve MarshallableIn Javadoc* (#1037)                                 | Extensive read-side docs & intern limit note                             |"
3103081781,1046,Javadoc Serialization Strategy & WireMarshaller,peter-lawrey,1070321,open,2025-05-30T12:22:38Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1046,"A housekeeping sweep across **serialization-strategy infrastructure** and the core marshaller

| Area                             | Change                                                                                                                                                                                                                                                                              | Rationale                                                                                                                                          |
| -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| **API Docs**                     | Re-wrote/expanded Javadoc for:<br>• `SerializationStrategy` + the `SerializationStrategies` enum<br>• `ScalarStrategy`<br>• `WireMarshaller`, `FieldAccess`, and the “unexpected field” marshaller<br>• `SerializationStrategies` nested wrappers (Array/PrimArray/Demarshallable). | \* Clearer contracts and type expectations  \* Links to related types  \* Added bracket-type semantics  \* Marked deprecations & removal schedules |
| **Internal comments & tidy-ups** | • Added missing `@return` / `@param` docs<br>• Removed outdated references (DeltaWire, legacy flags)<br>• Consistent first-line summary sentences                                                                                                                                   | Easier onboarding; IDE hovers are now useful.                                                                                                      |

---

## Breakdown by commit

| Commit  | Message                                                   | Highlight                                                    |
| ------- | --------------------------------------------------------- | ------------------------------------------------------------ |
| **1/8** | Create branch                                             | make `ordinal` field `final`                                 |
| **2/8** | *Improve SerializationStrategy Javadoc* (#1039)           | new param/return docs, bracket-type clarifications           |
| **3/8** | *Improve javadoc for SerializationStrategies* (#1040)     | each enum constant now fully documented                      |
| **4/8** | *Improve Javadoc in ScalarStrategy* (#1041)               | explained builder helpers, NONE bracket type                 |
| **5/8** | *Improve javadoc for WireMarshaller* (#1042)              | overview, constructor notes, leaf/default logic              |
| **6/8** | *Further WireMarshaller docs* (#1043)                     | added per-method explanations                                |
| **7/8** | *Improve javadoc for FieldAccess* (#1045)                 | covered every nested accessor class                          |
| **8/8** | *Improve Javadoc for unexpected field marshaller* (#1044) | explained custom flow when `unexpectedField()` is overridden |
"
3107809620,1109,Comprehensive Javadoc Refresh for Custom Wires,peter-lawrey,1070321,open,2025-06-01T20:27:00Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1109,"The wire module’s public-facing documentation had drifted behind the codebase, leaving gaps, outdated descriptions and inconsistent style.  Clear, accurate Javadoc is essential for:

* **Onboarding & maintenance** – newcomers can understand design intentions without having to delve into the code.
* **Tooling** – IDE quick-docs and generated site docs inherit these comments.
* **API stability** – well-defined contracts make it obvious what is (and is not) part of the public API surface.

### What changed?

| Commit              | Class / Area         | Key improvements                                                                                                      |
| ------------------- | -------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **76866f6 / #1105** | `RawWire`            | End-to-end rewrite: focuses on metadata-free layout, read/write caveats, constructor params, inner `RawValue*` docs.  |
| **9d4f7d6 / #1106** | `CSVWire`            | Added header-row semantics, escaping rules, constructor factories, and detailed `ValueIn/Out` behaviour.              |
| **50b2b84 / #1107** | `QueryWire`          | Describes URL-query grammar, stop-char testers, unsupported operations, and value writer semantics.                   |
| **0e54b10 / #1101** | `HashWire`           | Positions class as hashing-only `WireOut`, explains mixing constants, thread-local usage and every `ValueOut` branch. |
| **68f76f1 / #1102** | `InputStreamToWire`  | Documents length-prefixed framing, buffer lifecycle and error handling.                                               |
| **3846c4a / #1103** | `WireToOutputStream` | Mirrors the above for output: explains framing, buffer reuse and stream ownership.                                    |
| **85500a8 / #1104** | `WireObjectOutput`   | Adds per-method mapping notes from `ObjectOutput` → `ValueOut`, clarifies no-op methods.                              |
| **ae32574 / #1108** | `WireObjectInput`    | Trims boilerplate, adds targeted explanations, documents unsupported operations.                                      |

**Net diff:** *\~ +540 / -190* lines, 100 % comment-only – zero bytecode or functional changes.
"
3107845295,1121,Javadoc overhaul for the Method-Writer stack,peter-lawrey,1070321,open,2025-06-01T20:54:50Z,,https://github.com/OpenHFT/Chronicle-Wire,https://github.com/OpenHFT/Chronicle-Wire/pull/1121,"## Pull Request – Javadoc overhaul for the **Method-Writer** stack (#1110)

The Method-Writer code-path (proxy generation, invocation handlers, builders and helpers) is one of Chronicle Wire’s most sophisticated areas, but its documentation lagged behind the implementation:

* Several public classes lacked any contract-level comment.
* Internal helpers had misleading or redundant remarks (“This was a lambda…”).
* IDE quick-docs showed boiler-plate placeholders instead of useful guidance.

Cleaning this up vastly improves discoverability for users building fluent APIs and makes maintenance easier for the team.

### What changed?

| Area                           | Classes touched                                                                                                                                                                               | Highlights                                                                                                                                                                                            |
| ------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Invocation layer**           | `AbstractMethodWriterInvocationHandler`, `BinaryMethodWriterInvocationHandler`, `TextMethodWriterInvocationHandler`, `MethodWriterInvocationHandlerSupplier`, `ParameterHolderSequenceWriter` | • Clarified record-history, method-ID and generic-event semantics<br>• Documented caching strategy and thread-safety behaviour                                                                        |
| **Proxy generation (v1 & v2)** | `GenerateMethodWriter`, `GenerateMethodWriter2`, `MethodWriterClassNameGenerator`                                                                                                             | • Added end-to-end class/field/method docs explaining name mangling, template use, hash logic & fallbacks<br>• Removed verbose “what this method returns” boiler-plate and replaced with focused info |
| **Builder & API contracts**    | `VanillaMethodWriterBuilder`, `MethodWriter`, `MethodWriterValidationException`                                                                                                               | • Detailed fluent options, fallback paths, and error cases<br>• Linked to public entry points (`MarshallableOut#methodWriter…`)                                                                       |
| **Validation & Exceptions**    | `MethodWriterValidationException`                                                                                                                                                             | • Now states why fallback to reflection is *not* performed                                                                                                                                            |
| **Misc. helpers**              | `MethodWriterClassNameGenerator`                                                                                                                                                              | • Explained naming algorithm, hash converter, and length guard                                                                                                                                        |

 *comment-only* — absolutely **no byte-code or runtime behaviour change**.

"
3080333429,143,reafactor: remove deprecated awq algorithm,johnrachwan123,43934839,closed,2025-05-21T13:55:50Z,2025-05-26T15:04:39Z,https://github.com/PrunaAI/pruna,https://github.com/PrunaAI/pruna/pull/143,"## Description
- remove `AWQQuantizer` implementation and references
- drop awq save/load helpers
- update handler utils
- clean up SmashConfig examples
- remove autoawq dependency
- drop awq test case

## Related Issue
None.

## Type of Change
<!-- Mark the appropriate option with an ""x"" (no spaces around the ""x"") -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

## How Has This Been Tested?
None.

## Checklist
<!-- Mark items with ""x"" (no spaces around the ""x"") -->
- [x] My code follows the style guidelines of this project
- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [x] I have made corresponding changes to the documentation
- [ ] I have added tests that prove my fix is effective or that my feature works
- [x] New and existing unit tests pass locally with my changes

## Additional Notes
There will be another PR that adds AWQ back through llm-compressor."
3067890251,3648,XML content lost when using copy button on task page,KJ7LNW,93454819,closed,2025-05-16T04:17:50Z,2025-06-27T03:20:39Z,https://github.com/RooCodeInc/Roo-Code,https://github.com/RooCodeInc/Roo-Code/issues/3648,"## Which version of the app are you using?
v3.16.5

## Which API Provider are you using?
Anthropic

## Which Model are you using?
sonnet-3.5

## What happened?
When clicking the copy button on an existing task on the main front status page, the XML content structure is lost. Only the values inside the XML tags are copied, not the complete XML structure.

Expected behavior: The copy button should copy the entire original message content provided by the user.

## Steps to reproduce
1. Create or navigate to a task that contains XML content (such as a write_to_file operation)
2. Click the copy button on the task
3. Paste the copied content

The pasted content only contains the values from inside the XML tags, not the complete XML structure.

## Relevant API REQUEST output
Original content:
```
<write_to_file>
<path>.txt</path>
<content>test_insert</content>
<line_count>0</line_count>
</write_to_file>
```

After copying, only the following is retained:
```
.txt
test_insert
0
```

## Additional context
This issue affects the ability to easily copy and reuse XML tool commands from the task page."
3013111535,9868,"[Marketplace] Get rid of white bg color, this is not part of the designs...",ograce1421,191569339,closed,2025-04-23T08:19:00Z,2025-06-18T16:48:34Z,https://github.com/Significant-Gravitas/AutoGPT,https://github.com/Significant-Gravitas/AutoGPT/issues/9868,"
### Describe your issue.

Please get rid of the white background behind the agent cards. This is not part of the designs that I've created in Figma. 

Make the bg color of the card the same as the bg color of the page.. 

<img width=""1476"" alt=""Image"" src=""https://github.com/user-attachments/assets/72169002-d1cd-4f84-8613-07b7541dc3c5"" />

"
3128052176,214,"Disable the ""submit"" button while submitting",skorokithakis,23648,closed,2025-06-08T07:48:04Z,2025-06-09T06:59:26Z,https://github.com/SimonHalvdansson/Harmonic-HN,https://github.com/SimonHalvdansson/Harmonic-HN/issues/214,"When I write a comment, it's entirely possible to double-tap ""submit"" and get the comment posted twice. The button should be disabled while the request is in flight. "
3127922322,198,"Revert ""Add announcements to home view""",StephenDev0,158498287,closed,2025-06-08T04:51:47Z,2025-06-08T04:51:59Z,https://github.com/StephenDev0/StikDebug,https://github.com/StephenDev0/StikDebug/pull/198,Reverts StephenDev0/StikDebug#195
3139785426,18160,[Admin] Fix back button,GSadee,6140884,closed,2025-06-12T10:50:59Z,2025-06-12T11:26:29Z,https://github.com/Sylius/Sylius,https://github.com/Sylius/Sylius/pull/18160,"| Q               | A
|-----------------|-----
| Branch?         | 2.0
| Bug fix?        | yes
| New feature?    | no
| BC breaks?      | no
| Deprecations?   | 
| Related tickets | fixes https://github.com/Sylius/Sylius/issues/18098, replaces https://github.com/Sylius/Sylius/pull/18159, backporting https://github.com/Sylius/Sylius/pull/18084
| License         | MIT

<!--
 - Bug fixes must be submitted against the 1.14 or 2.0 branch
 - Features and deprecations must be submitted against the 2.1 branch
 - Make sure that the correct base branch is set

 To be sure you are not breaking any Backward Compatibilities, check the documentation:
 https://docs.sylius.com/en/latest/book/organization/backward-compatibility-promise.html
-->
"
3071542940,844,Vosk refactor introduced very slow loading,nshmyrev,2886672,closed,2025-05-18T08:14:05Z,2025-05-18T10:14:00Z,https://github.com/Uberi/speech_recognition,https://github.com/Uberi/speech_recognition/issues/844,"This PR:

https://github.com/Uberi/speech_recognition/pull/843

has critical issue, it loads new model on every recognition call.  It is a wrong approach and also very slow. 

"
3064843419,1226,Version Packages,github-actions[bot],41898282,closed,2025-05-15T04:21:22Z,2025-06-04T09:53:30Z,https://github.com/acacode/swagger-typescript-api,https://github.com/acacode/swagger-typescript-api/pull/1226,"This PR was opened by the [Changesets release](https://github.com/changesets/action) GitHub action. When you're ready to do a release, you can merge this and the packages will be published to npm automatically. If you're not ready to do a release yet, that's fine, whenever you add more changesets to main, this PR will be updated.


# Releases
## swagger-typescript-api@13.2.0

### Minor Changes

-   [#1187](https://github.com/acacode/swagger-typescript-api/pull/1187) [`1039ff1`](https://github.com/acacode/swagger-typescript-api/commit/1039ff1ac1c40c1875e31799ae9405f2f57862fd) Thanks [@gletournel](https://github.com/gletournel)! - Add support for json:api content type.

### Patch Changes

-   [#1225](https://github.com/acacode/swagger-typescript-api/pull/1225) [`a013686`](https://github.com/acacode/swagger-typescript-api/commit/a013686d8ce4e82bc16e5159d35a7fd1870497ab) Thanks [@smorimoto](https://github.com/smorimoto)! - Update the internal Biome to latest beta release.

-   [#1266](https://github.com/acacode/swagger-typescript-api/pull/1266) [`469ded7`](https://github.com/acacode/swagger-typescript-api/commit/469ded79d412b9fd4b3bed8dd493f63ebf48331f) Thanks [@dependabot](https://github.com/apps/dependabot)! - Update the internal Biome to latest beta release.

-   [#1235](https://github.com/acacode/swagger-typescript-api/pull/1235) [`0e251bb`](https://github.com/acacode/swagger-typescript-api/commit/0e251bb042bdec35fd6efa714868486ff882c7e4) Thanks [@smorimoto](https://github.com/smorimoto)! - Fix typos in CLI option description and warning message.

-   [#1270](https://github.com/acacode/swagger-typescript-api/pull/1270) [`c79625e`](https://github.com/acacode/swagger-typescript-api/commit/c79625e785b26926f1e1ca20a4ba847952a557da) Thanks [@smorimoto](https://github.com/smorimoto)! - Remove `required` field from command definitions for now.
"
3088434733,409,Feat/projects,alex-aipolabs,206715974,closed,2025-05-24T12:50:12Z,2025-06-02T13:44:21Z,https://github.com/aipotheosis-labs/aci,https://github.com/aipotheosis-labs/aci/pull/409,"### 🏷️ Ticket

[notion](https://www.notion.so/fbce3fc996ad4b2aaacd85d0492a48d7?v=c135b6e7f76243819caf99a83e291380&p=1f98378d6a478039b9a1da148a6dc2ee&pm=s)

### 📝 Description

Updated ui to add, delete and update projects.
Added crud operations for projects in the backend.
Return 409 Conflict if trying to delete last project
Return 422 Unprocessable if trying to create a project with empty name
Return 403 Forbidden if trying to create a project over the quota


### 🎥 Demo (if applicable)

### 📸 Screenshots (if applicable)

### ✅ Checklist

- [ ] I have signed the [Contributor License Agreement]() (CLA) and read the [contributing guide](./../CONTRIBUTING.md) (required)
- [ ] I have linked this PR to an issue or a ticket (required)
- [ ] I have updated the documentation related to my change if needed
- [ ] I have updated the tests accordingly (required for a bug fix or a new feature)
- [ ] All checks on CI passed


<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Added ability to create, update (rename), and delete projects from the user interface, including confirmation dialogs and inline project name editing.
  - Introduced a ""Danger Zone"" section for project deletion with safeguards to prevent deleting the last project in an organization.
  - Added a modal dialog for creating new projects directly from the project selector dropdown.

- **Improvements**
  - Projects are now sorted by creation date, and the active project selection is persisted across sessions.
  - Subscription plans now explicitly display project limits, and these limits are enforced when creating projects.
  - Enhanced error messages and user feedback for project-related actions.

- **Bug Fixes**
  - Improved error handling and validation for project creation and updates, including prevention of empty project names.

- **Tests**
  - Expanded and improved test coverage for project creation, updating, deletion, validation, and cascading deletions.

- **Documentation**
  - Updated pricing page to clearly display the number of projects included in each subscription plan.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3115373709,453,Feat/invite users,alex-aipolabs,206715974,closed,2025-06-03T20:37:39Z,2025-06-09T08:59:50Z,https://github.com/aipotheosis-labs/aci,https://github.com/aipotheosis-labs/aci/pull/453,"### 🏷️ Ticket

[notion](https://www.notion.so/fbce3fc996ad4b2aaacd85d0492a48d7?v=c135b6e7f76243819caf99a83e291380&p=1ca8378d6a4780d9842de0b5145772ef&pm=s)

### 📝 Description

[Describe your changes in detail (optional if the issue you linked already contains a
detail description of the change)]

### 🎥 Demo (if applicable)

### 📸 Screenshots (if applicable)

### ✅ Checklist

- [x] I have signed the [Contributor License Agreement]() (CLA) and read the [contributing guide](./../CONTRIBUTING.md) (required)
- [x] I have linked this PR to an issue or a ticket (required)
- [ ] I have updated the documentation related to my change if needed
- [x] I have updated the tests accordingly (required for a bug fix or a new feature)
- [x] All checks on CI passed


<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Introduced organization member management endpoints, allowing admins to invite new members, remove members, and view all organization members via the API.

- **Improvements**
  - Adjusted project access controls so that admins can now create projects and all members can view projects, providing more flexible organization management.
  - Simplified access validation by relying solely on built-in organization role checks.
  - Updated API key and organization ID header usage to configurable constants for consistent authentication and routing.

- **Chores**
  - Added a new API route prefix and header constants for organizations to the server configuration.
  - Registered the organizations router in the application setup.

- **Tests**
  - Added comprehensive tests for organization member invitation, removal, and listing functionalities, including authorization and role-based access control scenarios.
  - Updated tests to use configurable header constants for organization ID.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3105340038,132,"Revert ""Add CI workflow with tests""",alexanderjeurissen,1220084,closed,2025-05-31T11:17:04Z,2025-05-31T11:17:10Z,https://github.com/alexanderjeurissen/ranger_devicons,https://github.com/alexanderjeurissen/ranger_devicons/pull/132,Reverts alexanderjeurissen/ranger_devicons#130
1701361847,1370,Profiling eslint rules performance,anikets43,7136799,closed,2023-05-09T05:28:34Z,2025-05-25T09:48:25Z,https://github.com/angular-eslint/angular-eslint,https://github.com/angular-eslint/angular-eslint/issues/1370,"How to profile eslint rules performance with `@angular-eslint/builder`

Ref: https://eslint.org/docs/latest/extend/custom-rules#profile-rule-performance

**Versions**

| package                            | version |
| ---------------------------------- | ------- |
| `@angular-eslint/builder`          | `^15.2.1` |
| `ESLint`                           | `^8.40.0` |
| `node`                             | `16.18.1` |
"
2252370391,1780,[@angular-eslint/schematics] skip-install ignored,Quentigus,5646533,closed,2024-04-19T08:12:09Z,2025-05-25T09:15:54Z,https://github.com/angular-eslint/angular-eslint,https://github.com/angular-eslint/angular-eslint/issues/1780,"Hello,

I'm using your `ng-add` task inside our `ng-new` schematics to generate our projects and we have lost the possibility of using [--skip-install](https://angular.io/cli/new#:~:text=false-,%2D%2Dskip%2Dinstall,-Do%20not%20install).

Would it be possible to add a parameter to ignore [NodePackageInstallTask task]((https://github.com/angular-eslint/angular-eslint/blob/main/packages/schematics/src/ng-add/index.ts#L71) call, please ?

If version 16 is still supported, it would be great if we could have support for this version

Thanks"
2723271957,2165,Rule Request: [prefer-inject] Prefer injecting dependencies via inject instead of constructor arguments,NateRadebaugh,130445,closed,2024-12-06T15:06:16Z,2025-05-26T11:07:13Z,https://github.com/angular-eslint/angular-eslint,https://github.com/angular-eslint/angular-eslint/issues/2165,"[prefer-inject] Prefer injecting dependencies via inject instead of constructor arguments
> https://angular.dev/guide/di/dependency-injection#injecting-consuming-a-dependency
>
> The most common way to inject a dependency is to declare it in a class constructor. When Angular creates a new instance of a component, directive, or pipe class, it determines which services or other dependencies that class needs by looking at the constructor parameter types. For example, if the `HeroListComponent` needs the `HeroService`, the constructor can look like this:
> ```ts
> @Component({ … })
> class HeroListComponent {
>   constructor(private service: HeroService) {}
> }
> ```
> Another option is to use the [inject](https://angular.dev/api/core/inject) method:
> ```ts
> @Component({ … })
> class HeroListComponent {
>   private service = inject(HeroService);
> }
> ```

I'd love to be able to prefer the `inject(HeroService)` format, with auto-fixer"
2866496373,2252,[@angular-eslint/template/cyclomatic-complexity] Take into consideration new Angular control flows when calculating cyclomatic complexity,paperez,4905355,closed,2025-02-20T15:22:25Z,2025-05-24T20:23:15Z,https://github.com/angular-eslint/angular-eslint,https://github.com/angular-eslint/angular-eslint/issues/2252,"
**Description and reproduction of the issue**

The current implementation of the @angular-eslint/template/cyclomatic-complexity rule does not take into consideration Angular 17's new control flow syntax (e.g. @switch, @case, @default, @if, and @for). As a result, templates that are refactored using these new control flow directives may appear to have a lower (or sometimes inconsistent) cyclomatic complexity according to the rule, even though the logical decision points in the template remain unchanged.

**Versions**

| package                                  | version |
| -----------------------------------------| ------- |
| `@angular-eslint/eslint-plugin`                 | `18.1.0` |
| `@angular-eslint/eslint-plugin-template` | `18.1.0` |
| `@angular-eslint/template-parser`           | `18.1.0` |
| `@typescript-eslint/parser`                       | `7.17.0` |
| `ESLint`                                                        | `8.57.0` |
| `node`                                                          | `22.12.0` |

```sh
Angular CLI: 18.2.12
Node: 22.12.0
Package Manager: npm 10.9.0
OS: darwin arm64

Angular: 18.2.9
... animations, cdk, common, compiler, compiler-cli, core, forms
... language-service, material, platform-browser
... platform-browser-dynamic, platform-server, router
... service-worker

Package                         Version
---------------------------------------------------------
@angular-devkit/architect       0.1802.9
@angular-devkit/build-angular   18.2.9
@angular-devkit/core            18.2.12
@angular-devkit/schematics      18.2.12
@angular/cli                    18.2.12
@angular/fire                   18.0.1
@schematics/angular             18.2.9
ng-packagr                      18.1.0
rxjs                            7.8.1
typescript                      5.5.4
webpack                         5.97.1
zone.js                         0.14.10
```

- [x] I have tried restarting my IDE and the issue persists.
- [ ] I have updated to the latest supported version of the packages and checked my `ng version` output per the instructions given here.
"
3088728411,2448,feat!: angular-eslint v20,JamesHenry,900523,closed,2025-05-24T21:01:05Z,2025-06-06T15:17:58Z,https://github.com/angular-eslint/angular-eslint,https://github.com/angular-eslint/angular-eslint/pull/2448,"The contents of this branch are already available to use under the `prerelease-v20` dist tag on npm:

https://www.npmjs.com/package/angular-eslint/v/prerelease-v20

---------

## Final Items before `20.0.0`:

- [ ] **Required:** Double check remaining recommended rules do not contravene the rewritten Angular style guide
- [ ] **Nice to have:** Fix up style guide links and description to match the rewritten Angular style guide (will otherwise come in patch releases on 20.x.x)

---------

~~## TODOs~~ Completed Items

- [x] Drop support for EOL Node 18, align Node support with Angular v20 => `^20.19.0 || ^22.12.0 || ^24.0.0`
- [x] Drop support for TypeScript prior to `5.8` to align with Angular v20
- [x] Switch to Angular v20
- [x] Throw parse errors by default (#2255)
- [x] Do not auto-fix `prefer-standalone` (https://github.com/angular-eslint/angular-eslint/issues/2206)
- [x] Remove `@angular-eslint/component-class-suffix` from recommended to align with v20 style guide and CLI code generation
- [x] Remove `@angular-eslint/directive-class-suffix` from recommended to align with v20 style guide and CLI code generation
- [x] Add the new rule `@angular-eslint/prefer-inject` from #2461 to the recommended config

---------

Fixes #2206
FIxes https://github.com/angular-eslint/angular-eslint/issues/2481"
3088755000,18292,YTT201 diagnostic is wrong when the expression uses `!=`,dscorbett,1124347,closed,2025-05-24T21:29:12Z,2025-05-25T17:16:20Z,https://github.com/astral-sh/ruff,https://github.com/astral-sh/ruff/issues/18292,"### Summary

The diagnostic for [`sys-version-info0-eq3` (YTT201)](https://docs.astral.sh/ruff/rules/sys-version-info0-eq3/) is misleading for expressions with `!=` because it is worded as if the expression uses `==`. If the expression uses `!=`, the diagnostic should recommend `<` instead of `>=`.

```console
$ cat >ytt201.py <<'# EOF'
import sys
sys.version_info[0] != 3
# EOF

$ ruff --isolated check ytt201.py --select YTT201 --output-format concise -q
ytt201.py:2:1: YTT201 `sys.version_info[0] == 3` referenced (python4), use `>=`
```

### Version

ruff 0.11.11 (0397682f1 2025-05-22)"
3110140344,18427,Ruff 0.12,ntBre,36778786,closed,2025-06-02T13:13:14Z,2025-06-17T13:58:12Z,https://github.com/astral-sh/ruff,https://github.com/astral-sh/ruff/pull/18427,"## Summary

Release branch for Ruff 0.12.0

### Breaking changes

- Remove rust-toolchain.toml from sdist #17925 
- https://github.com/astral-sh/ruff/pull/18704

### Behavior changes
- https://github.com/astral-sh/ruff/pull/18500
- https://github.com/astral-sh/ruff/pull/18496
- https://github.com/astral-sh/ruff/pull/18506
- https://github.com/astral-sh/ruff/pull/18497
- https://github.com/astral-sh/ruff/pull/18522
- https://github.com/astral-sh/ruff/pull/18523
- https://github.com/astral-sh/ruff/pull/18518
- https://github.com/astral-sh/ruff/pull/18521
- https://github.com/astral-sh/ruff/pull/18520
- https://github.com/astral-sh/ruff/pull/18505
  - This might be a good one to mention in the blog post because existing ignores/noqas of UP007 will need to be extended/replaced with UP045
- https://github.com/astral-sh/ruff/pull/18516

### Recoded rules

### Deprecated rules
- https://github.com/astral-sh/ruff/pull/18618

### Changed rules

### Removed rules
- https://github.com/astral-sh/ruff/pull/18617

### Stabilized rules
- https://github.com/astral-sh/ruff/pull/18512
- https://github.com/astral-sh/ruff/pull/18510
- https://github.com/astral-sh/ruff/pull/18515
- https://github.com/astral-sh/ruff/pull/18556
- https://github.com/astral-sh/ruff/pull/18555
- https://github.com/astral-sh/ruff/pull/18554
- https://github.com/astral-sh/ruff/pull/18558
- https://github.com/astral-sh/ruff/pull/18561
- https://github.com/astral-sh/ruff/pull/18563
- https://github.com/astral-sh/ruff/pull/18560
- https://github.com/astral-sh/ruff/pull/18559
- https://github.com/astral-sh/ruff/pull/18566
- https://github.com/astral-sh/ruff/pull/18569
- https://github.com/astral-sh/ruff/pull/18565
- https://github.com/astral-sh/ruff/pull/18568
- https://github.com/astral-sh/ruff/pull/18505
- https://github.com/astral-sh/ruff/pull/18517
- https://github.com/astral-sh/ruff/pull/18525
- https://github.com/astral-sh/ruff/pull/18519
- https://github.com/astral-sh/ruff/pull/18524
- https://github.com/astral-sh/ruff/pull/18570
- https://github.com/astral-sh/ruff/pull/18571

### New or improved fixes
### Deferred stabilizations
- https://github.com/astral-sh/ruff/pull/18481
- https://github.com/astral-sh/ruff/pull/18567
- https://github.com/astral-sh/ruff/pull/18557
- https://github.com/astral-sh/ruff/pull/18601
- https://github.com/astral-sh/ruff/pull/18564
  - initially stabilized, but dropped after https://github.com/astral-sh/ruff/issues/18612 and #18614
- https://github.com/astral-sh/ruff/pull/18603
- https://github.com/astral-sh/ruff/pull/18562
  - Dropped after #18628 and #18631
- https://github.com/astral-sh/ruff/pull/18553
  - Dropped after #18675

## TODOs

- [x] Drop ~~empty~~ first commit (random whitespace change to get a baseline ecosystem check executable)
- [ ] Merge with rebase-merge (**don't squash merge!!!!**)

## Tests

<details>
<summary>
Ruff invocations on examples to verify that behavior has been stabilized correctly.
</summary>

```python
# example.py
# ruff: noqa: RUF001 # should trigger RUF100 unused
with open(""file.txt"") as f:
    for line in f.readlines(): # FURB129 safe fix
        ...

arr = [1,2,3]
sliceconcat = arr[1:] + [4,5,6] # RUF005 unsafe fix

from typing import Generic, ParamSpec, TypeVar, TypeVarTuple

U = TypeVar(""U"")
P = ParamSpec(""P"")
Ts = TypeVarTuple(""Ts"")


class C[T](Generic[U, P, *Ts]): ...  # RUF053

from datetime import datetime

date = ""2025-01-01T00:00:00Z""

datetime.fromisoformat(date.replace(""Z"", ""+00:00""))  # FURB162

if cond: # SIM108 fix should suggest `z = cond or other_cond`
    z = cond
else:
    z = other_cond

match x: # unsupported syntax before python 3.10
    case ""a"":
        ...

def foo(a,a): ... # semantic syntax error duplicate parameter names

def bar(a: bool | None): ... # FBT001

import subprocess

subprocess.run(""true"") # should _not_ trigger S603

class GenericClass[_T]:  # UP049
    var: _T

from decimal import Decimal

Decimal(""0"") # FURB157
Decimal(float(""Infinity""))

def decorator():
    pass


@decorator
# fmt: off # RUF028
def example():
    if True:
        # fmt: skip
        expression = [
            # fmt: off
            1,
            2,
        ]
        # yapf: disable
    # fmt: on
    # yapf: enable

def print_python_version():
    import platform # PLC0415

    print(python.python_version())

num = ""0xABC""

if num.startswith(""0b""):
    i = int(num[2:], 2) # FURB166
elif num.startswith(""0o""):
    i = int(num[2:], 8)
elif num.startswith(""0x""):
    i = int(num[2:], 16)

print(i)

class Person: # PLW1641
    def __init__(self):
        self.name = ""monty""

    def __eq__(self, other):
        return isinstance(other, Person) and other.name == self.name


a = round(1, 0) # RUF057

nums = {123, 456}

if 123 in nums: # FURB132
    nums.remove(123)

if x == float(""NaN""):
    pass

def test_foo(a=1): ... # PT028

import pytest


def test_foo_warns():
    with pytest.warns(Warning): # PT031
        setup()  # False negative if setup triggers a warning but foo does not.
        foo()

from pathlib import Path 

with Path(""file"").open(""w"") as f:
    for line in lines:
        f.write(line) # FURB122

with Path(""file"").open(""wb"") as f:
    for line in lines:
        f.write(line.encode())

import pytest


def test_foo():
    with pytest.warns(RuntimeWarning): # PT030
        ...

    # empty string is also an error
    with pytest.warns(RuntimeWarning, match=""""):
        ...

from typing import Optional

foo: Optional[int] = None # UP045 and _not_ UP007

import logging

logging.warning(""Foobar"", exc_info=ValueError(""foo""))  # LOG014

from itertools import starmap

starmap(func, zip(a, b))  # RUF058

from dataclasses import dataclass
from enum import Enum

@dataclass
class E(Enum): ... # RUF049

FRUITS = {""apple"": 1, ""orange"": 10, ""berry"": 22}

for fruit_name, fruit_count in FRUITS.items():
    print(FRUITS[fruit_name]) # PLR1733

def foo(bar,other_cond): # RET503
    if not bar:
        return 1
    if other_cond:
        return 2
```

```console
ruff check example.py --no-cache \
    --select FURB129 \
    --select RUF053 --target-version py312 \
    --select FURB162 \
    --select SIM108 \
    --select RUF100 \
    --select FBT001 \
    --select UP049 \
    --select S603 \
    --select FURB157 \
    --select RUF028 \
    --select PLC0415 \
    --select FURB166 \
    --select PLW1641 \
    --select RUF057 \
    --select FURB132 \
    --select PLW0177 \
    --select PT028 \
    --select PT031 \
    --select FURB122 \
    --select PT031 \
    --select UP045 \
    --select UP007 \
    --select LOG014 \
    --select RUF058 \
    --select RUF049 \
    --select PLR1733 \
    --select RET503
```

Note: Run the above with both `--diff` and `--statistics` to see behavior changes for fixes as well as rule stabilizations (and the stabilization of syntax/semantic errors).

```console
ruff check example.py --no-cache \
    --select RUF005 \
    --target-version py39 \
    --unsafe-fixes
    --diff
```

The below should offer a fix to remove the import:

```console
echo ""from __future__ import annotations"" | ruff check --no-cache --isolated --diff --stdin-filename ex.pyi --select PYI044 -
```

</details>

"
2247136847,3898,Redo should have ⇧⌘Z shortcut like every other Mac app ever created,coreyward,81224,closed,2024-04-17T01:30:49Z,2025-06-26T02:15:01Z,https://github.com/bambulab/BambuStudio,https://github.com/bambulab/BambuStudio/issues/3898,"### Bambu Studio Version

1.8.4.51

### Where is the application from?

Bambu Lab Official website, Bambu Lab github releases

### OS version

macOS

### Additional system information

_No response_

### Printer

X1C

### How to reproduce

1. Perform some operations
2. Hit ⌘Z to undo
3. Try hitting ⇧⌘Z out of muscle memory
4. See app continue to undo rather than redo
5. Use Edit > Redo via mouse repeatedly, only to learn that the undo/redo cache is extremely limited
6. Realize you just lost 20 minutes of fiddly work

### Actual results

⇧⌘Z performs an undo rather than a redo

### Expected results

⇧⌘Z should perform a redo, or at the absolute barest minimum should do nothing. But it is a standard shortcut baked into every Mac app by default, so I don't understand why Bambu has seen fit to change it to ⌘Y of all things…the only thing I know if it being used for is open history in web browsers.

### Project file & Debug log uploads

N/A

### Checklist of files to include

- [ ] Log file
- [ ] Project file"
3090683671,2665,computer controller is unable to run basic scripts (shell),michaelneale,14976,closed,2025-05-26T10:12:22Z,2025-05-28T05:08:47Z,https://github.com/block/goose,https://github.com/block/goose/issues/2665,"If you setup goose with just CC on, and as it to look at files in a directory, it will encounter permission errors on the script it writes which causes it to thrash unnecessarily. Most people have developer on default so unlikely to use it. 

This often could be avoided as well by having directory and file read tool available (as an option). "
3087709748,47,[Feature]: SPM support,GLinnik21,23104281,closed,2025-05-23T23:19:52Z,2025-06-04T20:42:54Z,https://github.com/cameroncooke/XcodeBuildMCP,https://github.com/cameroncooke/XcodeBuildMCP/issues/47,"### Feature Description

The Xcode Build MCP currently supports building `.xcodeproj` and `.xcworkspace` files, but doesn't have direct support for building Swift Package Manager packages using `swift build` commands.

## Current Behavior

When attempting to build an SPM package (e.g., a project with `Package.swift`), users need to:
1. Either use the automatically generated `.swiftpm/xcode/package.xcworkspace` (which can be unreliable)
2. Or fall back to using standard terminal commands like `swift build`

## Error Encountered

When trying to use `list_schems_ws` on an SPM-generated workspace (`.swiftpm/xcode/package.xcworkspace`), we encountered:

```
** INTERNAL ERROR: Unable to load workspace '/path/to/.swiftpm/xcode/package.xcworkspace' **
Uncaught Exception: -[Swift.__SwiftDeferredNSArray intersectsSet:]: unrecognized selector sent to instance
```

## Suggested Implementation

The implementation could wrap `swift build`, `swift test`, and other Swift Package Manager commands, similar to how the current MCP wraps `xcodebuild` commands.

### Use Cases

- **Building Swift Package Manager libraries and frameworks**
- **Testing SPM packages across multiple platforms (iOS, macOS, tvOS, watchOS)**
- **Integrating SPM packages into CI/CD pipelines**
- **Developing modular Swift codebases with multiple SPM packages**
- **Building command-line tools and server-side Swift applications**

### Example Interactions

You: ""Build the Library SPM package for macOS""
AI: Uses `build_spm_package` to execute `swift build --target Library --platform macos`

You: ""Run tests for my networking package on iOS simulator""  
AI: Uses `test_spm_package_ios_sim` to execute `swift test --target NetworkingTests --destination 'platform=iOS Simulator,name=iPhone 15'`

You: ""Clean and rebuild my SPM package with release configuration""
AI: Uses `clean_spm_package` then `build_smp_package --configuration release`

You: ""Check if my SPM package builds for all supported platforms""
AI: Uses `build_spm_package_multiplatform` to test builds across iOS, macOS, tvOS, watchOS

You: ""Generate and build documentation for my SPM package""
AI: Uses `generate_spm_docs` to execute `swift package generate-documentation`

This would make the feature request more comprehensive and show the practical value for Swift developers working with SPM packages."
3095162459,1593,Support Entra ID groups,achantavy,46503781,closed,2025-05-27T20:42:33Z,2025-06-09T20:39:15Z,https://github.com/cartography-cncf/cartography,https://github.com/cartography-cncf/cartography/issues/1593,"**Feature request template**

*Title*: *Add support for Entra ID groups*

*Description*:
> Describe your idea.  Please be detailed.  If a feature request, please
describe the desired behavior, what scenario it enables, and how it
would be used.

We should add support for Entra ID groups.

Definition of done: 
- we have a list of all groups in an entra ID tenant
- we have a mapping of all groups to entra ID users

[optional *Relevant Links*:]
> Any extra documentation required to understand the issue.

API docs: https://learn.microsoft.com/en-us/graph/api/resources/group?view=graph-rest-1.0

"
3131515168,1617,Add AGENTS.md to make cartography more editable by agents,achantavy,46503781,closed,2025-06-09T21:17:58Z,2025-06-09T21:37:15Z,https://github.com/cartography-cncf/cartography,https://github.com/cartography-cncf/cartography/pull/1617,"I, for one, welcome our new robot overlords.

### Summary
> Describe your changes.

Adds an AGENTS.md file to make cartography more easily editable by AI coding assistants.

https://github.com/cartography-cncf/cartography/pull/1614 is an example of a PR that was created in 1 or 2 steps with an AI agent.

OpenAI Codex should pick up on this automatically. For other agents you may need to reference this file explicitly."
3131618459,1618,feat: Add nested Entra group support,achantavy,46503781,closed,2025-06-09T22:19:43Z,2025-06-10T23:03:40Z,https://github.com/cartography-cncf/cartography,https://github.com/cartography-cncf/cartography/pull/1618,"### Summary
- Support nested groups in Entra ingestion
- Add EntraGroup->EntraGroup relationship
- Document nested group relationship
- Update tests for nested groups



### Related issues or links
> Include links to relevant issues or other pages.

- Follow-up of https://github.com/cartography-cncf/cartography/pull/1614: we support groups of groups now.

### Checklist

Provide proof that this works (this makes reviews move faster). Please perform one or more of the following:
- [x] Update/add unit or integration tests.
- [x] Include a screenshot showing what the graph looked like before and after your changes.

Groups of groups:
![Screenshot 2025-06-09 at 5 25 55 PM](https://github.com/user-attachments/assets/a6f718f9-2332-4799-9fd6-057acbc941cd)


And in Entra it looks like:
![Screenshot 2025-06-09 at 5 26 31 PM](https://github.com/user-attachments/assets/dc127398-8945-4b3a-b911-8c30125e88da)
![Screenshot 2025-06-09 at 5 26 42 PM](https://github.com/user-attachments/assets/8316c43d-4a1e-4f54-984b-559cf664392c)

- [x] Include console log trace showing what happened before and after your changes.

```
INFO:cartography.sync:Starting sync with update tag '1749516786'
INFO:cartography.sync:Starting sync stage 'entra'
INFO:cartography.intel.entra.users:Loading 6 Entra users
INFO:cartography.graph.statement:Completed EntraUser statement #1
INFO:cartography.graph.statement:Completed EntraUser statement #2
INFO:cartography.graph.job:Finished job EntraUser
INFO:cartography.intel.entra.groups:Loading 6 Entra groups
INFO:cartography.graph.statement:Completed EntraGroup statement #1
INFO:cartography.graph.statement:Completed EntraGroup statement #2
INFO:cartography.graph.statement:Completed EntraGroup statement #3
INFO:cartography.graph.statement:Completed EntraGroup statement #4
INFO:cartography.graph.job:Finished job EntraGroup
INFO:cartography.intel.entra.ou:Loading 0 Entra OUs
INFO:cartography.graph.statement:Completed EntraOU statement #1
INFO:cartography.graph.statement:Completed EntraOU statement #2
INFO:cartography.graph.job:Finished job EntraOU
INFO:cartography.sync:Finishing sync stage 'entra'
INFO:cartography.sync:Finishing sync with update tag '1749516786'
```

If you are changing a node or relationship:
- [x] Update the [schema](https://github.com/cartography-cncf/cartography/tree/master/docs/root/modules) and [readme](https://github.com/cartography-cncf/cartography/blob/master/docs/schema/README.md).

If you are implementing a new intel module:
- [x] Use the NodeSchema [data model](https://cartography-cncf.github.io/cartography/dev/writing-intel-modules.html#defining-a-node).


"
3131818307,1621,fix: Remove unused SQS test variable,achantavy,46503781,closed,2025-06-10T00:36:17Z,2025-06-10T00:44:38Z,https://github.com/cartography-cncf/cartography,https://github.com/cartography-cncf/cartography/pull/1621,"Fast follow of #1619

"
3168978338,1648,chore: Remove manual ECS indexes,achantavy,46503781,closed,2025-06-23T17:53:57Z,2025-06-23T18:43:34Z,https://github.com/cartography-cncf/cartography,https://github.com/cartography-cncf/cartography/pull/1648,"### Summary
> Describe your changes.

Fast follow of #1620. Forgot to remove the unneeded indexes now.


### Checklist

Provide proof that this works (this makes reviews move faster). Please perform one or more of the following:
- [ ] Update/add unit or integration tests.
- [ ] Include a screenshot showing what the graph looked like before and after your changes.
- [ ] Include console log trace showing what happened before and after your changes.

If you are changing a node or relationship:
- [ ] Update the [schema](https://github.com/cartography-cncf/cartography/tree/master/docs/root/modules) and [readme](https://github.com/cartography-cncf/cartography/blob/master/docs/schema/README.md).

If you are implementing a new intel module:
- [ ] Use the NodeSchema [data model](https://cartography-cncf.github.io/cartography/dev/writing-intel-modules.html#defining-a-node).
"
3158465046,1317,Fix describe stacks StringSlice flags,osterman,52489,open,2025-06-18T23:49:22Z,,https://github.com/cloudposse/atmos,https://github.com/cloudposse/atmos/pull/1317,"## Summary
- parse `--components`, `--component-types`, and `--sections` as string slices
- replicate panic when slice flags are defined as strings in a unit test
- document the need to run `go build` before tests

------
https://chatgpt.com/codex/tasks/task_b_6852e5346c7483329a2a810e0d733569

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Enhanced command-line flags for stack description to accept multiple values for components, component types, and sections.

- **Bug Fixes**
  - Improved test coverage and error handling for flag parsing, ensuring correct behavior when using multi-value flags.

- **Documentation**
  - Added guidance to build the project before running Go tests.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
2951600353,34945,torqued: expose learning state in the ui,sshane,25857203,closed,2025-03-27T05:14:38Z,2025-06-10T08:48:47Z,https://github.com/commaai/openpilot,https://github.com/commaai/openpilot/issues/34945,"This is for [torqued](https://github.com/commaai/openpilot/blob/master/selfdrive/locationd/torqued.py)

Should explore something like the calibration button (but without reset) or an offroad alert until it's calibrated. Offroad alert might be too intrusive, but it makes sense if lateral performance is degraded until it's completed which is the case with Rivians"
3071970309,35271,system/ui: support resizable window,incognitojam,4038174,closed,2025-05-18T18:19:10Z,2025-05-18T23:11:03Z,https://github.com/commaai/openpilot,https://github.com/commaai/openpilot/pull/35271,useful when your monitor resolution is less than a three...
2913150944,670,Support new OpenAI Responses API,franboladoruiz,167551574,open,2025-03-12T08:30:02Z,,https://github.com/davidmigloz/langchain_dart,https://github.com/davidmigloz/langchain_dart/issues/670,"### Feature Request

OpenAI has released a new Responses API that is meant to eventually replace the completions and assistant APIs.

- https://platform.openai.com/docs/quickstart?api-mode=responses
- https://openai.com/index/new-tools-for-building-agents

### Motivation

This API is supposed to become the new standard API to consume OpenAI's models.

### Your contribution

I can help with testing. "
3004275946,696,SettingToolChoice Required causes Infinite Loop,jbienzss,149444736,closed,2025-04-18T07:33:05Z,2025-06-15T20:41:38Z,https://github.com/davidmigloz/langchain_dart,https://github.com/davidmigloz/langchain_dart/issues/696,"### Package

openai_realtime_dart

### Reproduction

Steps:

1. Add a tool to call with `client.addTool`
2. Have the tool return a value (I returned an empty map `{}`)
3. Call `updateSession` and set 
        ```toolChoice: SessionConfigToolChoice.mode(
             SessionConfigToolChoiceMode.required
        )```
4. When calling `connect` specify `model: 'gpt-4o-mini-realtime-preview'`

Run the app. After the first message is sent the tool will be called repeatedly. I don't know if setting the model matters. This seems to be about `SessionConfigToolChoiceMode.required`.

### Current behavior

Tool is called indefinitely

### Expected behavior

Tool would only be called once per user message at most.

### Your contribution

I can repro and I am happy to help troubleshoot, but I haven't been able to determine the root cause so far."
3097762983,2697,fix: incrementally watch files,zilto,68975210,closed,2025-05-28T15:24:37Z,2025-05-30T07:55:22Z,https://github.com/dlt-hub/dlt,https://github.com/dlt-hub/dlt/pull/2697,"This is a fork of #2691. Please pull the branch and validate it works on your end!

"
129718146,1557,"Support authentication agents for SSH, like Pageant",kenkendk,1510755,closed,2016-01-29T09:53:32Z,2025-06-03T17:43:46Z,https://github.com/duplicati/duplicati,https://github.com/duplicati/duplicati/issues/1557,"There should be a full implementation here, just a matter of adding it:
https://github.com/dimov-cz/win-sshfs/commit/8eb20b34ec27c430cf3d235fb588ed4aa71a937f
"
3082879805,4705,chore: centralise env resolution further,wtfsayo,82053242,closed,2025-05-22T10:26:51Z,2025-05-22T16:00:11Z,https://github.com/elizaOS/eliza,https://github.com/elizaOS/eliza/pull/4705,"

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Introduced new utilities for resolving environment files and database directories, improving consistency across the project.

- **Refactor**
  - Updated default data directory for local databases from `.pglite` to `.elizadb` throughout the application and documentation.
  - Centralized and streamlined environment and path resolution, making directory management project-relative instead of user home-relative.
  - Simplified and unified server and database initialization logic for improved modularity.
  - Enhanced template resolution in development environments by detecting monorepo roots for more reliable path handling.
  - Replaced synchronous environment loading with asynchronous flows for improved startup and test execution.

- **Bug Fixes**
  - Enhanced handling of environment variable and data directory resolution to prevent misconfiguration.
  - Added precondition checks in tests to skip when required model files are missing.

- **Documentation**
  - Updated documentation to reflect the new default database directory and improved configuration instructions.

- **Chores**
  - Adjusted ignore patterns to exclude new database directories and environment files at any depth.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3126830621,4987,fix: resolve env command interactive mode and flag inconsistencies,yungalgo,113615973,closed,2025-06-07T10:30:18Z,2025-06-07T17:53:20Z,https://github.com/elizaOS/eliza,https://github.com/elizaOS/eliza/pull/4987,"### Problem

Three critical issues in `elizaos env` command causing unreliable environment management:

1. **Infinite Loop**: `elizaos env interactive -y` loops forever, requiring Ctrl+C to exit
2. **Flag Logic Bug**: `elizaos env list --local` shows system info when it should only display local variables
3. **Inconsistent -y Behavior**: `edit-local -y` prompts for input instead of auto-confirming like `reset -y`

### Solution

**Interactive Mode (-y flag handling)**

- Interactive mode now ignores `-y` flag since it requires user input by design
- Removed problematic auto-execution logic that caused infinite loops

**List --local Flag Fix**

- Fixed conditional logic to show ONLY local environment variables
- Removed system information display when `--local` flag is used
- Improved error handling for missing .env files

**Edit-local -y Standardization**

- `-y` flag now displays current variables and exits gracefully
- Consistent with other commands - no interactive prompts when `-y` specified
- Auto-skips variable addition prompts in non-interactive mode

### Implementation Details

**Files Changed:**

- `packages/cli/src/commands/env.ts` - Core logic fixes
- `packages/docs/docs/cli/env.md` - Documentation updates

**Key Changes:**

- `showMainMenu()`: Removed conditional `-y` logic, always prompts user
- `editEnvVars()`: Added early exit for `-y` flag, updated `addNewVariable()` signature
- `addNewVariable()`: Added `yes` parameter to skip prompts in auto-confirm mode
- List command: Fixed `--local` conditional to exclude system information

**Testing:**

- All existing tests pass
- Fixes verified against reported issue scenarios
- No breaking changes to existing functionality

### Expected Behavior After Fix

```bash
# No longer loops infinitely - prompts user normally
elizaos env interactive -y

# Shows ONLY local variables, no system info
elizaos env list --local

# Displays variables and exits cleanly
elizaos env edit-local -y
```


<!-- This is an auto-generated comment: release notes by coderabbit.ai -->

## Summary by CodeRabbit

- **New Features**
	- Added support for a `--yes` flag to environment variable editing and listing commands, enabling auto-confirm mode to bypass interactive prompts.
- **Improvements**
	- Enhanced handling of local environment variable listing, providing clearer output and better management of missing files.
- **Documentation**
	- Updated documentation to clarify the behavior of the `--yes` flag in environment commands, including new notes and revised examples.

<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3071594172,6651,RabbitMQ Quorum Queue configuration - Fatal production erros,arnoldsi-payo,117906652,closed,2025-05-18T09:24:51Z,2025-05-20T09:53:21Z,https://github.com/elsa-workflows/elsa-core,https://github.com/elsa-workflows/elsa-core/issues/6651,"Our organization moved to RabbitMQ Quorum Queues. This change lead to an error creating queues.
It's not throwing any errors, It's just endless loop:

```
DT: 2025-05-18 12:04:45.8624 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 14 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Bind queue: source: 333b9515-elsa-dispatch-cancel-workflow, destination: 333b9515-elsa-dispatch-cancel-workflow
DT: 2025-05-18 12:05:17.2164 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 3 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare queue: name: 333b9515-elsa-dispatch-cancel-workflow, x-expires: 3600000, consumer-count: 0 message-count: 0
DT: 2025-05-18 12:05:17.2354 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 3 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare exchange: name: 333b9515-elsa-dispatch-cancel-workflow, type: fanout, auto-delete
DT: 2025-05-18 12:05:17.2354 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 3 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare exchange: name: Payoneer.DocumentProcessingCenterElsaWorkflows:Elsa.Workflows.Runtime.Requests:DispatchCancelWorkflowsRequest, type: fanout, durable
DT: 2025-05-18 12:05:17.3811 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 3 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Bind queue: source: 333b9515-elsa-dispatch-cancel-workflow, destination: 333b9515-elsa-dispatch-cancel-workflow
DT: 2025-05-18 12:05:48.7472 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 7 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare queue: name: 333b9515-elsa-dispatch-cancel-workflow, x-expires: 3600000, consumer-count: 0 message-count: 0
DT: 2025-05-18 12:05:48.7722 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 7 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare exchange: name: 333b9515-elsa-dispatch-cancel-workflow, type: fanout, auto-delete
DT: 2025-05-18 12:05:48.7722 | LV: Debug | CID:  | VSID:  | REF:  | xFor:  | CSys:  | PID: 179700 | TID: 7 | AHID:  | SRC: MassTransit.LogContext.Define | Msg: Declare exchange: name: Payoneer.DocumentProcessingCenterElsaWorkflows:Elsa.Workflows.Runtime.Requests:DispatchCancelWorkflowsRequest, type: fanout, durable

```

Quorum Queues does not support 'auto-delete'.

MassTransit has configuration for Quorum Queues:

https://masstransit.io/documentation/configuration/transports/rabbitmq#quorum-queues

Expected behaviour:
 - Elsa masstransit abstraction should expose queue configurations
"
3137158067,16379,interop: supervisor <> op-node mode renaming,tynes,6626818,closed,2025-06-11T14:56:58Z,2025-06-23T09:29:17Z,https://github.com/ethereum-optimism/optimism,https://github.com/ethereum-optimism/optimism/issues/16379,This ticket represents the renaming of the supervisor <> node mode renaming per [here](https://oplabs.notion.site/Supervisor-Mode-Naming-Convention-20df153ee16280649630c3a55850d906). The previous names consistently confused people and the new names exist to make it easier to understand what is going on. All mentions of managed mode should be replaced with indexing mode
3165353913,1653,test-suite(ast-builder::schemaless): add basic schemaless ast-builder test,chae401,83829352,closed,2025-06-21T19:29:52Z,2025-06-23T13:46:23Z,https://github.com/gluesql/gluesql,https://github.com/gluesql/gluesql/pull/1653,"
- Create schemaless table
- Insert JSON-formatted records
- SELECT * returns Payload::SelectMap and verifies record contents
- DELETE row and re-SELECT to confirm deletion
- DROP TABLE and verify cleanup"
2371011347,276,"Editing task, esc key should close the modal",cortl,7924611,closed,2024-06-23T18:22:12Z,2025-06-12T11:34:21Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/issues/276,"When a task is opened `/tasks/n`, the escape key should close the modal and return to the previous page."
3003061953,677,Editor URL Link should not extend beyond current word,nebula-it,40148908,closed,2025-04-17T17:22:20Z,2025-06-10T19:09:15Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/issues/677,"### Description

In the editor(both main body and comments) of task, if you add a hyperlink to a word by selecting the word and then pasting using `Ctrl+V` and then hitting the `space` and typing next word, the next words are hyperlinked as well. Which is not ideal the hyperlink should be dropped from formatting once you hit `space`.

### Vikunja Version

v0.24.6

### Browser and version

_No response_

### Can you reproduce the bug on the Vikunja demo site?

Yes

### Screenshots

_No response_"
3126755288,891,fix(frontend): mark only clicked task item,dpschen,6173598,closed,2025-06-07T09:16:56Z,2025-06-16T20:43:54Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/pull/891,
3126934524,896,Database path should follow `service.rootpath`,eirnym,485399,closed,2025-06-07T12:09:22Z,2025-06-13T07:16:26Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/issues/896,"### Description

At the moment database path set to `./vikunja.db` and doesn't follow `service.rootpath` as other parts do.

### Vikunja Version

530fe4cef

### Browser and version

_No response_

### Can you reproduce the bug on the Vikunja demo site?

Yes

### Screenshots

_No response_"
3139773585,929,Fix Sass import deprecation warnings,kolaente,13721712,closed,2025-06-12T10:46:44Z,2025-06-12T10:49:11Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/pull/929,"## Summary
- replace deprecated `@import` usage with `@use` or `@forward` in front-end Sass files

## Testing
- `pnpm lint:fix`

------
https://chatgpt.com/codex/tasks/task_e_684881d0a728832293b5a0da388c235f"
3150537935,962,fix: set default timezone when placeholder used,dpschen,6173598,open,2025-06-16T16:06:08Z,,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/pull/962,I guess this is just convenience. But foremost the DX should be fixed for this.
3174712935,1019,chore(deps): upgrade to Tailwind 4,kolaente,13721712,closed,2025-06-25T08:26:37Z,2025-06-25T08:29:39Z,https://github.com/go-vikunja/vikunja,https://github.com/go-vikunja/vikunja/pull/1019,"Closes https://github.com/go-vikunja/vikunja/pull/468

## Summary
- import global styles in main entry
- drop inline import in `App.vue`
- switch tailwind config to ESM
- try configuring vite plugin for tailwind

## Testing
- `pnpm lint:fix`

------
https://chatgpt.com/codex/tasks/task_e_6849cd0e23d4832294423351b68925cb"
552661167,1,[1.0.0-pre-release] c.SaveFile undefined ,cheft,1567209,closed,2020-01-21T06:59:00Z,2020-01-21T08:16:57Z,https://github.com/gofiber/fiber,https://github.com/gofiber/fiber/issues/1,c.SaveFile undefined (type *fiber.Ctx has no field or method SaveFile)
552664185,2,[1.0.0-pre-release]c.Attachment download file is 0 byte,cheft,1567209,closed,2020-01-21T07:07:04Z,2020-01-21T08:11:31Z,https://github.com/gofiber/fiber,https://github.com/gofiber/fiber/issues/2,"Use `c.Attachment(""./test.txt"")`, the download file is 0 bytes.

The source file has content, but the download does not

```go
app.Get(""/files/test"", func(c *fiber.Ctx) {
  c.Attachment(""./test.txt"")
})
```"
2960699755,3385,📝 [Proposal]: Fiber Security Package,gaby,835733,closed,2025-03-31T14:37:30Z,2025-05-24T21:01:54Z,https://github.com/gofiber/fiber,https://github.com/gofiber/fiber/issues/3385,"### Feature Proposal Description

Common security things like getting `api-key` from a header, query, or cookie rely on the user implementing this. Proposal is to implement these to make it easier for users to add security to their API/Apps. This would be similar to `fastapi.Security` package. See here: https://fastapi.tiangolo.com/reference/security/

We already cover some of these via the `BasicAuth` middleware. At a minimum we should natively provide these to users:
   - APIKeyCookie
   - APIKeyHeader
   - APIKeyQuery
   - HTTPAuthorizationCredentials
   - HTTPBasic
   - HTTPBasicCredentials
   - HTTPBearer
   - HTTPDigest

Each one can be done as a separate PR.

### Alignment with Express API

N/a

### HTTP RFC Standards Compliance

N/a

### API Stability

N/a

### Feature Examples

```go
N/a
```

### Checklist:

- [x] I agree to follow Fiber's [Code of Conduct](https://github.com/gofiber/fiber/blob/master/.github/CODE_OF_CONDUCT.md).
- [x] I have searched for existing issues that describe my proposal before opening this one.
- [x] I understand that a proposal that does not meet these guidelines may be closed without explanation."
3119785304,3503,🧹 chore: Add upper index limit for parsers,gaby,835733,closed,2025-06-05T04:21:05Z,2025-06-10T06:45:49Z,https://github.com/gofiber/fiber,https://github.com/gofiber/fiber/pull/3503,"## Summary
- Add upper limit to parsed indexes to 1000
- distinguish index overflow from invalid path
- Update tests for new limit
- make proxy middleware tests work offline
"
3134983349,3514,🧹 [Maintenance]: Enhanced Timeout Middleware Configuration,Andrei-hub11,83555334,open,2025-06-10T22:30:15Z,,https://github.com/gofiber/fiber,https://github.com/gofiber/fiber/issues/3514,"### Maintenance Task Description

## Summary

Add configurable timeout middleware with per-route timeouts, path exclusions, and custom timeout handlers while maintaining full backward compatibility.

## Motivation

Current timeout middleware limitations:
- Global timeout for all routes
- Cannot skip specific paths (health checks, uploads)
- Fixed timeout response
- No per-route timeout configuration

## Proposed Solution

Add `NewWithConfig` function following Fiber's established middleware patterns:

```go
type Config struct {
    // Next defines a function to skip this middleware
    Next      func(c fiber.Ctx) bool
    
    // Timeout defines the default timeout duration
    Timeout   time.Duration
    
    // OnTimeout is called when a timeout occurs
    OnTimeout fiber.Handler
    
    // SkipPaths defines paths that should ignore timeout
    SkipPaths []string
    
    // PerRoute allows specific timeouts per route
    PerRoute  map[string]time.Duration
}

func NewWithConfig(config Config) fiber.Handler
```

## Usage Examples

### Basic Configuration
```go
app.Use(timeout.NewWithConfig(timeout.Config{
    Timeout: 30 * time.Second,
}))
```

### Per-Route Timeouts
```go
app.Use(timeout.NewWithConfig(timeout.Config{
    Timeout: 5 * time.Second,
    PerRoute: map[string]time.Duration{
        ""/api/reports"": 30 * time.Second,
        ""/api/uploads"": 60 * time.Second,
    },
}))
```

### Skip Specific Paths
```go
app.Use(timeout.NewWithConfig(timeout.Config{
    Timeout: 5 * time.Second,
    SkipPaths: []string{""/health"", ""/metrics"", ""/webhook""},
}))
```

### Custom Timeout Response
```go
app.Use(timeout.NewWithConfig(timeout.Config{
    Timeout: 5 * time.Second,
    OnTimeout: func(c fiber.Ctx) error {
        return c.Status(408).JSON(fiber.Map{
            ""error"": ""Request timeout"",
            ""path"":  c.Path(),
        })
    },
}))
```

## Benefits

- **Flexible**: Per-route timeout configuration
- **Production-ready**: Skip health checks and monitoring endpoints
- **User-friendly**: Custom timeout responses with context
- **Backward compatible**: Existing `New()` function unchanged

## Implementation

- Uses goroutines for asynchronous request processing
- Context-based timeout management with `context.WithTimeout`
- Zero breaking changes to existing API

## Backward Compatibility

✅ All existing `timeout.New()` calls work unchanged  
✅ Can be adopted incrementally  
✅ Follows same patterns as other Fiber middlewares (CORS, Logger)  

---

### Impact on the Project


This enhancement significantly increases the usefulness of the timeout middleware without introducing any breaking changes, bringing the following positive impacts:

- Greater flexibility in request timeout control, better suited to real-world production scenarios.
- Reduces the need for external workarounds or duplicated logic in handlers.
- Helps improve application stability and predictability, especially for public APIs with high-latency endpoints.
- Lays the groundwork for future improvements, such as dynamic timeouts based on headers or context.
-  Keeps existing tests intact and adds coverage for new cases without interfering with the current API.

This change aligns with Fiber’s design philosophy and should be easy for the community to adopt.


### Additional Context (optional)

Implementation is ready with full tests and documentation. Happy to submit a PR if this approach looks good! 🙏

### Checklist:

- [x] I have confirmed that this maintenance task is currently not being addressed.
- [x] I understand that this task will be evaluated by the maintainers and prioritized accordingly.
- [x] I am available to provide further information if needed."
3147810001,1849, feat: add OnStart hook to run synchronous jobs before server starts,HeerakKashyap,175127332,closed,2025-06-15T16:56:06Z,2025-06-17T09:41:22Z,https://github.com/gofr-dev/gofr,https://github.com/gofr-dev/gofr/pull/1849,"**Concise explanation:**

This PR adds a new OnStart hook feature to the GoFr framework, allowing users to register and run synchronous jobs before the server starts serving requests.
Issue addressed:
Addresses issue #1833  Support to run a synchronous Job on app start.
Motivation & benefits:
Enables initialization tasks (e.g., in-memory cache, API calls, pre-loading data) to be performed before the app begins handling traffic, improving reliability and flexibility for microservice developers.


**Breaking Changes :**
No breaking changes are introduced by this PR.
The new feature is fully backward compatible and opt-in.

**Additional Information:**
No new dependencies or external libraries were added.

Example usage:
![image](https://github.com/user-attachments/assets/7c9a6d98-ef93-418b-b143-77c98ca522ff)
All startup hooks are executed in order before the server starts. If any hook returns an error, the app logs the error and exits.

**Checklist:**

 I have formatted my code using goimports and golangci-lint.
 All new code is covered by unit tests.
 This PR does not decrease the overall code coverage.
 I have reviewed the code comments and documentation for clarity.

   Fixes #1833"
2229718025,57,Don't panic when headless,daonb,36852,closed,2024-04-07T11:13:29Z,2025-06-07T10:23:26Z,https://github.com/golang-design/clipboard,https://github.com/golang-design/clipboard/issues/57,"I've just added you're excellent package to my project and it works great on my arm mac.
When I try to run my docker compose based tests it fails to compile:

```
clipboard_linux.c:15:10: fatal error: X11/Xlib.h: No such file or directory
   15 | #include <X11/Xlib.h>
        |          ^~~~~~~~~~~~
 compilation terminated.
```

Makes sense - containers don't have X. I've tried disabling CGO and got in run time:

```
 panic: clipboard: cannot use when CGO_ENABLED=0
 ```
 
It's clear the package can't do anything on a system with no clipboard, but IMHO it should be able to compile and return an error on all calls, leaving it to the calling program to handle. Like in my program's, where I want to use an environment variable as the clipboard storage so I can run and validate clipboard related tests.

"
2475046213,62,Update Go Dependencies to fix Security Vulnerabilities,yschiebelhut,26283224,closed,2024-08-20T08:34:56Z,2025-06-07T10:44:26Z,https://github.com/golang-design/clipboard,https://github.com/golang-design/clipboard/pull/62,Especially `golang.org/x/image` had a few security vulnerabilities fixed. This PR updates the go libraries to the latest available version while not bumping major versions. Update was performed via Renovate and not checked otherwise.
1965575726,15,Auto-name conversations,ErikBjare,1405370,open,2023-10-27T13:48:26Z,,https://github.com/gptme/gptme,https://github.com/gptme/gptme/issues/15,"We can already give conversations a name automatically with `/rename auto` but this should be improved:

 - [x] Name conversation automatically with `/rename auto`
 - [ ] Don't include date in conversation name, fetch from file/message timestamps.
    - Filesystem metadata not very reliable for this type of thing, but message timestamps are now stored, so should use them. 
 - [ ] Run automatically on save? (if name not already set)
    - https://github.com/ErikBjare/gptme/pull/449
      - This will probably not work for gptme-server, the webui wouldn't get notice of the rename. 
         - Needs special logic, maybe set an ""auto"" name when we first create a conversation name? Or detect/redirect renames?
      - A different approach would be to not rename the conversation folder names at all, instead keep them as unique IDs and add a (auto-)settable ""name"" field in the conversation metadata."
3101160739,358,[Grida Canvas] Daily RC,softmarshmallow,16307013,closed,2025-05-29T18:34:29Z,2025-05-30T08:57:26Z,https://github.com/gridaco/grida,https://github.com/gridaco/grida/pull/358,"- https://github.com/gridaco/grida/pull/357
- https://github.com/gridaco/grida/pull/360
- https://github.com/gridaco/grida/pull/359

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Introduced a fully styled, accessible Select dropdown UI component with customizable options and improved composability.
  - Added a new default behavior for rotation quantization, allowing rotation to be quantized by 1 degree.
  - Implemented edge scrolling, enabling the canvas to auto-scroll when dragging near the viewport edge.

- **Improvements**
  - Scene duplication now fully clones all child nodes, preserving the entire scene structure.
  - Rotation quantization step is now configurable for finer control over rotation gestures.
  - Enhanced image insertion to automatically detect and use the image's natural dimensions.
  - Extended grouping and containment behavior to properly handle root-level nodes in scenes with multiple root children.

- **UI/Style**
  - Updated combobox and context menu styling for better alignment, truncation, and visual consistency.
  - Refined Select and font size controls for improved usability and appearance.
  - Wrapped canvas UI with a global editor context provider to enhance editor state management.

- **Documentation**
  - Updated feature documentation to reflect new rotation quantization and edge scrolling behaviors.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3141013291,1271,abs (absolute value) should simplify in the alternatives,acoustoelectrically,215733403,open,2025-06-12T17:06:05Z,,https://github.com/herbie-fp/herbie,https://github.com/herbie-fp/herbie/issues/1271,"If you have a variable in an absolute value, herbie can generate an alternative that is the absolute value of a number.. It should probably simplify:

https://herbie.uwplse.org/demo/1e8980063f2d6dc28030cdc4e732bb76c4ad6650.1a83c9f5186db102b678a2d5f869f99992469071/graph.html (alternative 2 is |1|, and it should probably say 1)

https://herbie.uwplse.org/demo/bb8b662d59fb402c35febc9b302f326857e24d11.1a83c9f5186db102b678a2d5f869f99992469071/graph.html (alternative 2 is |2|, and it should probably say 2)

https://herbie.uwplse.org/demo/3ed24e72cb5faf489dff1722934507f9aaa13c8b.1a83c9f5186db102b678a2d5f869f99992469071/graph.html (alternative 2 is |1|, and it should probably say 1)

https://herbie.uwplse.org/demo/fb2ef1594b789063080c7a48d8adf005ae233979.1a83c9f5186db102b678a2d5f869f99992469071/graph.html (alternative 4 says |1|, and it should probably say 1)

However, when putting in just abs(1) and abs(2) as the initial expression, the expressions simplify to 1 and 2. This doesn't happen with sqrt() or cbrt()"
2547129270,1635,Adding many AddedTokens makes loading a tokenizer extremely slow.,stephantul,8882233,open,2024-09-25T07:04:26Z,,https://github.com/huggingface/tokenizers,https://github.com/huggingface/tokenizers/issues/1635,"Hi!

I'm not sure if this is a problem that can be solved, or needs to be solved. Basically, we want to make a kind of hybrid tokenizer, in which we add a whole bunch of whole words to a tokenizer, and select these words instead of the subwords if they appear. 

For example: if we pass the pretokenized string `[""dog"", ""walks"", ""around"", ""Paris""]`, and ""Paris"" is a whole token, we want to select it instead of decomposing it into subtokens. I think that adding `Paris` as an `AddedToken` is the right approach for this (but please correct me if I'm wrong.)

So, we added many of these tokens (about 400k), but this makes loading a tokenizer extremely slow, like, it takes 15-30 minutes to load. We now add them as regular tokens, which works fine, but which has the downside of also finding these whole word tokens as part of other words. For example `Parisians` will now be turned into `[""Paris"", ""##ians""]`, which might have a different meaning.

So my main question is: is there a reason why adding many `AddedToken`s is slow? Or is this just a path that hasn't been fully optimized yet? 

Is using `AddedToken`s in this way simply wrong? Should we be trying something else?

Thanks!
Stéphan"
2558614776,467,[Feature request] Allow to use MathJax instead of KaTex,CHN-beta,35858462,closed,2024-10-01T09:00:26Z,2025-06-14T13:36:11Z,https://github.com/imfing/hextra,https://github.com/imfing/hextra/issues/467,"**Feature Description**

MathJax is another widely used library for rendering LaTeX in the browser.
It supports a wider range of LaTeX commands than KaTeX, such as `physics` package (which is useful in physics and engineering), with the trade-off of being more resource-intensive.
It is a good idea to support both libraries, so that users can choose the one that best fits their needs.

**Problem/Solution**

Add an option to choose between KaTeX and MathJax for rendering LaTeX in the browser.

Integrate MathJax into hugo site seems not very hard, see [hugo official doc](https://gohugo.io/content-management/mathematics/) and [mathjax official doc](https://www.mathjax.org/#gettingstarted).
Sadly I am not familiar with javascript and hugo development, so I can't provide a PR for this feature.

**Additional Context**

MathJax seems to be usually running on the client side, but KaTeX seems usually running on the server side.
I am not sure if this makes any difficulty to integrate MathJax into hextra.
"
3092053558,389,Investigate performence drop,janbjorge,16663421,closed,2025-05-26T21:03:06Z,2025-06-27T06:28:46Z,https://github.com/janbjorge/pgqueuer,https://github.com/janbjorge/pgqueuer/issues/389,"Investigate a significant performance drop w/asyncpg.

![Image](https://github.com/user-attachments/assets/f804969f-5053-479b-a515-aa9f54733896)"
3070283805,487,`request.app.state.mcp_server` is not set in Starlette app created by `FastMCP.http_app`,sooperset,32061883,closed,2025-05-17T03:55:47Z,2025-05-17T15:48:27Z,https://github.com/jlowin/fastmcp,https://github.com/jlowin/fastmcp/issues/487,"### Description

When creating an HTTP-based server (using `streamable-http` or `sse` transport) via `FastMCP.http_app()`, the `FastMCP` server instance is not stored in the resulting Starlette application's state (i.e., `request.app.state.mcp_server` is unavailable). This makes it difficult for custom middleware to access the `FastMCP` server instance, which might be necessary for obtaining server-level settings (like configured paths) or the instance itself for other operations.

According to the Starlette documentation and common practice, `request.app` refers to the Starlette application instance, and `request.app.state` is the recommended place to store application-level state. Middleware often relies on this to access shared application components.

### Example Code

The following minimal example demonstrates that `request.app.state.mcp_server` is not available within a custom middleware when the Starlette app is created by `FastMCP.http_app()`.

```Python
# filename: mcp_state_test.py
import uvicorn
from starlette.applications import Starlette # Explicitly import Starlette
from starlette.requests import Request
from starlette.middleware import Middleware
from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint
from starlette.responses import JSONResponse # Not strictly needed for demo, but good practice

from fastmcp import Context, FastMCP


class StateAccessMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: RequestResponseEndpoint):
        # Attempt to access the FastMCP server instance from app.state
        mcp_server_instance = getattr(request.app.state, ""mcp_server"", None)

        if mcp_server_instance:
            print(
                f""SUCCESS: MCP Server instance found in middleware: {mcp_server_instance.name}""
            )
        else:
            print(
                ""FAILURE: MCP Server instance NOT FOUND in middleware via request.app.state.mcp_server""
            )
            print(f""         request.app type: {type(request.app)}"")
            print(f""         request.app.state attributes: {dir(request.app.state) if hasattr(request.app, 'state') else 'No state'}"")


        # Example of why middleware might need mcp_server_instance:
        # if mcp_server_instance:
        #     expected_mcp_path = mcp_server_instance.settings.streamable_http_path.rstrip(""/"")
        #     current_path = request.url.path.rstrip(""/"")
        #     if current_path == expected_mcp_path:
        #         print(f""Request path matches MCP path: {current_path}"")
        # else:
        #     print(""Cannot check path match as mcp_server_instance is None."")

        response = await call_next(request)
        return response


# Initialize FastMCP server
mcp_server = FastMCP(name=""TestServerForStateAccess"")


@mcp_server.tool()
def example_tool(ctx: Context, text: str) -> str:
    """"""A simple example tool.""""""
    return f""Tool processed: {text}""


# Create the Starlette app using FastMCP.http_app() and add our middleware
# Note: We need to wrap the middleware class with starlette.middleware.Middleware
starlette_app: Starlette = mcp_server.http_app( # Explicitly type hint for clarity
    middleware=[Middleware(StateAccessMiddleware)],
    transport=""streamable-http"" # or ""sse""
)

if __name__ == ""__main__"":
    print(f""FastMCP instance: {mcp_server}"")
    print(f""Starlette app instance: {starlette_app}"")
    # Accessing state before server runs might show default state.
    # The relevant check is within the middleware during a request.
    # print(f""Starlette app state initially: {starlette_app.state.__dict__ if hasattr(starlette_app, 'state') else 'No state'}"")
    uvicorn.run(starlette_app, host=""0.0.0.0"", port=7878)
```

**Steps to Reproduce:**

1.  Save the code above as `mcp_state_test.py`.
2.  Ensure `fastmcp`, `uvicorn`, and `starlette` are installed.
3.  Run the server: `python mcp_state_test.py`
4.  In a separate terminal, send a POST request to the MCP endpoint (default is `http://localhost:7878/mcp` for `streamable-http`):
    
    ```bash
    curl -X POST http://localhost:7878/mcp \
         -H ""Content-Type: application/json"" \
         -d '{""jsonrpc"":""2.0"",""method"":""tools/list"",""id"":1}'
    ```

**Expected Behavior:**

The server console (where `python mcp_state_test.py` was run) should print:
```
SUCCESS: MCP Server instance found in middleware: TestServerForStateAccess
```
This would indicate that `request.app.state.mcp_server` was successfully set to the `mcp_server` instance by FastMCP.

**Actual Behavior:**

The server console prints:
```
FAILURE: MCP Server instance NOT FOUND in middleware via request.app.state.mcp_server
         request.app type: <class 'starlette.applications.Starlette'>
         request.app.state attributes: ['_state'] 
```
(The client might receive a 307 redirect first, then a 200 OK or an error depending on subsequent processing, but the key is the ""FAILURE"" message in the server logs).

This demonstrates that the `FastMCP` instance is not being attached to the `Starlette` app's state when `FastMCP.http_app()` creates the application.

### Version Information

```Text
FastMCP version: 2.3.4
MCP version: 1.8.1
Python version: 3.13.2
```

### Additional Context

This missing `mcp_server` in `request.app.state` becomes problematic when developing custom middleware that needs to interact with the `FastMCP` instance. (Refs. https://github.com/sooperset/mcp-atlassian/pull/416) For example, to:
*   Access server settings like configured paths (e.g., `mcp_server_instance.settings.streamable_http_path`).
*   Dynamically call `FastMCP` methods or access its managers (tool, resource, prompt managers) if needed for advanced routing or pre/post-processing logic within the middleware.

A potential workaround for users is to ensure their middleware gets a direct reference to the `FastMCP` instance (e.g., via constructor injection if the middleware is instantiated where the `FastMCP` instance is available). However, using `request.app.state` is generally the standard Starlette way for middleware to access application-wide objects.

It appears that in `fastmcp/server/http.py`, the functions `create_streamable_http_app` and `create_sse_app` (which are called by `FastMCP.http_app`) instantiate `Starlette` (via `create_base_app`) but do not subsequently set `app.state.mcp_server = server_instance` (where `server_instance` would be the `FastMCP` instance). Adding this line in `create_base_app` or the calling functions might resolve the issue.

Thank you for considering this issue!"
3127318171,13,Improve timing accuracy,joamag,25441,open,2025-06-07T17:50:21Z,,https://github.com/joamag/boytacean,https://github.com/joamag/boytacean/pull/13,"## Summary
- handle highest priority interrupt in CPU
- allow multiple mode transitions in PPU clock
- add regression tests for interrupt priority and long PPU clocks

## Testing
- `cargo test`

------
https://chatgpt.com/codex/tasks/task_e_684386833a308328af8ff1a47d939c72

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **Bug Fixes**
  - Improved interrupt handling to prioritize and service the highest priority interrupt when multiple interrupts occur simultaneously.
  - Enhanced PPU timing to allow multiple mode transitions within a single update, ensuring accurate scanline and mode updates.

- **New Features**
  - Added support for HBlank DMA transfer.

- **Tests**
  - Added tests to verify interrupt prioritization and PPU behavior with large cycle counts.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3130070212,19,Add regression test for HDMA stop cycles,joamag,25441,closed,2025-06-09T11:50:15Z,2025-06-09T14:30:40Z,https://github.com/joamag/boytacean,https://github.com/joamag/boytacean/pull/19,"## Summary
- test that stopping HDMA in HBlank mode resets `cycles_hdma`
- cover stopping transfers with non-zero remaining cycles

## Testing
- `cargo test test_hdma_hblank_stop_resets_cycles --quiet`
- `cargo test test_hdma_hblank_stop_mid_block --quiet`
- `cargo test --quiet`


------
https://chatgpt.com/codex/tasks/task_e_6846c285226c8328ab174e7d643033a4

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **Tests**
  - Added new unit tests to improve coverage of HDMA (HBlank DMA) stopping behavior and cycle handling in Game Boy Color mode.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
2441480234,22,CanVec/Toporama maps,bfransoo,161159598,open,2024-08-01T05:03:29Z,,https://github.com/joshuafuller/ATAK-Maps,https://github.com/joshuafuller/ATAK-Maps/issues/22,"https://natural-resources.canada.ca/science-and-data/science-and-research/geomatics/topographic-tools-and-data/web-services/17216#

Any chance you could add CanVec data to a map source? Or investigate why my client crashes adding their WMS address? 

Helpful repo for the rest, thanks a ton! "
2692786883,25,Add OpenSeaMaps,joshuafuller,6954640,open,2024-11-26T01:53:35Z,,https://github.com/joshuafuller/ATAK-Maps,https://github.com/joshuafuller/ATAK-Maps/issues/25,"# Feature Request: Add OpenSeaMaps

## Description
Add support for OpenSeaMaps as a custom map source. This addition will enhance the functionality by including nautical charting data provided by OpenSeaMaps. Credit for the XML configuration goes to **Jonathan Svensson**.

## XML Configuration

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<customMapSource>
    <name>OpenSeaMapTILES</name>
    <minZoom>0</minZoom>
    <maxZoom>18</maxZoom>
    <tileType>png</tileType>
    <url>https://t2.openseamap.org/tile/{$z}/{$x}/{$y}.png</url>
    <coordinatesystem>epsg:3857</coordinatesystem>
    <backgroundColor>#000000</backgroundColor>
    <ignoreErrors>false</ignoreErrors>
</customMapSource>
```

Purpose

	•	To provide support for nautical maps via OpenSeaMaps.
	•	Improves mapping functionality for users needing marine chart data.

Acceptance Criteria

	•	OpenSeaMaps tiles are displayed correctly when added as a custom map source.
	•	Ensure compatibility with zoom levels from 0 to 18.
	•	Handle errors gracefully if tiles fail to load.
	•	Validate and ensure the coordinates system matches epsg:3857.

Additional Notes

	•	OpenSeaMaps tiles are served as PNG files and require a dark background color (#000000) for optimal visibility.
	•	Ensure the implementation doesn’t conflict with existing map sources.

Would appreciate any feedback or additional considerations for this integration. Thank you!
"
2765219150,27,ATAK Map suggestion,rmeehan82,190219589,closed,2025-01-01T19:12:40Z,2025-05-17T02:26:15Z,https://github.com/joshuafuller/ATAK-Maps,https://github.com/joshuafuller/ATAK-Maps/issues/27,"Hello sir! Great stuff! Thanks for putting in the time to help with simplifying maps for ATAK. If you could add FEMA flood maps to your list, that would be very helpful for FD's planning on where to deploy resources during/before a Flood. Thanks for your consideration! 

Rick "
3003221681,33,suggestion for adding Polish Geoportal topographic map,pplecke,127231562,open,2025-04-17T18:51:49Z,,https://github.com/joshuafuller/ATAK-Maps,https://github.com/joshuafuller/ATAK-Maps/issues/33,"Hi!

It would be great to have added things like:
[Rastrowa Mapa Topograficzna Polski](https://mapy.geoportal.gov.pl/imap/Imgp_2.html?locale=pl&gui=new&sessionID=6332980)
https://mapy.geoportal.gov.pl/wss/service/WMTS/guest/wmts/TOPO
or Polish ortophoto map
[Ortofotomapa standardowa](https://mapy.geoportal.gov.pl/imap/Imgp_2.html?locale=pl&gui=new&sessionID=6332941)
https://mapy.geoportal.gov.pl/wss/service/PZGIK/ORTO/WMTS/StandardResolution

More on this services could be found https://www.geoportal.gov.pl/pl/usluga/uslugi-przegladania-wms-i-wmts/ basically it's polish goverment mapping portal."
3070268303,51,chore(master): release 1.2.1,github-actions[bot],41898282,closed,2025-05-17T03:42:50Z,2025-05-17T03:44:15Z,https://github.com/joshuafuller/ATAK-Maps,https://github.com/joshuafuller/ATAK-Maps/pull/51,":robot: I have created a release *beep* *boop*
---


## [1.2.1](https://github.com/joshuafuller/ATAK-Maps/compare/v1.2.0...v1.2.1) (2025-05-17)


### Bug Fixes

* clarify docs phrasing ([#50](https://github.com/joshuafuller/ATAK-Maps/issues/50)) ([d317f2e](https://github.com/joshuafuller/ATAK-Maps/commit/d317f2e722a202a25877c9ce0c17251e7f3cb240))

---
This PR was generated with [Release Please](https://github.com/googleapis/release-please). See [documentation](https://github.com/googleapis/release-please#release-please)."
3073889940,1413,[Refactor]: Investigate mmr docs ordering,Ahmad-mtos,91780764,open,2025-05-19T13:37:55Z,,https://github.com/julep-ai/julep,https://github.com/julep-ai/julep/issues/1413,"### 📜 Description

basically make sure the logic in https://github.com/julep-ai/julep/pull/1373 makes sense, especially the changed test

### 👟 Relevant files

_No response_"
3079204848,1438,chore: Update CHANGELOG.md,Ahmad-mtos,91780764,closed,2025-05-21T07:20:22Z,2025-05-21T07:20:45Z,https://github.com/julep-ai/julep,https://github.com/julep-ai/julep/pull/1438,"
<!-- ELLIPSIS_HIDDEN -->



> [!IMPORTANT]
> Corrected pull request reference number in `CHANGELOG.md` for the **Secrets** management feature.
> 
>   - **Changelog Update**:
>     - Corrected pull request reference number from `#1424` to `#1312` for the **Secrets** management feature in `CHANGELOG.md`.
> 
> <sup>This description was created by </sup>[<img alt=""Ellipsis"" src=""https://img.shields.io/badge/Ellipsis-blue?color=175173"">](https://www.ellipsis.dev?ref=julep-ai%2Fjulep&utm_source=github&utm_medium=referral)<sup> for 536cefb5b98c5c32248baa0b1b3042cb03bef728. You can [customize](https://app.ellipsis.dev/julep-ai/settings/summaries) this summary. It will automatically update as commits are pushed.</sup>

<!-- ELLIPSIS_HIDDEN -->"
3079946273,1442,[Feature]: a new endpoint to fetch the status of the execution without the output,HamadaSalhab,31417987,closed,2025-05-21T11:46:20Z,2025-05-24T16:15:32Z,https://github.com/julep-ai/julep,https://github.com/julep-ai/julep/issues/1442,"### 🔖 Feature description

It should also allow streaming

### 🎤 Why is this feature needed ?

_No response_

### ✌️ How do you aim to achieve this?

_No response_

### 👀 Have you searched issues and PRs to see if this feature request has been raised before?

- [x] I checked and didn't find similar issue"
2879917319,4041,Extra bar will be added to the end of the waveform when option normalize is set to true,onigetoc,47570,closed,2025-02-26T01:44:22Z,2025-05-28T15:01:54Z,https://github.com/katspaugh/wavesurfer.js,https://github.com/katspaugh/wavesurfer.js/issues/4041,"Extra bar will be added to the end of the waveform when option normalize is set to true

## Bug description
When we set normalize to true Extra bar will be added to the end of the waveform

## Environment
React

## Minimal code snippet
It's the second canvas. In the Google Chrome inspector, if i remove the second canvas or replace 4px by zero or the width to zero (0) it fix it.
<canvas width=""4"" height=""40"" style=""width: 4px; height: 40px; left: 730px;""></canvas>

## Expected result
Not extra bar at the end of the waveform

## Obtained result


## Screenshots
Set the normalize option to true to the player waveform and a extra bar will be added to the end 
https://wavesurfer.xyz/examples/?all-options.js
"
264253148,278,Chrome bug drawHitFromCache(),devth8,7171749,closed,2017-10-10T14:37:03Z,2017-10-13T10:51:13Z,https://github.com/konvajs/konva,https://github.com/konvajs/konva/issues/278,"In drag'n'drop the following example :
https://konvajs.github.io/docs/events/Image_Events.html
```
lion.cache();
lion.drawHitFromCache();
```
does not work as soon as one leaves the window the image which has the function

Ok :
_____________
|                  |
|         O      |
|                  |
_____________

O = image


Bug :

(after drag'n'drop image output window)

_____________
|                  |
|                  |  O
|                  |
_____________

bug Chrome drag'n'drop

group drag'n'drop (with in image cache & drawHitFromCache) is larger than the window

"
3076126749,1736,[Bug]: hcloud provider error on hcloud_load_balancer_network.cluster creation after upgrade to v2.17.1,jr-dimedis,8652743,closed,2025-05-20T08:19:31Z,2025-06-09T05:26:46Z,https://github.com/kube-hetzner/terraform-hcloud-kube-hetzner,https://github.com/kube-hetzner/terraform-hcloud-kube-hetzner/issues/1736,"### Description

I upgraded the kube-hetzner module from v2.17.0 to v2.17.1 and `terraform apply` results in this error:

```
Terraform will perform the following actions:

  # module.kube-hetzner.hcloud_load_balancer_network.cluster[0] will be created
  + resource ""hcloud_load_balancer_network"" ""cluster"" {
      + enable_public_interface = true
      + id                      = (known after apply)
      + ip                      = (known after apply)
      + load_balancer_id        = 1659641
      + subnet_id               = ""2919908-10.0.0.0/16""
    }

  # module.kube-hetzner.hcloud_load_balancer_target.cluster[0] will be created
  + resource ""hcloud_load_balancer_target"" ""cluster"" {
      + id               = (known after apply)
      + label_selector   = ""cluster=k8stest1,engine=k3s,provisioner=terraform,role=agent_node""
      + load_balancer_id = 1659641
      + type             = ""label_selector""
      + use_private_ip   = true
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.kube-hetzner.hcloud_load_balancer_network.cluster[0]: Creating...
╷
│ Error: Provider produced inconsistent result after apply
│ 
│ When applying changes to module.kube-hetzner.hcloud_load_balancer_network.cluster[0], provider ""provider[\""registry.terraform.io/hetznercloud/hcloud\""]"" produced an unexpected new value: Root object was present, but now absent.
│ 
│ This is a bug in the provider, which should be reported in the provider's own issue tracker.
╵
```

The load balancer id in the output corresponds to the nginx load balancer I configured with kube-hetzner (and not the control plane load balancer I activated as well).

Maybe this report should go to `hetznercloud/hcloud` but I thought it's worth to report this here and getting some help! Otherwise just tell me and I'll create an issue in the `hcloud` project.

Thanks!

### Kube.tf file

```terraform
  load_balancer_type     = ""lb11""
  load_balancer_location = ""fsn1""
  ingress_controller = ""nginx""
  use_control_plane_lb = true
```

### Used provider versions

```
Providers required by configuration:
.
├── provider[registry.terraform.io/hetznercloud/hcloud] >= 1.49.1
├── provider[registry.terraform.io/hashicorp/vault]
└── module.kube-hetzner
    ├── provider[registry.terraform.io/hashicorp/local] >= 2.5.2
    ├── provider[registry.terraform.io/tenstad/remote] >= 0.1.3
    ├── provider[registry.terraform.io/integrations/github] >= 6.4.0
    ├── provider[registry.terraform.io/hashicorp/null]
    ├── provider[registry.terraform.io/hashicorp/random]
    ├── provider[registry.terraform.io/hashicorp/cloudinit]
    ├── provider[registry.terraform.io/hetznercloud/hcloud] >= 1.49.1
    ├── module.agents
    │   ├── provider[registry.terraform.io/hetznercloud/hcloud] >= 1.49.1
    │   ├── provider[registry.terraform.io/hashicorp/null]
    │   ├── provider[registry.terraform.io/hashicorp/random]
    │   └── provider[registry.terraform.io/hashicorp/cloudinit]
    └── module.control_planes
        ├── provider[registry.terraform.io/hetznercloud/hcloud] >= 1.49.1
        ├── provider[registry.terraform.io/hashicorp/null]
        ├── provider[registry.terraform.io/hashicorp/random]
        └── provider[registry.terraform.io/hashicorp/cloudinit]
```

### Platform

Linux"
3105725219,1746,[fix] enable load balancer network configuration and update dependencies,arbianshkodra,97307964,closed,2025-05-31T16:22:51Z,2025-06-09T04:35:54Z,https://github.com/kube-hetzner/terraform-hcloud-kube-hetzner,https://github.com/kube-hetzner/terraform-hcloud-kube-hetzner/pull/1746,"# Fixes #1736, related to #1741

## Related Issues/PRs
- Fixes #1736
- Builds on #1741 

## Changes Made
- Updated data source logic in data.tf
- Modified initialization in init.tf  
- Adjusted local values in locals.tf

## Testing
- tofu plan
- tofu apply
- everything looks in place."
3105845275,363,Refactor code using typed-version of `sync.Map`,amorey,75881,closed,2025-05-31T17:55:10Z,2025-06-05T12:02:13Z,https://github.com/kubetail-org/kubetail,https://github.com/kubetail-org/kubetail/issues/363,"The built-in go type `sync.Map` is useful for making thread-safe programs but the lack of built-in type safety makes it cumbersome to use. It would be useful to have a typed version of `sync.Map` that would have a similar [API](https://pkg.go.dev/sync#Map) and behave like this:

```go
import ""github.com/kubetail-org/kubetail/modules/shared/util""

type MyValue struct {
  a string
  b string
}

func main () {
  var m util.SyncMap[string, MyValue]

  m.Store(""k1"", MyValue{a: ""A"", b: ""B""})
  v1, exists := m.Load(""k1"")
  fmt.Println(""all should be true"", exists, v1.a == ""A"", v1.b == ""B"")
}
```

Then we could refactor our code using `sync.Map` and simplify blocks like this: https://github.com/kubetail-org/kubetail/blob/main/modules/dashboard/internal/cluster-api/health-monitor.go#L148-L181
"
3117978759,377,Upgrade rust to 1.87.0,amorey,75881,closed,2025-06-04T14:06:48Z,2025-06-04T21:36:14Z,https://github.com/kubetail-org/kubetail,https://github.com/kubetail-org/kubetail/issues/377,Upgrade to rust 1.87.0 wherever rust is used
3133830459,5042,support pandas (dataframe and series) serialization with jsonplus,sydney-runkle,54324534,closed,2025-06-10T14:30:17Z,2025-06-10T19:37:08Z,https://github.com/langchain-ai/langgraph,https://github.com/langchain-ai/langgraph/pull/5042,
3140330911,5077,Pandas serialization/deserialization logic with msgpack,sydney-runkle,54324534,open,2025-06-12T13:35:59Z,,https://github.com/langchain-ai/langgraph,https://github.com/langchain-ai/langgraph/issues/5077,"Right now, users can use pandas series/dataframes in state and serialize them with a `JsonPlusSerializer` that has `pickle_fallback` enabled.

It'd be great to have these as first class citizens, able to be serialized via `msgpack` like `numpy` arrays.

This is a bit of a tricky task, as dataframes have lots of nuanced features like:
* multiindexes (both row and column)
* dtypes by column
* opportunity for arbitrary objects in table cells

We want to preserve df structure during serialization and deserialization.

There are a few options here, assuming we continue to use msgpack:
* Dump pickled content (this is a bit redundant, both are serialization protocols). One benefit here is that pandas x pickle work well together with all of the above nuances
* Dump bytes directly, though custom logic will have to be written for the above pandas features
* Use `arrow` - this is the most efficient storage wise, though there are some type inconsistencies (like with `object` dtype) that will need to be considered.

A PR addressing this should have thorough testing, perhaps mimicking many of the conditions tested for in https://github.com/langchain-ai/langgraph/pull/5057.

You might want to reference https://github.com/langchain-ai/langgraph/pull/5035 as a reference for how to add logic for new types to `JsonPlusSerializer`."
2215979185,1547,chore(api): casing of fromTimestamp param,marcklingen,2834609,closed,2024-03-29T20:45:41Z,2024-03-29T20:49:04Z,https://github.com/langfuse/langfuse,https://github.com/langfuse/langfuse/pull/1547,
3014537518,5,Issue updating workflows,outbound,824269,open,2025-04-23T16:07:02Z,,https://github.com/leonardsellem/n8n-mcp-server,https://github.com/leonardsellem/n8n-mcp-server/issues/5,"Thanks for making this. 

The tool works when creating or lsting workflows. But it fails when trying to update a scenario. I've tried it on simple or complex scenarios. But Claude desktop always comes back with: 

""I'll try a different approach by creating a new workflow..."" and creates a new one instead. 

Can you help me troubleshoot this?

Claude MCP on Windows 11. Self Hosted n8n 
Tested on n8n 1.8.6 and 1.8.9

Looking at the log - this is the error I see

2025-04-23T16:08:27.210Z [n8n-syno] [info] Message from server: {""jsonrpc"":""2.0"",""id"":156,""result"":{""resources"":[{""uri"":""n8n://workflows"",""name"":""n8n Workflows"",""mimeType"":""application/json"",""description"":""List of all workflows in the n8n instance with their basic information""},{""uri"":""n8n://execution-stats"",""name"":""n8n Execution Statistics"",""mimeType"":""application/json"",""description"":""Summary statistics of workflow executions including success rates, average duration, and trends""}]}}
2025-04-23T16:08:28.888Z [n8n-syno] [info] Message from client: {""method"":""prompts/list"",""params"":{},""jsonrpc"":""2.0"",""id"":157}
2025-04-23T16:08:28.889Z [n8n-syno] [info] Message from server: {""jsonrpc"":""2.0"",""id"":157,""error"":{""code"":-32601,""message"":""Method not found""}}
2025-04-23T16:08:29.031Z [n8n-syno] [info] Message from client: {""method"":""prompts/list"",""params"":{},""jsonrpc"":""2.0"",""id"":158}
2025-04-23T16:08:29.032Z [n8n-syno] [info] Message from server: {""jsonrpc"":""2.0"",""id"":158,""error"":{""code"":-32601,""message"":""Method not found""}}
"
3116943096,33,Merge PR #25 with tests,leonardsellem,2162208,closed,2025-06-04T08:21:02Z,2025-06-04T08:21:16Z,https://github.com/leonardsellem/n8n-mcp-server,https://github.com/leonardsellem/n8n-mcp-server/pull/33,"## Summary
- merge branch for PR #25
- resolve conflicts in resource formatter tests and workflow tool tests

## Testing
- `npm run lint` *(fails: @typescript-eslint/no-explicit-any etc.)*
- `npm test`


------
https://chatgpt.com/codex/tasks/task_e_683fffeca9748327ae9ccb8fc7a095bf"
3119491578,38,🐞 Bug Report: create_workflow rejects valid nodes array (always returns error 1004),ashepp,13700294,open,2025-06-05T00:39:10Z,,https://github.com/leonardsellem/n8n-mcp-server,https://github.com/leonardsellem/n8n-mcp-server/issues/38,"I've been trying to integarte n8n-mcp-server with chatgpt via https://chromewebstore.google.com/detail/mcp-superassistant/kngiafgkdnlkgmefdafaibkibegkcaef

It had worked previously with TypingMind / Claude to create a workflow but I've spent hour trying to debug this issue today. 
I'm running n8n on unraid in a docker and exposed to a custom URL via nginx. 


 

Summary of Today’s MCP-workflow Experiment, Adam

Goal

Spin up a minimal n8n workflow (Webhook → Set) entirely through the n8n.create_workflow MCP function so you can confirm end-to-end LLM-driven automation.

What We Tried

Passed nodes and connections in every plausible format:

raw JSON literals

stringified, single-line JSON

multi-line, indented JSON

repeated <parameter name=""nodes"">… entries (array-style XML)

even an empty nodes array ([]) for a baseline test.

Verified our schema by fetching a known-good workflow (get_workflow) and mirroring its structure.

Each attempt still returned MCP error 1004: Parameter ""nodes"" must be an array.

Diagnosis

The error persists even when nodes is an array, which implies the XML wrapper is forwarding every parameter as a plain string; the MCP validator refuses to coerce that string into an array.

Direct REST calls to the n8n API succeed, so the bug lives strictly in the MCP parameter-parsing layer.

Workarounds Discussed

Clone an existing workflow via get_workflow → create_workflow (REST) or modify via update_workflow, thus avoiding the broken array-creation path.

File a formal bug so the maintainers can add JSON.parse (or equivalent) before validation.

Bug-report Draft

I composed a ready-to-paste issue template detailing environment, reproduction steps, and suggested fix.

Next Actions

Submit the bug report to the leonardsellem/n8n-mcp-server repo (or whichever tracker you’re using).

Until it’s fixed, use the clone-and-trim method for any workflows you need to auto-generate.


🐞 Bug Report: create_workflow rejects valid nodes array (always returns error 1004)

Environment

MCP server: leonardsellem/n8n-mcp-server (v 0.1.3)

n8n core: cloud instance at https://n8n.snackify.ai/

Wrapper client: XML/LLM tool-call layer (ChatGPT “SuperAssistant” interface)

Date/time: 2025-06-04 17:xx PDT

Description
Calling n8n.create_workflow always returns
MCP error 1004: Parameter ""nodes"" must be an array
even when nodes is supplied as:
• a valid JSON array string – [ {...}, {...} ]
• a one-line compressed array (same content)
• an empty array – []

Submitting the same payload directly via REST (POST /workflows) works, so the failure seems isolated to the MCP parameter-parsing layer.

Minimal reproduction
create_workflow payload:
name: MCP Empty-Nodes Test
nodes: []
connections: {}
settings: {}
active: false

Expected result: workflow created (or a different validation error for empty nodes).
Actual result: MCP error 1004: Parameter ""nodes"" must be an array.

Additional findings

list_workflows, get_workflow, and update_workflow succeed through the same interface.

Cloning an existing workflow via get_workflow → update_workflow also succeeds.

Indicates the wrapper forwards every parameter as a plain string; the backend never JSON.parses nodes.

Impact
Blocks all workflow creation via MCP tooling or LLM integrations, preventing dynamic automation scenarios.

Suggested fix

In the MCP server (or its XML wrapper), detect parameters expected to be arrays/objects (nodes, connections, settings) and run JSON.parse on their string values before schema validation.

Alternatively, document that callers must supply pre-parsed arrays and adjust the validator accordingly."
3108154186,1845,chore(deps): lock file maintenance,renovate[bot],29139614,closed,2025-06-02T01:04:42Z,2025-06-03T05:04:04Z,https://github.com/liam-hq/liam,https://github.com/liam-hq/liam/pull/1845,"This PR contains the following updates:

| Update | Change |
|---|---|
| lockFileMaintenance | All locks refreshed |

🔧 This Pull Request updates lock files to use the latest dependency versions.

---

### Configuration

📅 **Schedule**: Branch creation - ""before 4am on monday"" (UTC), Automerge - At any time (no schedule defined).

🚦 **Automerge**: Disabled by config. Please merge this manually once you are satisfied.

♻ **Rebasing**: Whenever PR becomes conflicted, or you tick the rebase/retry checkbox.

👻 **Immortal**: This PR will be recreated if closed unmerged. Get [config help](https://redirect.github.com/renovatebot/renovate/discussions) if that's undesired.

---

 - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box

---

This PR was generated by [Mend Renovate](https://mend.io/renovate/). View the [repository job log](https://developer.mend.io/github/liam-hq/liam).
<!--renovate-debug:eyJjcmVhdGVkSW5WZXIiOiI0MC4zMy42IiwidXBkYXRlZEluVmVyIjoiNDAuMzMuNiIsInRhcmdldEJyYW5jaCI6Im1haW4iLCJsYWJlbHMiOltdfQ==-->
"
3112292654,1856,🐛(knip): Fix remaining knip configuration errors,MH4GF,31152321,closed,2025-06-03T03:53:50Z,2025-06-03T04:45:18Z,https://github.com/liam-hq/liam,https://github.com/liam-hq/liam/pull/1856,"## Issue

- resolve: Additional knip errors missed in PR #1853

## Why is this change needed?

There were remaining errors that were missed during the review of https://github.com/liam-hq/liam/pull/1853. This PR addresses the remaining knip configuration issues that were not caught in the previous review.

## What would you like reviewers to focus on?

- Removal of unused `langfuse` dependency while preserving `langfuse-vercel`
- Cleanup of unnecessary `ignoreUnresolved` configuration in knip.jsonc

## Testing Verification

Knip configuration has been tested to ensure no false positive errors remain.

## What was done

### 🤖 Generated by PR Agent at 2a5658cd915a0bc4efde07322c0ff5a16b97a4c5

- Removed unused `langfuse` dependency from `package.json`
- Cleaned up unnecessary `ignoreUnresolved` entries in `knip.jsonc`
- Streamlined knip configuration for accuracy and maintainability


## Detailed Changes

<table><thead><tr><th></th><th align=""left"">Relevant files</th></tr></thead><tbody><tr><td><strong>Dependencies</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>package.json</strong><dd><code>Remove unused langfuse dependency from package.json</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

frontend/apps/app/package.json

<li>Deleted the <code>langfuse</code> dependency from the dependencies list<br> <li> Kept <code>langfuse-vercel</code> dependency intact<br> <li> Streamlined package management by removing unused package


</details>


  </td>
  <td><a href=""https://github.com/liam-hq/liam/pull/1856/files#diff-1cb683806b3ef955a38fae27b87a08febf12a8b1465dedad3a3f92c0136f132a"">+0/-1</a>&nbsp; &nbsp; &nbsp; </td>

</tr>
</table></td></tr><tr><td><strong>Configuration changes</strong></td><td><table>
<tr>
  <td>
    <details>
      <summary><strong>knip.jsonc</strong><dd><code>Clean up ignoreUnresolved in knip.jsonc</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>
<hr>

knip.jsonc

<li>Removed <code>ignoreUnresolved</code> entries for <code>schema.generated.js</code><br> <li> Cleaned up configuration to avoid unnecessary suppressions<br> <li> Improved knip config maintainability


</details>


  </td>
  <td><a href=""https://github.com/liam-hq/liam/pull/1856/files#diff-48d5ba4681726b42e98dae10c08bd94f7f9836644c8f183c6475d10dcf67ebf1"">+0/-6</a>&nbsp; &nbsp; &nbsp; </td>

</tr>
</table></td></tr></tr></tbody></table>

## Additional Notes

This is a follow-up fix to ensure complete resolution of knip configuration issues.

___

> <details> <summary>  Need help?</summary><li>Type <code>/help how to ...</code> in the comments thread for any questions about Qodo Merge usage.</li><li>Check out the <a href=""https://qodo-merge-docs.qodo.ai/usage-guide/"">documentation</a> for more information.</li></details>"
2645492872,625,能否提添加硬盘温度检测和硬盘smart的相关信息,axlrose,26582,closed,2024-11-09T02:20:54Z,2025-06-04T23:34:01Z,https://github.com/lollipopkit/flutter_server_box,https://github.com/lollipopkit/flutter_server_box/issues/625,"非常好用的一款软件，能否将硬盘温度和硬盘smart健康状态加上，谢谢！
"
3053591143,138,Add debouncing for showing QR code changes,lyqht,35736525,closed,2025-05-10T02:57:36Z,2025-05-29T03:05:50Z,https://github.com/lyqht/mini-qr,https://github.com/lyqht/mini-qr/issues/138,For a11y so that less flashes happen per second
3064507554,140,FEATURE REQUEST: FRAME TEXT LINE BREAKS,tali0n,7634251,closed,2025-05-14T23:51:06Z,2025-05-29T02:57:14Z,https://github.com/lyqht/mini-qr,https://github.com/lyqht/mini-qr/issues/140,"Perhaps I'm missing something obvious, but is it possible to a line breaks on the frame text?  For example, when I put text in now it will wrap once it reaches the end of the frame but I'd like to add 2 to 3 separate lines such as:

Line 1
Line 2
Line 3

vs

Line 1 Line 2 Line 3

Thank you!"
3088052714,146,Frame presets,lyqht,35736525,closed,2025-05-24T04:50:46Z,2025-05-31T07:49:40Z,https://github.com/lyqht/mini-qr,https://github.com/lyqht/mini-qr/issues/146,"Similar to QR code presets, but for frames!"
3103265089,161,Add frame preset feature,lyqht,35736525,closed,2025-05-30T13:33:00Z,2025-05-31T07:49:40Z,https://github.com/lyqht/mini-qr,https://github.com/lyqht/mini-qr/pull/161,"# Frame Preset Feature and Test Improvements

Resolves #146

![CleanShot 2025-05-31 at 15 44 57@2x](https://github.com/user-attachments/assets/810323e1-7f86-49b8-9957-c890bd729338)


## Features
- Add support for selecting and applying different frame presets in QRCodeCreate component
- Introduce frame presets with default, dark, and borderless styles for QR code frames

## Testing Improvements
- Remove outdated e2e test file for 'app' functionality
- Refactor test suite structure for QR code creation and management
- Add support for saving and loading QR code configurations via file
- Implement export functionality for single QR codes with and without frames
- Introduce batch export functionality for generating multiple QR codes
- Add e2e test for scanning a QR code from a file"
3066729862,24,[bounty] $$$ make more examples,louis030195,25003283,open,2025-05-15T15:55:59Z,,https://github.com/mediar-ai/terminator,https://github.com/mediar-ai/terminator/issues/24,"
/bounty 100

build more examples, apps!

### 🧠 High-Value Terminator Apps 

| #  | Name                   | Problem Solved                            | MVP Implementation (max 1-week)                                                  | Reward |
|----|------------------------|-------------------------------------------|-------------------------------------------------------------------------------|--------|
| 1  | **MedClaim AutoFill**  | Manual claim PDF → EMR UI fill            | Parse fixed PDF → autofill 5 fields in dummy EMR desktop app                 | $300   |
| 2  | **HotelSync Pro**      | Manual hotel email → portal update        | Watch folder for email PDFs → extract 3 fields → auto-fill web UI            | $250   |
| 3  | **FormFiller Pro**     | W-9 forms filled manually                 | Load W-9 PDF → auto-fill 7 fields in Acrobat via accessibility API           | $200   |
| 4  | **SAP Data Bridge**    | Manual SAP UI data entry                  | Dummy SAP-like app → read JSON → fill 5 fields via Terminator                | $300   |
| 5  | **TravelDesk Connector**| Copy-paste between FreshDesk and Amadeus | Copy ticket ID from one app → paste to second via window switch + keyboard   | $200   |
| 6  | **CAPTCHASolver Ent.** | Manual CAPTCHA solving                    | Auto-fill login form → fake CAPTCHA image → user prompt + form submit        | $250   |
| 7  | **VisaDoc Processor**  | Visa form data from scanned PDF           | OCR 3 fields from fixed visa PDF → auto-fill US gov form page                | $200   |
| 8  | **BPO Accelerator**    | Manual Excel-to-form copy-paste           | Load Excel row → match to form fields in dummy app → fill & log              | $300   |
| 9  | **ConsultantRPA**      | Need for white-label simple RPA           | Build template-based Terminator CLI with 1 sample config + branding toggle   | $200   |
| 10 | **WorkflowSensor**     | Unseen repetitive work                    | Log active window + keystrokes for 2 apps → output JSON                      | $150   |
| 11 | **ExcelToLegacyBot**   | Manual Excel → legacy tool entry          | Excel watcher → fill dummy legacy form with 5 fields                         | $200   |
| 12 | **ClipboardTriggerBot**| Clipboard → form filler                   | On Ctrl+Shift+F → paste structured clipboard text into 3 form fields         | $150   |
| 13 | **InsurancePDFParser** | Insurance data to structured JSON         | Parse 3 fields from fixed claim PDF → export to JSON                         | $150   |
| 14 | **PDFFormMapper**      | Unstructured form field labeling          | Load PDF → output guessed field names as JSON                               | $150   |
| 15 | **AuditTrail Recorder**| Need UI activity logs for compliance      | Capture click/window/fill events in CSV with timestamps                     | $200   |
| 16 | **InboxToFormBot**     | Email order → form entry                  | Drag email (EML or PDF) → extract 2 fields → fill into form in app           | $200   |
| 17 | **LegacyHRBot**        | Resume → onboarding app fill              | Extract name + phone from resume → fill onboarding form in dummy app         | $150   |
| 18 | **WindowsLoginAutomator**| Repeat logins to portals                 | Open dummy login UI → auto-enter credentials from config                     | $150   |
| 19 | **GovForm AutoFiller** | Tedious gov form input                    | Fill IRS/visa PDF from sample JSON using keyboard events                     | $200   |
| 20 | **ClaimCheck Validator**| Double entry QA for claims                | Extract from form + compare with PDF → mark match/mismatch in UI             | $200   |

focus on Copilot experience instead of Autopilot for now (eg human in the loop) as it's easier to do for now 

quality will influence the bounty size

you can use Typescript, Python, or Tauri, Rust as you prefer (will influence bounty) (we usually prefer tauri or rust as it's easier to share with non technical users)

if you use [tauri](https://v2.tauri.app/), feel free to use the [pre-built server](https://github.com/mediar-ai/terminator?tab=readme-ov-file#quick-start) running on the side on your machine and use the TS SDK from UI, i can help/do the packaging into standalone app later 

if these are too complex feel free to suggest simpler 

we're looking for quality examples / apps though, rule of thumb is that **if I can vibe code the thing you did in a single OpenAI Codex prompt, you probably did not work hard enough**.


"
2955333635,6430,[Bug]: name lost,cracky22,104385850,open,2025-03-28T08:05:28Z,,https://github.com/meshtastic/firmware,https://github.com/meshtastic/firmware/issues/6430,"### Category

Other

### Hardware

Heltec V3

### Is this bug report about any UI component firmware like InkHUD or Meshtatic UI (MUI)?

- [ ] Meshtastic UI aka MUI colorTFT
- [ ] InkHUD ePaper
- [ ] OLED slide UI on any display

### Firmware Version

2.6.2

### Description

the heltec v3 keeps forgetting its name and you have to set it again

### Relevant log output

```Shell

```"
3114259541,175,Feat add new simple tui,alehander92,830715,closed,2025-06-03T14:37:24Z,2025-06-03T14:37:54Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/175,originally from #167 with codex
3114514259,178,Feat send trace data with launch,alehander92,830715,closed,2025-06-03T15:43:58Z,2025-06-03T15:49:26Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/178,from #177 with codex
3117732786,182,Feat add dap client,alehander92,830715,closed,2025-06-04T12:53:06Z,2025-06-04T12:53:25Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/182,originally #180 with codex
3117837496,184,Feat use stream socket for dap,alehander92,830715,closed,2025-06-04T13:24:54Z,2025-06-04T13:25:48Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/184,originally #183 with codex
3118643787,188,Feat handle dap responses and events,alehander92,830715,closed,2025-06-04T17:59:41Z,2025-06-04T18:01:08Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/188,"originally in #187 with codex; many of the changes might not be relevant, we mostly want to change simple_tui"
3118688092,191,Feat: simple-tui line numbers,alehander92,830715,closed,2025-06-04T18:16:41Z,2025-06-04T18:16:59Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/191,originally #189 with codex
3118690901,192,Feat: simple-tui active line,alehander92,830715,closed,2025-06-04T18:17:41Z,2025-06-04T18:22:15Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/192,originally #190 with codex
3118711548,194,Feat: simple-tui add calltrace panel,alehander92,830715,closed,2025-06-04T18:24:32Z,2025-06-04T18:28:34Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/194,originally #193 with codex
3121879265,197,Add setBreakpoints support,pxor,68468634,closed,2025-06-05T16:41:23Z,2025-06-06T13:46:35Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/197,"## Summary
- add helper to persist breakpoints for the DAP server
- register breakpoints from `setBreakpoints` requests
- exercise the server in new test

## Testing
- `cargo build`
- `cargo test`
- `cargo clippy`


------
https://chatgpt.com/codex/tasks/task_b_6841bfe7f4a883318e83db6248652463"
3122225327,201,Fix: simple-tui: send initialize,alehander92,830715,closed,2025-06-05T18:33:32Z,2025-06-05T18:34:08Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/201,originally #199 with codex
3130410867,211,Feat: db-backend: add stdio transport dap,alehander92,830715,closed,2025-06-09T14:02:10Z,2025-06-09T14:16:59Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/211,originally #210 with codex
3130652305,213,Feat: db-backend: dap: add support for `configuration done`,alehander92,830715,closed,2025-06-09T15:29:09Z,2025-06-09T15:29:24Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/213,originally #212 with codex
3130921625,215,Feat: db-backend: send capabilities in DAP initialize response,alehander92,830715,closed,2025-06-09T17:17:45Z,2025-06-10T11:18:25Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/215,"originally #214 with codex

some manual fixes in the next commits after original ones"
3139544565,222,fix: prevent text selection in footer,alehander92,830715,closed,2025-06-12T09:34:50Z,2025-06-12T09:35:16Z,https://github.com/metacraft-labs/codetracer,https://github.com/metacraft-labs/codetracer/pull/222,"Added user-select:none styles for location path, inline status, and ready-status spans so text in the status bar can't be highlighted.

originally #198 with codex"
3146992153,2274,opt: optimize union to avoid recalculating size in sorted_set,Topology2333,118144168,closed,2025-06-15T02:11:12Z,2025-06-16T04:50:53Z,https://github.com/moonbitlang/core,https://github.com/moonbitlang/core/pull/2274,"This pull request optimizes the implementation of the Set union operation in the `sorted_set` module.

#### Key Changes

- **Efficient Size Calculation in Union:**  
  The `union` function in `sorted_set/set.mbt` is refactored so that the size of the resulting set is computed during the union process, rather than by iterating over the set after construction.  
  - The internal `aux` function now returns both the new root node and the size of the subtree.
  - The overall size is accumulated as trees are merged, eliminating the need for an extra traversal.

- **New Utility Function:**  
  A new helper function `count_nodes` is introduced in `sorted_set/utils.mbt`.  
  - This function recursively calculates the number of nodes in a (sub)tree.
  - It is used by the `aux` function to efficiently determine subtree sizes when merging.

#### Benefits

- **Performance Improvement:**  
  By calculating the set size during the merge, we avoid an O(n) traversal after the union, improving efficiency especially for large sets.

- **Cleaner Code:**  
  The new approach removes the need for a temporary counter and a post-processing step, resulting in a clearer and more maintainable implementation."
3089545186,71,Expand multimodal image support,mrwadams,2872334,closed,2025-05-25T20:10:51Z,2025-05-25T20:43:50Z,https://github.com/mrwadams/stride-gpt,https://github.com/mrwadams/stride-gpt/pull/71,"## Summary
- support image analysis for Azure OpenAI, Google AI, and Anthropic models
- generalize image upload in the UI for any provider that accepts images
- document multimodal support for all providers

## Testing
- `python -m py_compile main.py threat_model.py`
- `python -m py_compile attack_tree.py dread.py mitigations.py test_cases.py utils.py`
"
3160092688,444,UTF-8 Support for Subjects and Issuers,Squiblydoo,77356206,closed,2025-06-19T12:09:36Z,2025-06-19T15:57:45Z,https://github.com/mtrojnar/osslsigncode,https://github.com/mtrojnar/osslsigncode/pull/444,"I primarily use osslsigncode to collect information about the certificate subject. (I track abused code-signing certificates.)
I observed that in the current build of osslsigncode, the content printed to the terminal does not support UTF-8.

Printing the subject of the certificate of the file [here](https://bazaar.abuse.ch/sample/be5d6c4aa4b27548a06c2afaef3b4035abf65566e9a8bfd642b4a2032729656e/), will produce the following result:

```
Subject: /serialNumber=91140802MADALQC44B/jurisdictionC=CN/businessCategory=Private Organization/C=CN/ST=\xE5\xB1\xB1\xE8\xA5\xBF\xE7\x9C\x81/O=\xE8\xBF\x90\xE5\x9F\x8E\xE5\xB8\x82\xE7\x9B\x90\xE6\xB9\x96\xE5\x8C\xBA\xE9\xA3\x8E\xE9\xA2\x9C\xE5\x95\x86\xE8\xB4\xB8\xE6\x9C\x89\xE9\x99\x90\xE5\x85\xAC\xE5\x8F\xB8/CN=\xE8\xBF\x90\xE5\x9F\x8E\xE5\xB8\x82\xE7\x9B\x90\xE6\xB9\x96\xE5\x8C\xBA\xE9\xA3\x8E\xE9\xA2\x9C\xE5\x95\x86\xE8\xB4\xB8\xE6\x9C\x89\xE9\x99\x90\xE5\x85\xAC\xE5\x8F\xB8
```

With my suggested changes, it will produce the following result:
```
Subject: CN=运城市盐湖区风颜商贸有限公司,O=运城市盐湖区风颜商贸有限公司,ST=山西省,C=CN,businessCategory=Private Organization,jurisdictionC=CN,serialNumber=91140802MADALQC44B
```

I also tested this with a certificate with a [Danish subject](https://www.virustotal.com/gui/file/f82bee604ef597b2dcd0d8f5871680fe1233c70867214ec78f050388f3b02691/details) and [Ukrainian subject](https://www.virustotal.com/gui/file/a31d955304360eade30679137269659a9c7b1e53aecb2eb7e616a4ad0f91c655) (each have characters that were not previously supported).

Danish:
```
Subject: jurisdictionC=DK,businessCategory=Private Organization,CN=Paperbucketmdb ApS,serialNumber=32330233,O=Paperbucketmdb ApS,L=København,ST=Hovedstaden,C=DK
```

Ukrainian:
```
Subject: jurisdictionC=UA,businessCategory=Private Organization,CN=ТОВ \""Гейм Трейд\"",serialNumber=45350408,O=ТОВ \""Гейм Трейд\"",L=Kyiv,ST=Kiev,C=UA
```

------------------------------
Note: In regards to the changes themselves, I am not a C/C++ developer; I have some programming skill and these changes were made consulting with ChatGPT and troubleshooting issues with ChatGPT. But there may be additional improvements that you see.

It is my understanding that OpenSSL's ""X509_NAME_oneline"" has limitations preventing it from printing UTF-8 and the best solution is using ""X509_NAME_print_ex"", but it is a bit more complex to use.

We have to set flags in order to print the UTF-8 content appropriately. We also have to explicitly unset the `ASN1_STRFLGS_ESC_MSB` flag as OpenSSL strongly enforces it but it results in an incorrect output (it accidentally removes the ""x"" from the hex encoded characters, preventing them from rendering correctly).
```c
    unsigned long flags = XN_FLAG_RFC2253 | ASN1_STRFLGS_UTF8_CONVERT | ASN1_STRFLGS_ESC_CTRL;
    flags &= ~ASN1_STRFLGS_ESC_MSB;
```
"
3113093759,2058,Move particle to netket.experimental and update tests,gcarleo,28149892,closed,2025-06-03T09:03:39Z,2025-06-05T17:33:42Z,https://github.com/netket/netket,https://github.com/netket/netket/pull/2058,"- move `netket.hilbert.Particle` to `netket.experimental.hilbert`
- update internal imports, tests, docs, and tutorial

changes to the particle interface are fully described in #2052. we can either merge #2052 first or just merge this one... 

In any case I would do this as soon as possible so to allow fast iterations on the continuous space interface, while it's in experimental "
3178928108,2068,Fix qutip conversion tests,Adrien-Kahn,73946504,closed,2025-06-26T12:15:12Z,2025-06-30T09:52:52Z,https://github.com/netket/netket,https://github.com/netket/netket/pull/2068,"`QuTiP` now automatically converts trivial `Qobj` dims like `[1, 1, 1, 1]` to `[1]`. This PR fixes the tests to account for this change of behaviour."
3100931810,2530,chore: mcp e2e clean up,JamesHenry,900523,open,2025-05-29T17:00:24Z,,https://github.com/nrwl/nx-console,https://github.com/nrwl/nx-console/pull/2530,
2971053911,1246,New lints: `#[target_feature]` changes,obi1kenobi,2348618,open,2025-04-04T01:30:45Z,,https://github.com/obi1kenobi/cargo-semver-checks,https://github.com/obi1kenobi/cargo-semver-checks/issues/1246,"As of Rust 1.86, `#[target_feature]` can be applied to safe functions, so we should look at what it means in terms of breaking changes.

Reading [the reference page for this attribute](https://doc.rust-lang.org/nightly/reference/attributes/codegen.html#the-target_feature-attribute) is highly recommended before proceeding with this issue.

Adding `#[target_feature]` to a safe pub function that didn't have it before is a major breaking change, since the function [no longer implements its corresponding `Fn()` trait](https://doc.rust-lang.org/nightly/reference/attributes/codegen.html#r-attributes.codegen.target_feature.fn-traits) — [playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2024&gist=42fe0e2362950d1716798bfa6b58ce1c)
- [x] lint for functions (deny by default): #1303
- [x] lint for `ImplOwner` methods (deny by default): #1306
- currently prohibited for safe functions in traits; no lint there

Adding `#[target_feature]` to a unsafe pub function that didn't have it before is _usually_ a major breaking change, since the safety obligations for that function have changed. The exception is if the newly-requested feature was already enabled on that target, or it's [implied by another already-requested feature](https://doc.rust-lang.org/reference/attributes/codegen.html#available-features). For example: x86-64 with any OS at all enables `sse` and `sse2` by default, and `avx2` implies `avx`. Information on whether required features are explicit or implied, or globally enabled, is available in the schema.
- [x] lint for functions (deny by default): #1302
- [x] lint for `ImplOwner` methods (deny by default): #1307 
- [x] lint for trait associated functions / methods (deny by default): #1304

If a safe pub function already had `#[target_feature]`, adding a new feature is always a major breaking change. This lint shouldn't trigger if the function became `unsafe` as well — that breakage dominates.
- [x] lint for functions (deny by default): #1332
- [x] lint for `ImplOwner` methods (deny by default): #1333
- currently prohibited in safe functions in traits; no lint here

If an unsafe pub function already had `#[target_feature]`, adding a new feature is only major breaking if the feature isn't implied nor already globally enabled, as above. This lint should trigger even if the function might have become safe in the meantime.
- [x] lint for functions (deny by default): #1316
- [x] lint for `ImplOwner` methods (deny by default): #1311
- [x] lint for trait associated functions / methods (deny by default): #1315

If an unsealed trait's associated function has a feature removed from its existing `#[target_feature]` list, that's a major breaking change since [Rust currently allows impls of that trait to specify a stricter (i.e. the previous) `#[target_feature]`](https://bsky.app/profile/predr.ag/post/3llxaktvurk2b) without any warning. Such downstream impls may suddenly be hit with UB when a caller that uses `impl Trait` or `dyn Trait` with their impl (with stricter target feature requirements) is used based on the *trait's* looser declared target feature requirements. The exception to the breakage is when the removed feature continues to be implied by either the platform (see above x86-64 example) or by another feature that remains declared.
- [x] lint for unsealed trait associated functions / methods (deny by default): #1337
- [x] lint for public API sealed trait associated functions / methods (warn by default): #1339

If a function, method, or trait function gains a target feature requirement that is not valid for the current target triple, that change renders that function / method / trait function unusable on that target triple. This is in itself a major breaking change, and applies regardless of whether the function is safe or unsafe.
- [ ] function is no longer callable on the current target triple because it now requires a feature not valid on that target
- [ ] same as above, but for methods / associated functions
- [ ] same as above, but for trait functions

## Related false-positives

`#[target_feature]` also appears to trigger a bug in rustdoc JSON that causes false-positives in two of our lints: `function_unsafe_added` and `inherent_method_unsafe_added`. The cause is this: https://github.com/rust-lang/rust/issues/142655

## Open questions
- ~~How do we find out which features are effectively implied by which target? This seems to be one of those things that ""everyone knows"" but isn't really written down directly in that explicit form.~~ (answered below)
- ~~How do we figure out which target's ""implied"" rules we should be looking at in `cargo-semver-checks`? We may have to ask `rustdoc` to describe the target while generating rustdoc JSON.~~
- ~~How do we encode the ""implies"" rules? Do we put them in the schema (as ""adapter magic""), or do we make some wild pile of regexes, or something else?~~ (answered below)
- With regard to the above, how will we handle cases when new features are added to the list? We may only support target features that are considered stable (i.e. ""unstable features don't auto-enable any other features and are never automatically enabled themselves""), and rely on stabilization announcements to be notified of changes."
3055832106,4714,Okteto namespace list outputting options,seanson,603619,closed,2025-05-12T06:49:49Z,2025-05-28T11:19:19Z,https://github.com/okteto/okteto,https://github.com/okteto/okteto/issues/4714,"**Is your feature request related to a problem? Please describe.**
When running automation using the Okteto CLI it can be flaky and difficult to capture output from `okteto namespace list` as it only supports plain text output with a `*` to denote active namespaces, compared to `okteto previews list` which has a JSON or YAML format output that can be parsed.

**Describe the solution you'd like**
The same output format options for `okteto namespace list`

**Describe alternatives you've considered**
Currently using some grep commands as an alternative.

**Additional context**
Looking at the code for namespaces and previews there seems to be two ways of constructing cobra commands. Is `cmd/preview/list.go` the preferred pattern if I was to contribute a similar function for `cmd/namespace/list.go`?"
3098786999,1951,[feat] Undo/Redo feature,homebodify,42330394,closed,2025-05-28T23:36:36Z,2025-06-11T19:18:44Z,https://github.com/onlook-dev/onlook,https://github.com/onlook-dev/onlook/issues/1951,"#### Describe the feature

As a designer, I use keyboard shortcuts for Undo (CMD+Z) and Redo (CMD+SHIFT+Z) even in Figma and other browser-based tools. Since this feature doesn't seem to be available, the browser tab's Undo/Redo gets triggered instead, which is often confusing. If this could be considered, I think it would help me focus better on my work."
3122798106,32,Getting access to raw response object in a Guardrail?,Manouchehri,7232674,closed,2025-06-05T21:55:10Z,2025-06-16T17:05:48Z,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/32,"Inside a Guardrail, is there a way I can access the raw response object? e.g. I am trying to read `prompt_filter_results` in my Guardrail. Example response object: 

```json
{
  ""choices"": [
    {
      ""content_filter_results"": {

      },
      ""finish_reason"": ""tool_calls"",
      ""index"": 0,
      ""logprobs"": null,
      ""message"": {
        ""annotations"": [],
        ""content"": null,
        ""refusal"": null,
        ""role"": ""assistant"",
        ""tool_calls"": [
          {
            ""function"": {
              ""arguments"": ""{}"",
              ""name"": ""transfer_to_History_Tutor""
            },
            ""id"": ""call_UsPG83icg4t0pZsf1uQWI97W"",
            ""type"": ""function""
          }
        ]
      }
    }
  ],
  ""created"": 1749158752,
  ""id"": ""chatcmpl-BfCNsjM9bfc3k7Dj3vnGZlN6Zmp5V"",
  ""model"": ""gpt-4.1-nano-2025-04-14"",
  ""object"": ""chat.completion"",
  ""prompt_filter_results"": [
    {
      ""prompt_index"": 0,
      ""content_filter_results"": {
        ""hate"": {
          ""filtered"": false,
          ""severity"": ""low""
        },
        ""jailbreak"": {
          ""filtered"": false,
          ""detected"": true
        },
        ""self_harm"": {
          ""filtered"": false,
          ""severity"": ""safe""
        },
        ""sexual"": {
          ""filtered"": false,
          ""severity"": ""safe""
        },
        ""violence"": {
          ""filtered"": false,
          ""severity"": ""safe""
        }
      }
    }
  ],
  ""system_fingerprint"": ""fp_68472df8fd"",
  ""usage"": {
    ""completion_tokens"": 15,
    ""completion_tokens_details"": {
      ""accepted_prediction_tokens"": 0,
      ""audio_tokens"": 0,
      ""reasoning_tokens"": 0,
      ""rejected_prediction_tokens"": 0
    },
    ""prompt_tokens"": 200,
    ""prompt_tokens_details"": {
      ""audio_tokens"": 0,
      ""cached_tokens"": 0
    },
    ""total_tokens"": 215
  }
}
```"
3140202091,92,Azure OpenAI Completions API - Prompt annotations cause NULL reference exception,desmondpp,64268953,closed,2025-06-12T13:00:38Z,2025-06-12T22:34:16Z,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/92,"### Describe the bug

When streaming an agent response using the completions API with an Azure OpenAI endpoint, prompt annotations are returned from the model where the choices propery is `[]`. The following code does not adequately handle a choices property that exists, but contains no elements:
```
        if (!chunk.choices || !chunk.choices[0].delta)
            continue;
```

This results in a `Cannot read properties of undefined (reading 'delta')` error. 

### Debug information

- Agents SDK version: (e.g. `v0.0.7`)
- Runtime environment (e.g. `Node.js 22.16.0`)

### Repro steps

Use an Azure OpenAI endpoint with any prompt and the following set:

```
setOpenAIAPI('chat_completions');
const stream = await runner.run(agent, messages, {
      stream: true,
    });
```

### Expected behavior

At a minimum, the prompt annotations should be ignored and the streamed chat completion should resume.
"
3142585706,99,NaN in part.usage.promptTokens causes exception in @openai/agents-extensions,physihan,20788562,closed,2025-06-13T07:34:09Z,2025-06-16T16:47:14Z,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/99,"
**Description**:
When using the OpenAI SDK, I encountered an issue where `part.usage.promptTokens` (or `completionTokens`) returned `NaN`, which led to exceptions being thrown during runtime. This seems to occur when the backend model fails to populate the `usage` field correctly.

**Location in Code**:
`node_modules/@openai/agents-extensions/dist/aiSdk.mjs`
Specifically in the `finish` case handler (around line 505).

```diff
- usagePromptTokens = part.usage.promptTokens;
- usageCompletionTokens = part.usage.completionTokens;
+ usagePromptTokens = Number.isNaN(part.usage?.promptTokens) ? 0 : part.usage?.promptTokens;
+ usageCompletionTokens = Number.isNaN(part.usage?.completionTokens) ? 0 : part.usage?.completionTokens;
```

**Suggested Fix**:
The patch shown above makes the code resilient to `NaN` values in the `usage` field by falling back to `0`. A similar patch was also applied in `aiSdk.js`.

**Steps to Reproduce**:

1. Trigger a call to an OpenAI-compatible model with an agent extension.
2. Receive a partial response where `usage.promptTokens` is `NaN`.
3. SDK throws an exception due to math operations involving `NaN`.

**Expected Behavior**:
The SDK should handle `undefined` or `NaN` usage tokens gracefully and continue execution without throwing.

**Environment**:

* `@openai/agents-extensions` version: \[include version]
* Node.js version: \[include version]
* Runtime: \[e.g., Node, browser, edge function, etc.]

"
3142694887,100,Would it be possible to expose `callId` in tool lifecycle events for better tracking?,physihan,20788562,closed,2025-06-13T08:15:49Z,2025-06-16T16:02:30Z,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/100,"
**Description:**

I've been exploring how to track individual tool calls across their lifecycle using the OpenAI Agents JS SDK. I noticed that the `agent_tool_start` and `agent_tool_end` events don't seem to include a `callId` or similar identifier, which makes it a bit tricky to correlate the beginning and end of a specific tool call—especially when a tool may be invoked multiple times concurrently.

## Question / Suggestion

Is there a reason why `callId` (which I believe is used internally to track tool invocations) isn't exposed in the tool lifecycle events?

If it's technically feasible, would it make sense to include it in the emitted events like so?

```ts
agent_tool_start: [
  context: RunContext<TContext>,
  agent: Agent<TContext, TOutput>,
  tool: Tool,
  callId: string  // <- possible addition?
];

agent_tool_end: [
  context: RunContext<TContext>,
  agent: Agent<TContext, TOutput>,
  tool: Tool,
  result: string,
  callId: string  // <- possible addition?
];
```

## Why This Might Help

Having access to something like `callId` would be useful for:

* Linking `agent_tool_start` and `agent_tool_end` for the same tool call
* Measuring execution time for individual tool invocations
* Debugging and monitoring concurrent tool usage
* Correlating human approval workflows with specific tool executions

## Current Workaround

At the moment, I'm considering workarounds like generating my own unique IDs per tool invocation, but that feels redundant if the SDK already generates and tracks a `callId` internally.

## Curious to Know

If there's already a way to do this or a better recommended approach, I’d love to hear about it!

"
3147282604,107,`TypeError` when handling streamed final usage chunk with `choices: []`,stanoswald,53464809,closed,2025-06-15T09:23:42Z,2025-06-15T15:27:01Z,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/107,"### Please read this first

- ✅**Have you read the docs?**
- ✅**Have you searched for related issues?**

### Describe the bug

When using an OpenAI-API compatible provider , the streamed response may include a final chunk with `choices: []`. The `convertChatCompletionsStreamToResponses` function in `openaiChatCompletionsStreaming.ts` assumes chunk.choices[0] exists, and throws:

```
TypeError: Cannot read properties of undefined (reading 'delta')
```
This is due to this line:
```
if (!chunk.choices?.[0]?.delta) continue;
```
This line assumes `chunk.choices` is non-empty, but according to the [OpenAI Chat Completions Streaming API documentation](https://platform.openai.com/docs/api-reference/chat-streaming/streaming#chat-streaming/streaming-choices):

> **choices**: Can also be empty for the last chunk if you set `stream_options: {""include_usage"": true}`.

So `choices: []` seems a valid case, and should be handled gracefully by the SDK for compatibility with OpenAI-compatible providers.

### Debug information

- Agents SDK version: (e.g. `v0.0.7`)
- Runtime environment (e.g. `Node.js 22.11.0`)"
3162483932,130,Tracing fails with Unicode characters in OpenAI Agents SDK,JahanzaibTayyab,48027944,open,2025-06-20T09:07:48Z,,https://github.com/openai/openai-agents-js,https://github.com/openai/openai-agents-js/issues/130,"### Please read this first

- **Have you read the docs?** [Agents SDK docs](https://openai.github.io/openai-agents-js/)
- **Have you searched for related issues?** Others may have faced similar issues.

### Describe the bug

When using the OpenAI Agents SDK with tracing enabled, the exporter fails if any string (e.g., prompt or metadata) contains characters outside the Latin-1 (ISO-8859-1) range — such as Unicode curly quotes (`“` or `”`, code point 8220). This throws an internal `TypeError` in `undici`.

### Debug information

- Agents SDK version: ""@openai/agents"": ""^0.0.9"",
- Runtime environment ( `Node.js 22.16.0`)

![Image](https://github.com/user-attachments/assets/4577bcc6-2aa5-4373-bd41-7136c6099e44)
![Image](https://github.com/user-attachments/assets/e4d0da4f-2bbd-4ed9-baff-78a6d8c370b0)
"
3050576884,668,Infinite recursion in src/agents/extensions/visualization.py due to circular references,qinqiang2000,27554333,closed,2025-05-09T02:42:38Z,2025-05-23T17:00:12Z,https://github.com/openai/openai-agents-python,https://github.com/openai/openai-agents-python/issues/668,"## Issue Description
The functions `get_all_nodes` and `get_all_edges` in `src/agents/extensions/visualization.py` can lead to infinite recursion when there are circular references between agents (when agents form a cycle through handoffs).

## Current Behavior
When agents have circular references through handoffs, the visualization functions will recursively traverse the agent graph without any cycle detection, leading to infinite recursion and eventual stack overflow.

## Expected Behavior
The visualization functions should handle circular references gracefully by detecting cycles and preventing repeated traversal of the same agents.

## Proposed Solution
Add a `visited` set to track already visited agents and prevent repeated recursion. Here's a sketch of the fix:

```python
def get_all_nodes(agent: Agent, parent: Optional[Agent] = None, visited: Optional[set] = None) -> str:
    if visited is None:
        visited = set()
    if agent.name in visited:  # Prevent infinite recursion
        return """"
    visited.add(agent.name)
    # ... rest of the function ...
```

Similar changes would be needed for `get_all_edges`."
3083968118,743,Added RunErrorDetails object for MaxTurnsExceeded exception,DanieleMorotti,58258368,closed,2025-05-22T16:39:58Z,2025-05-29T20:11:33Z,https://github.com/openai/openai-agents-python,https://github.com/openai/openai-agents-python/pull/743,"### Summary

Introduced the `RunErrorDetails` object to get partial results from a run interrupted by `MaxTurnsExceeded` exception. In this proposal the `RunErrorDetails` object contains all the fields from `RunResult` with `final_output` set to `None` and `output_guardrail_results` set to an empty list. We can decide to return less information.

@rm-openai At the moment the exception doesn't return the `RunErrorDetails` object for the streaming mode. Do you have any suggestions on how to deal with it? In the `_check_errors` function of `agents/result.py` file.

### Test plan

I have not implemented any tests currently, but if needed I can implement a basic test to retrieve partial data.

### Issue number

This PR is an attempt to solve issue #719 

### Checks

- [✅ ] I've added new tests (if relevant)
- [ ] I've added/updated the relevant documentation
- [ ✅] I've run `make lint` and `make format`
- [ ✅] I've made sure tests pass"
3142546269,860,name_override not respected when use_docstring_info=False due to missing parentheses in func_name assignment in function_schema,HafizFasih,161964251,closed,2025-06-13T07:18:23Z,2025-06-15T19:46:44Z,https://github.com/openai/openai-agents-python,https://github.com/openai/openai-agents-python/issues/860,"### Describe the bug
A clear and concise description of what the bug is.

In the *function_schema* method of the OpenAI Agents SDK, the following line:

```func_name = name_override or doc_info.name if doc_info else func.__name__```

does not honor name_override when use_docstring_info=False. This happens because of operator precedence in Python. Without parentheses, the expression is interpreted as:

```func_name = (name_override or doc_info.name) if doc_info else func.__name__```
So when doc_info is None, even if name_override is set, it falls back to func.__name__.

### Debug information
- Agents SDK version: (e.g. `v0.0.3`)
- Python version (e.g. Python 3.10)

### Repro steps

from agents.function_schema import function_schema

def my_func():
    pass

schema = function_schema(
    my_func,
    name_override=""CustomName"",
    use_docstring_info=False
)

print(schema.name)  # Expected: ""CustomName"", Actual: ""my_func""


### Expected behavior
Even when use_docstring_info=False, if name_override is provided, it should be used for func_name.

Suggested Fix:
Update this line:
func_name = name_override or doc_info.name if doc_info else func.__name__
To this (with parentheses to enforce correct evaluation):
func_name = name_override or (doc_info.name if doc_info else func.__name__)
"
3136733006,27435,5.x merge 4.x,asmorkalov,2536374,closed,2025-06-11T12:56:52Z,2025-06-12T09:34:15Z,https://github.com/opencv/opencv,https://github.com/opencv/opencv/pull/27435,"OpenCV Contrib: https://github.com/opencv/opencv_contrib/pull/3951

#26299 from s-trinh:feat/getClosestEllipsePoints_2
#27149 from liane-lin:4.x
#27153 from 03kiko:fix-videowriter-writing-colorless-images-26276
#27362 from vrabaud:tsan
#27375 from CodeLinaro:doc_update
#27384 from Kumataro:fix27382
#27385 from CodeLinaro:doc_update
#27389 from MaximSmolskiy:add_HoughCirclesWithAccumulator_binding
#27390 from MaximSmolskiy:update_HoughLinesWithAccumulator_binding
#27393 from asmorkalov:as/elseif_hdr_parser
#27396 from abhishek-gola:hdr_bug_fix
#27398 from asmorkalov:as/relax_remap_relative
#27403 from CodeLinaro:apreetam_6thPost
#27406 from asmorkalov:as/revert_android_ipp
#27408 from KAVYANSHTYAGI:Umat-vector-contructor
#27414 from amane-ame:remap_fix
#27418 from dkurt:fix_valgrind_warnings
#27419 from FleeOvernight:fixUpdCameraId
#27422 from KAVYANSHTYAGI:codex/find-and-fix-major-repo-issue
#27428 from phanirithvij:dnn-cmake-protobuf-generate
#27430 from CodeLinaro:dsp_markdown

Previous ""Merge 4.x"": #27370"
3006927314,71,support for dynamic lsp switching (projects with multiple languages),shyraptor,18635772,closed,2025-04-20T09:59:56Z,2025-06-13T12:25:04Z,https://github.com/oraios/serena,https://github.com/oraios/serena/pull/71,"Works really well for me. 
Feel free to modify it to your liking or return it back to me for fixing."
3160279812,185,Finish type hierarchy tool,MischaPanch,35432522,open,2025-06-19T13:05:57Z,,https://github.com/oraios/serena,https://github.com/oraios/serena/issues/185,"See #169 

Even LS that claim to support 3.17 don't work properly... Most don't support it anyway

Status of PR, which was written entirely by codex and claude code: 

1. the type_hierarchy method should be renamed to inherits_from, since that's what it does
2. check tests 
3. simplify symbol resolution, use existing methods like request_containing_symbol, reduce duplication
4. the detection of whethe the reference is an inheritance reference is based on heuristics and regex, ugly af, likely can be improved"
3160376398,192,Finish MultiLanguageLS,MischaPanch,35432522,open,2025-06-19T13:37:30Z,,https://github.com/oraios/serena,https://github.com/oraios/serena/issues/192,Started in #168 and almost finished there (by codex) but conflicts need to be resolved (process isolation changed things)
1368429006,1224,Request: `view` CLI command,itsezc,33750251,open,2022-09-10T00:20:12Z,,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/1224,"### What is the problem this feature will solve?

Currently there is no way to see information related to a package, similar to that of NPM: https://docs.npmjs.com/cli/v7/commands/npm-view 

### What is the feature you are proposing to solve the problem?

A `bun view` command can be implemented that works similar to the `npm view`

### What alternatives have you considered?

N/A"
1712787294,2899,Bus Error (core dumped) regression,jkbz64,13223538,closed,2023-05-16T21:54:12Z,2023-05-21T22:44:04Z,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/2899,"### What version of Bun is running?

0.6.1

### What platform is your computer?

Linux 6.2.0-asahi-11-1-edge-ARCH aarch64 unknown

### What steps can reproduce the bug?

![image](https://github.com/oven-sh/bun/assets/13223538/cd8127ab-2a94-461e-ae1b-766efabf287d)

```js
import { ethers } from ""ethers"";

async function run() {
  const provider = new ethers.WebSocketProvider(""wss://masked-url"", 1);
  console.log(await provider.getBlockNumber());
}

run();
```

### What is the expected behavior?

It should not crash (because v0.5.9 worked)

### What do you see instead?

[1]    122718 bus error (core dumped)  bun run index.js

### Additional information

0.6.0 crashes too
ethers v6.3"
1886169523,4540,"Compat with node:net `server.listen(port, host, backlog, callback)`?",ignoramous,852289,closed,2023-09-07T15:54:56Z,2025-05-29T05:54:22Z,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/4540,"### What version of Bun is running?

0.8.1+16b4bf341acc0f4804f0b6bdf5298c180cd00366

### What platform is your computer?

Linux 5.4.0-135-generic x86_64 x86_64

### What steps can reproduce the bug?

Listening with [`server.listen(port, host, backlog, callback)`](https://nodejs.org/api/net.html#serverlistenport-host-backlog-callback) ([like we do](https://github.com/serverless-dns/serverless-dns/blob/e64a44d541e574593dd720932f3b69905c997982/src/server-node.js#L311)) does not work when the package is bundled up with `bun build --target node`. Removing `backlog` however works. 

Also I've noticed that, `bun run <entry-point>` works as-is (with the `backlog` arg) but `bun build <entry-point> --target node` doesn't.

### What is the expected behavior?

Do not expect `bun bundle <nodejs-entry-point> --target node` to behave any differently to `bun run <nodejs-entry-point>`

### What do you see instead?

The Bun process continues executing the rest of the code without reporting *any* error.

### Additional information

Coincidentally, I see the same ""bug"" (?) with Deno, too."
2028329105,7490,It is impossible do inspect Bun application inside docker using vscode,matepaiva,9984086,open,2023-12-06T11:26:03Z,,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/7490,"### What version of Bun is running?

docker oven/bun:1-slim

### What platform is your computer?

docker

### What steps can reproduce the bug?

1. create a simple bun application.
2. add a script to your package.json like `""watch"": ""bun --hot --inspect=ws://0.0.0.0:6499/forcingPrefix index.ts ""`
3. create a Dockerfile to run it, like:
```
FROM oven/bun:1-slim as base
COPY . .
RUN bun install

USER bun

ENV NODE_ENV=development

EXPOSE 3000/tcp
EXPOSE 6499/tcp

CMD [""bun"", ""watch""]
```
4. create a docker-compose.yaml, like:
```
version: ""3.8""

services:
  bun-app:
    build: ./html-to-image-bun-server
    ports:
      - ""3001:3000""
      - ""6499:6499""
    expose:
      - 6499
    volumes:
      - ./html-to-image-bun-server:/home/bun/app
```
5. run `docker compose up`
6. create a `.vscode/launch.json` like:
```
{
  ""version"": ""0.2.0"",
  ""configurations"": [
    {
      ""type"": ""bun"",
      ""request"": ""attach"",
      ""name"": ""Attach to Bun"",
      ""url"": ""ws://127.0.0.1:6499/forcingPrefix"",      
    }
  ]
}
```
7. start debugging via vscode using ""Attach to Bun"" option. It starts fine.
8. add a breakpoint to any line and do something (a request) to run that line. It will not stop at the line, but it should! ❌ 


### What is the expected behavior?

I should be able to inspect a bun application inside a docker via websocket, but it does not work as supposed.

### What do you see instead?

I can inspect it using the web bun debugger, but it does not work at vscode.

### Additional information

Instead of ""0.0.0.0"", I tried to pass different values to inspect (at package.json and at launch.json), like ""localhost"" or ""127.0.0.1"". It does not work."
2855586912,17362,support `Bun.file` on static routes,TiBianMod,6713842,closed,2025-02-15T16:29:48Z,2025-06-11T02:41:22Z,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/17362,"### What version of Bun is running?

1.2.2+c1708ea6a

### What platform is your computer?

Darwin 24.3.0 x86_64 i386

### What steps can reproduce the bug?

`index.ts`

```ts
import { serve } from ""bun"";

serve({
    port: 3000,
    static: {
        ""/static"": new Response(Bun.file(""/path/to/file.html"")),
    },
    fetch: () => new Response(""fallback""),
});
```

`bun index.ts`

### What is the expected behavior?

_No response_

### What do you see instead?

**TODOError: TODO: support Bun.file(path) in static routes**

### Additional information

_No response_"
3101476920,20028,"Revert ""Add net autoselectfamily default test (#19970)""",190n,7763597,closed,2025-05-29T21:01:12Z,2025-05-29T21:53:45Z,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/pull/20028,"### What does this PR do?

This reverts PR #19970 since it seems to be the one that broke test-http-pipeline-requests-connection-leak:

- it failed on that PR: https://buildkite.com/bun/bun/builds/17526
- it passed in #18962 (https://buildkite.com/bun/bun/builds/17511) which was the immediate parent of that PR

(The diff on `net.ts` here is smaller than in #19970 since the rest of #19970 was already reverted in #20002)

### How did you verify your code works?

Will see what CI says"
3166225152,20565,Missing `Math.sumPrecise()`,i-love-neko-girls,208837966,closed,2025-06-22T19:55:14Z,2025-06-23T02:23:16Z,https://github.com/oven-sh/bun,https://github.com/oven-sh/bun/issues/20565,"### What version of Bun is running?

1.2.17+282dda62c

### What platform is your computer?

Darwin 24.0.0 arm64 arm

### What steps can reproduce the bug?

`bun --print 'Math.sumPrecise'`

### What is the expected behavior?

`[Function: sumPrecise]`

### What do you see instead?

`undefined`

### Additional information

[Bun v1.2.17 changelog](https://bun.sh/blog/bun-v1.2.17) mentioned:
> `Math.sumPrecise` implements Radford M. Neal's xsum algorithm with a large superaccumulator for arrays with more than 1,000 elements, which is 10% faster on large datasets

but `Math.sumPrecise` is missing in Bun"
3157040319,3,Support `--output-formatter`,possibilities,502777,open,2025-06-18T14:08:29Z,,https://github.com/possibilities/claude-composer,https://github.com/possibilities/claude-composer/issues/3,"If you use `--print` and `json` or `stream-json` with `--output-format`, `claude-composer` should be able to invoke your preferred formatting tool. By default it will be unset. When running `cc-init` setting it to `jq` or not setting it are provided as options (and `cc-config` will support a `--use-jq-as-output-formatter`, `--no-use-jq-as-output-formatter`).

Whatever the tool is set to will be ""piped through"" when ""json"" or ""stream-json"" output is selected.

cc @neilellis

"
974713354,7321,Resizing creatives is incompatible with Google's anchor ads,dmitriyshashkin,11873939,open,2021-08-19T14:17:29Z,,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/7321,"## Type of issue
Bug

## Description
Google recently released new ad format: anchor ads. Basically google's implementation of sticky units https://developers.google.com/publisher-tag/samples/display-anchor-ad

And overall prebid works great with them. The only problem is that this anchor ad takes the whole width of the screen. And if the ad is shorter, google takes care of positioning it in the center. The ad is positioned in the `<ins>` container which takes care of floating, inside it there is a `div` that has width set to 100% and inside this `div` there is an `iframe` element centered through margin auto.

Unfortunately once the ad is rendered Prebid sets width for both the div and the iframe equal to the width specified in the bid oblect. https://github.com/prebid/Prebid.js/blob/master/src/secureCreatives.js#L100  Which breaks the horizontal alignment. It can probably be fixed by adding text-align: center to the `<ins>` element, but I'm not sure whether it's a good idea to tamper with google's styles. And perhaps this should be handled on prebid's side, not by each of the publishers individually.

## Steps to reproduce
1. Create out of the page ad unit of anchor type.
2. Let HB bid with size 320x50 win.

### Expected results
Ad is horizontally centered

### Actual results
Ad is skewed to the left

![Screenshot from 2021-08-19 15-59-40](https://user-images.githubusercontent.com/11873939/130084217-bae22318-db6a-48bf-bab9-32ed944093ed.png)"
1254060275,8500,Application/json connection concerns,patmmccann,1683175,closed,2022-05-31T15:42:22Z,2022-06-30T18:53:12Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/8500,https://github.com/prebid/Prebid.js/pull/8498 indicates ajax type application/json causes performance issues. A quick search indicates it is used widely in the project. Should this be remedied? 
1746051043,10062,Interest on Yielding on the Main Thread to optimize UX of sites using prebid.js?,gilbertococchi,329023,closed,2023-06-07T14:31:42Z,2025-06-26T17:51:51Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/10062,"## Type of issue
Feature Request

## Description
Chrome recently announced that  [INP](https://web.dev/inp/) will become a Core Web Vitals Metric.
To optimize User Experience as INP suggest it's a good approach for 1P and 3P developers to Yield on the Main thread and reduce Long Tasks when possible.

[https://web.dev/optimize-long-tasks/](https://web.dev/optimize-long-tasks/) is a great article that covers the different methodologies to Yield on the Main Thread.

Some of these methods are available (like scheduler.postTask) and some others will be shortly available via origin Trival (scheduler.yield).

It would be positive if prebid.js as well as other 3Ps libraries used by websites would Yield on the Main Thread, so in case of User Interaction, the Browser will be able to Render the Next Frame.

In the Screenshot you can see the Long Task generated by the prebid.js Example container taken [from this link](https://docs.prebid.org/dev-docs/examples/basic-example.html)

<img width=""709"" alt=""prebid"" src=""https://github.com/prebid/Prebid.js/assets/329023/e03696f7-19ed-41d4-9bbe-fe52c9e8a50f"">

Would there be any interest from prebid.js Library owners to consider some of this approach in order to allow Prebid.js to work as usual while reducing it's Main Thread blocking time?

happy to chat more about this.
Gilberto
"
1845771210,10348,"Integration examples ""failsafe"" logic does not fail safely",dgirardi,10151381,closed,2023-08-10T19:28:48Z,2025-05-27T17:20:50Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/10348,"## Type of issue

Bug?

## Description

Many integration examples, both here and in documentation, use this pattern:

https://github.com/prebid/Prebid.js/blob/04c757032048c1fe7ec5e5d1cf9e821a8ca2a7bb/integrationExamples/gpt/hello_world.html#L55-L68

The idea is that after a certain time, if Prebid didn't work, we want to yield to the ad server. However, that logic still relies on Prebid - and if Prebid is up and running, we might as well include the failsafe in it, rather than asking the publisher to do it.

I think the original intent was to also handle the case where Prebid failed to load, which could be done with something like:

```javascript
function sendAdserverRequest() {    
    if (pbjs.adserverRequestSent) return;
    pbjs.adserverRequestSent = true;
    googletag.cmd.push(function() {
        if (pbjs.libLoaded) {
            pbjs.que.push(function() {
                pbjs.setTargetingForGPTAsync();
                googletag.pubads().refresh();
            });
       } else {
          googletag.pubads().refresh();           
       }
    });
}
```

"
2156633102,11148,Q: Why browsingTopics: true by default on all outgoing bidder requests?,orazumov-zeta,99964372,closed,2024-02-27T13:44:34Z,2025-06-20T23:39:45Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/11148,"## Type of issue
Question

## Description
Why `browsingTopics: true` by default on outgoing bidder requests? ([sources](https://github.com/prebid/Prebid.js/blob/98162dc9d9b5318ea7042e4a23c5ef1d7b8b4c27/src/adapters/bidderFactory.js#L465C45-L465C59))
Related PR: _Core: enable Sec-Browsing-Topics header on outgoing bidder requests_ https://github.com/prebid/Prebid.js/pull/10340

<img width=""900"" alt=""image"" src=""https://github.com/prebid/Prebid.js/assets/99964372/20807479-90fd-45e0-9bbe-4f2b769b5b64"">

Not all bidders support this. As a result, in Chrome console, I see numerous errors of the type '**Attestation check for Topics on _URL_ failed.**' There is an option '**topicsHeader**' to control this. Perhaps it would be better to have browsingTopics enabled not by default, but only when this option is explicitly specified?

## Steps to reproduce
Open the Chrome browser console on any page where Prebid.js is running with configured bidders that do not support browsingTopics (for example, appnexus, mediafuse, sovrn, minutemedia, etc.). You will see errors **Attestation check for Topics on _URL_ failed.**

<img width=""803"" alt=""image"" src=""https://github.com/prebid/Prebid.js/assets/99964372/5a0c892c-38ee-4ca4-9de5-78d3f6ab5ebe"">

## Test page
Here you can see such error: https://www.bmwblog.com/2024/02/26/how-a-bmw-7-series-turned-from-city-cruiser-to-off-road-adventurer/

### Expected results

### Actual results

## Platform details
Prebid.js 8.35
Chrome 121.0.6167.184 (Official Build) (arm64)

## Other information
[Core: enable Sec-Browsing-Topics header on outgoing bidder requests](https://github.com/prebid/Prebid.js/pull/10340)
"
2483316114,12171,Various modules: jsdoc fixes,patmmccann,1683175,closed,2024-08-23T14:49:42Z,2025-05-23T12:18:42Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/12171,"Vendor js doc to fix:

Can be seen from https://app.circleci.com/pipelines/github/prebid/Prebid.js/23090/workflows/d4cff7dd-79c6-4e36-8b89-6e4aabb93b1a/jobs/40877 in the linter warnings

- [ ] /modules/1plusXRtdProvider.js
- [ ] /modules/33acrossAnalyticsAdapter.js
- [ ] /modules/adhashBidAdapter.js
- [ ] /modules/adlooxRtdProvider.js
- [ ] /modules/adotBidAdapter.js
- [ ] /modules/adplusBidAdapter.js
- [ ] /modules/adtelligentBidAdapter.js
- [ ] /modules/adyoulikeBidAdapter.js
- [ ] /modules/bliinkBidAdapter.js
- [ ] /modules/concertBidAdapter.js
- [ ] /modules/consumableBidAdapter.js
- [ ] /modules/criteoIdSystem.js
- [ ] /modules/dailymotionBidAdapter.js
- [ ] /modules/datawrkzBidAdapter.js
- [ ] /modules/discoveryBidAdapter.js
- [ ] /modules/dmdIdSystem.js
- [ ] /modules/dsp_genieeBidAdapter.js
- [ ] /modules/dxkultureBidAdapter.js
- [ ] /modules/fabrickIdSystem.js
- [ ] /modules/feedadBidAdapter.js
- [ ] /modules/gmosspBidAdapter.js
- [ ] /modules/hybridBidAdapter.js
- [ ] /modules/iasRtdProvider.js
- [ ] /modules/identityLinkIdSystem.js
- [ ] /modules/idxIdSystem.js
- [ ] /modules/impactifyBidAdapter.js
- [ ] /modules/improvedigitalBidAdapter.js
- [ ] /modules/integr8BidAdapter.js
- [x] /modules/intentIqIdSystem.js
- [ ] /modules/ivsBidAdapter.js
- [ ] /modules/jixieBidAdapter.js
- [ ] /modules/kinessoIdSystem.js
- [ ] /modules/lemmaDigitalBidAdapter.js
- [ ] /modules/limelightDigitalBidAdapter.js
- [ ] /modules/lmpIdSystem.js
- [ ] /modules/malltvBidAdapter.js
- [ ] /modules/mediaforceBidAdapter.js
- [ ] /modules/mediagoBidAdapter.js
- [ ] /modules/medianetBidAdapter.js
- [ ] /modules/mediasquareBidAdapter.js
- [ ] /modules/merkleIdSystem.js
- [ ] /modules/missenaBidAdapter.js
- [ ] /modules/mwOpenLinkIdSystem.js
- [ ] /modules/nativoBidAdapter.js
- [ ] /modules/netIdSystem.js
- [ ] /modules/neuwoRtdProvider.js
- [ ] /modules/nextrollBidAdapter.js
- [ ] /modules/nobidBidAdapter.js
- [ ] /modules/novatiqIdSystem.js
- [ ] /modules/onetagBidAdapter.js
- [ ] /modules/operaadsBidAdapter.js
- [ ] /modules/optidigitalBidAdapter.js
- [ ] /modules/orbidderBidAdapter.js
- [ ] /modules/pilotxBidAdapter.js
- [ ] /modules/prismaBidAdapter.js
- [ ] /modules/pubwiseBidAdapter.js
- [ ] /modules/qortexRtdProvider.js
- [ ] /modules/radsBidAdapter.js
- [ ] /modules/raynRtdProvider.js
- [ ] /modules/relevadRtdProvider.js
- [ ] /modules/retailspotBidAdapter.js
- [x] /modules/rubiconBidAdapter.js
- [x] /modules/seedtagBidAdapter.js
- [ ] /modules/slimcutBidAdapter.js
- [ ] /modules/smartadserverBidAdapter.js
- [ ] /modules/sovrnBidAdapter.js
- [ ] /modules/stvBidAdapter.js
- [ ] /modules/sublimeBidAdapter.js
- [ ] /modules/teadsBidAdapter.js
- [ ] /modules/temedyaBidAdapter.js
- [ ] /modules/theAdxBidAdapter.js
- [ ] /modules/ttdBidAdapter.js
- [ ] /modules/ucfunnelBidAdapter.js
- [ ] /modules/utiqIdSystem.js
- [ ] /modules/utiqMtpIdSystem.js
- [ ] /modules/viantOrtbBidAdapter.js
- [ ] /modules/vibrantmediaBidAdapter.js
- [ ] /modules/videobyteBidAdapter.js
- [ ] /modules/viewdeosDXBidAdapter.js
- [ ] /modules/viouslyBidAdapter.js
- [ ] /modules/voxBidAdapter.js
- [ ] /modules/welectBidAdapter.js
- [ ] /modules/yieldoneBidAdapter.js
- [ ] /modules/zeotapIdPlusIdSystem.js
"
2856056983,12772,IX Diagnostic Param Filtering Out Live Intent,zachsavishinsky,33969235,closed,2025-02-16T11:58:26Z,2025-06-11T12:13:22Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/12772,"I am not exactly sure the ramifications of this, or if this is actually an issue, but I came across something that appears to be slightly off.  In the IX bid adapter, the diagnostics object calls _getUserIds() to set the userIds param.  This then compares the user ids to the hardcoded PROVIDERS array.  

As you can see here:
https://github.com/prebid/Prebid.js/blob/d27b0c2e888beb1fbd9545a37e5a7722ad2515d5/modules/ixBidAdapter.js#L64

lipbid is defined, however it seems that the key when you call pbjs.getUserIds() is actually lipb, which is an object of what looks to be SSP specific ids (lipbid being a child object).

As such, it seems that lipbid doesn't get passed into the diagnostic object."
2915343723,12879,Typescript support,dgirardi,10151381,closed,2025-03-12T22:59:27Z,2025-06-12T11:13:35Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/pull/12879,"## Type of change
<!-- Remove items that don't apply and/or select an item by changing [ ] to [x] -->
- [x] Feature

## Description of change

Change the build system, extracting a ""precompilation"" step that runs before the normal build.

Precompilation consists of:
 - the typescript type checker (no compilation except for the extraction of declaration / `.d.ts`)
 - babel transpilation, including transpilation of typescript files. 

The output of precompilation is thus a collection of paired *standard* `.js` and `.d.ts` files; standard in the sense that they are like the original source files (no module system transformation), minus prebid-specific things (`FEATURES`, `$$MACRO$$`, etc). 
Pending some changes to the release process, these could be used as a ""consumer"" version for npm consumers, without the need for special babel configuration; and the type definitions should then be available as well.
They are also used as input for the rest of the (webpack) build.


This is a WIP - initial version has no typescript code at all, but leaving this open to allow folks to contribute their type definitions.


## Other information

Related: 
https://github.com/prebid/Prebid.js/issues/5287
https://github.com/prebid/Prebid.js/issues/5097
https://github.com/prebid/Prebid.js/pull/11166


"
3008396877,13012,PBS adapter including ad units without bids/bidders,Sir-Will,5961995,closed,2025-04-21T13:15:56Z,2025-07-01T15:47:15Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/13012,"The `prebidServerBidAdapter` does not seem to filter out ad units which don't have any bids/bidders configured. This causes PBS to reject the request and ad units with bidders being affected.

Shouldn't PBJS filter out ad units without bidders, before sending the auction request?

Something to keep in mind is that empty ad units get the `{bidder: null}` added:
https://github.com/prebid/Prebid.js/blob/7ff0e444abac35b035186b1a8482d71b2d351f39/src/adapterManager.js#L93-L95"
3024985146,13039,get rid of findIndex polyfill,patmmccann,1683175,closed,2025-04-28T13:43:01Z,2025-05-27T17:35:03Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/13039,"only used in a few places

https://github.com/search?q=repo%3Aprebid%2FPrebid.js+findIndex+polyfill.js&type=code"
3034745225,13058,convert site.content.ext.documentLang,patmmccann,1683175,closed,2025-05-01T21:24:43Z,2025-06-25T20:40:46Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/13058,"              Put `html.lang` to site.content.language by default might be bad because according to [ortb spec](https://iabtechlab.com/wp-content/uploads/2022/04/OpenRTB-2-6_FINAL.pdf) (page 27) language code comes in `ISO-639-1-alpha-2` standard, but html language attribute is `BCP 47`. I think that adding functionality that is incorrect in terms of OpenRTB specification is not the best approach; why can't we leave it optional as it is now?

_Originally posted by @PixelQuasar in https://github.com/prebid/Prebid.js/pull/12918#discussion_r2026480469_
            

We could do the conversion for some common languages, perhaps top 10? "
3094598675,13182,Fix: Ensure failsafe logic in examples fails safely,agentmoose,213664706,closed,2025-05-27T17:01:56Z,2025-05-27T17:15:40Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/pull/13182,"The failsafe timeout in many GPT integration examples was intended to refresh ads via `googletag.pubads().refresh()` if Prebid.js didn't load or respond in time. However, the original implementation of the failsafe function
(typically `sendAdserverRequest` or `initAdserver`) still attempted to call Prebid.js functions like
`pbjs.setTargetingForGPTAsync()`, which would fail if Prebid.js itself hadn't loaded.

This change modifies these failsafe functions to check for `pbjs.libLoaded` before attempting to call Prebid-specific functions.
- If `pbjs.libLoaded` is true, the original logic of calling `pbjs.setTargetingForGPTAsync()` and then `googletag.pubads().refresh()` is executed.
- If `pbjs.libLoaded` is false, only `googletag.pubads().refresh()` is called, truly acting as a failsafe for the ad server call.

This fix has been applied to 38 files within the
`integrationExamples/gpt/` directory that exhibited this pattern.

<!--
Thank you for your pull request! 

Please title your pull request like this: 'Module: Change', eg 'Fraggles Bid Adapter: support fragglerock'

Please make sure this PR is scoped to one change or you may be asked to resubmit. 
 
Please make sure any added or changed code includes tests with greater than 80% code coverage. 

See https://github.com/prebid/Prebid.js/blob/master/CONTRIBUTING.md#testing-prebidjs for documentation on testing Prebid.js.

For any user facing change, submit a link to a PR on the docs repo at https://github.com/prebid/prebid.github.io/
-->

## Type of change
<!-- Remove items that don't apply and/or select an item by changing [ ] to [x] -->
- [ ] Bugfix
- [ ] Feature
- [ ] New bidder adapter  <!--  IMPORTANT: also submit your bidder parameter documentation as noted in https://docs.prebid.org/dev-docs/bidder-adaptor.html#submitting-your-adapter -->
- [ ] Updated bidder adapter  <!--  IMPORTANT: (1) consider whether you need to upgrade your bidder parameter documentation in https://github.com/prebid/prebid.github.io/tree/master/dev-docs/bidders and (2) if you have a Prebid Server adapter, please consider whether that should be updated as well. --> 
- [ ] Code style update (formatting, local variables)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] CI related changes

- [ ] Does this change affect user-facing APIs or examples documented on http://prebid.org?
- [ ] Other

## Description of change
<!-- Describe the change proposed in this pull request -->

<!-- For new bidder adapters, please provide the following
- contact email of the adapter’s maintainer
- test parameters for validating bids:
```
{
  bidder: '<bidder name>',
  params: {
    // ...
  }
}
```

Be sure to test the integration with your adserver using the [Hello World](https://github.com/prebid/Prebid.js/blob/master/integrationExamples/gpt/hello_world.html) sample page. -->


## Other information
<!-- References to related PR or issue #s, @mentions of the person or team responsible for reviewing changes, etc. -->
"
3114593576,13258,Core: Delete src/polyfill.js,patmmccann,1683175,closed,2025-06-03T16:08:16Z,2025-06-24T15:27:05Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/pull/13258,"there are all gone, eg #13160 #13039 #13167 "
3114897844,13262,kargo and bliink bid adapter: remaining intermittent test failure on safari,patmmccann,1683175,closed,2025-06-03T17:52:02Z,2025-06-04T15:33:10Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/pull/13262,related pr #13243 ; test still fails on occasion after merge
3121484767,13280,gutil.PluginError is not a constructor,EskelCz,1198558,closed,2025-06-05T14:28:40Z,2025-06-05T18:55:22Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/13280,"When running `gulp build --modules=modules.json` with the latest build (9.47.0) I'm getting this error: `TypeError: gutil.PluginError is not a constructor`.
The root cause is probably some missing module in my json file, but the error handling should be improved.
Thanks."
3128875180,13315,Webdriver: Move to switchframe,patmmccann,1683175,closed,2025-06-09T01:26:14Z,2025-06-13T13:43:56Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/issues/13315,"
A reverted pr mentioned we should switch out this api

@jlquaccia 
I apologize for the delay. I encountered an issue where I couldn't run the tests locally. It turned out that the current tests were using a legacy API - switchToFrame (https://webdriver.io/docs/api/webdriver/#switchtoframe). I updated the WebDriver version and modified the test utilities to use the new API (switchFrame) - now all tests green, including the one that was previously failing in CI. .

_Originally posted by @Akiyamka in https://github.com/prebid/Prebid.js/issues/12979#issuecomment-2939856976_
            "
3144361775,13381,New Adapter: fwsspBidAdapter,FreeWheelVIS,4663682,closed,2025-06-13T18:13:56Z,2025-06-18T10:37:42Z,https://github.com/prebid/Prebid.js,https://github.com/prebid/Prebid.js/pull/13381,"## Type of change
- [ ] Bugfix
- [ ] Feature
- [x ] New bidder adapter  <!--  IMPORTANT: also submit your bidder parameter documentation as noted in https://docs.prebid.org/dev-docs/bidder-adaptor.html#submitting-your-adapter -->
- [ ] Updated bidder adapter  <!--  IMPORTANT: (1) consider whether you need to upgrade your bidder parameter documentation in https://github.com/prebid/prebid.github.io/tree/master/dev-docs/bidders and (2) if you have a Prebid Server adapter, please consider whether that should be updated as well. --> 
- [ ] Code style update (formatting, local variables)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] CI related changes

- [ ] Does this change affect user-facing APIs or examples documented on http://prebid.org?
- [ ] Other

## Description of change
New Adapter: fwsspBidAdapter

- contact email of the adapter’s maintainer: vis@freewheel.com
- test parameters for validating bids:
```
 {
  bidder: 'fwssp',
  params: {
      env: 'stg',
      format : 'inbanner',
      contentId : 'div-gpt-ad-1460505748561-0',
      serverUrl: 'https://81cec.v.fwmrm.net/ad/g/1',
      networkId: '96749',
      profile: '96749:global-js',
      siteSectionId: 'pause_ad_site_section',
      flags: '+play',
      videoAssetId: 'pause_ad_video',
      slau: 'midroll',
  }
}
```

A demo using the adapter can be found at https://vi.freewheel.tv/prebid-adapter-inbanner-demo/

## Other information
<!-- References to related PR or issue #s, @mentions of the person or team responsible for reviewing changes, etc. -->
"
3070947227,4051,test: add unit test for src/share.ts,gru-agent[bot],185149714,closed,2025-05-17T17:20:27Z,2025-05-17T18:20:39Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4051,"> [!WARNING]
> [Regression Alert] The existing unit tests were failing. Gru has updated them, adding coverage and ensuring they pass. Please check if this behavior is expected.

## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | sklein12 | [4050](https://github.com/promptfoo/promptfoo/pull/4050) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/94082232-d0bb-4bfc-9fe5-28af68c25615?filePath=src/share.ts) |

## Summary


This PR refactors and enhances the `share.ts` module and its associated tests. Key changes include:



### Code Changes:

1. **Export Consolidation**:

   - Added explicit exports for various utility functions in `share.ts` to improve modularity and reusability.



2. **Refactoring Test Code**:

   - Introduced a helper function `createMockEval` in `share.test.ts` to streamline the creation of mock `Eval` objects, reducing redundancy and improving readability.

   - Removed redundant mock resets and explicit mock return value setups in tests, relying on default mock behavior for cleaner test code.



3. **Enhanced Test Coverage**:

   - Added a new test case for `hasEvalBeenShared` to handle scenarios where network errors occur, ensuring robust error handling.



4. **Simplified Test Logic**:

   - Consolidated and simplified test cases for `createShareableUrl` by removing duplicate logic and combining similar scenarios.

   - Streamlined chunked vs regular sending tests, focusing on key behaviors and reducing unnecessary complexity.



### Functional Improvements:

- Improved modularity and maintainability of the `share.ts` module by consolidating exports.

- Enhanced test reliability and readability by reducing redundancy and improving mock object creation.

- Expanded test coverage to handle edge cases, such as network errors, ensuring better robustness.



These changes collectively improve the codebase's maintainability, readability, and reliability while ensuring comprehensive test coverage.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 65.28% -> 77.71%  🔺 |
| functions | 71.42% -> 85.71%  🔺 |
| statements | 65.28% -> 77.71%  🔺 |
| branches | 76.38% -> 76.38% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 22 -> 21  🔻 |
| failed | 3 -> 0  🔻 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-share-ts-1747502416191/test/share.test.ts)
"
3070993617,4053,test: add unit test for src/models/eval.ts,gru-agent[bot],185149714,closed,2025-05-17T18:48:52Z,2025-05-17T23:03:19Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4053,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | sklein12 | [4050](https://github.com/promptfoo/promptfoo/pull/4050) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/94082232-d0bb-4bfc-9fe5-28af68c25615?filePath=src/models/eval.ts) |

## Summary


This PR enhances the test coverage for the `Eval` model by adding new test cases and improving existing ones. Key updates include:



1. **New Test Cases**:

   - `fetchSampleResults`:

     - Verifies behavior when no results exist.

     - Ensures all results are returned when the sample size exceeds the available results.

   - `getResultsCount`:

     - Confirms cached count is returned when available.

     - Handles scenarios with empty results.

     - Validates behavior when no rows exist for a given `evalId`.



2. **Refactoring**:

   - Simplified the `beforeEach` setup by removing redundant comments and consolidating table cleanup logic.



These changes aim to ensure the robustness and reliability of the `Eval` model's functionality.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 69.91% -> 74.63%  🔺 |
| functions | 55.17% -> 65.51%  🔺 |
| statements | 69.91% -> 74.63%  🔺 |
| branches | 70.96% -> 70.87%  🔻 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 12 -> 17  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-models-eval-ts-1747507723134/test/models/eval.test.ts)
"
3071144437,4056,test: add unit test for src/providers/ai21.ts,gru-agent[bot],185149714,closed,2025-05-17T23:20:57Z,2025-05-17T23:31:58Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4056,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4052](https://github.com/promptfoo/promptfoo/pull/4052) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/5dfffdd1-3ec3-4317-9b17-ffedf631a923?filePath=src/providers/ai21.ts) |

## Summary


This PR introduces unit tests for the `AI21ChatCompletionProvider` class, ensuring robust validation of its functionality. Key changes include:



- **Unit Tests**:

  - Added tests to validate the construction of the provider with valid and invalid model names, including logging warnings for unknown models.

  - Verified the retrieval of API keys from both configuration and environment variables.

  - Tested the retrieval of API URLs, including default and custom configurations.

  - Ensured proper error handling when the API key is missing.

  - Simulated successful API calls and validated the response structure, including token usage.

  - Handled various error scenarios:

    - API error responses.

    - Malformed API responses.

    - Network errors.

  - Verified cost calculation based on token usage.



- **Mocking**:

  - Utilized `jest.mock` to mock dependencies like `fetchWithCache` and `logger`.



- **Exports**:

  - Added exports for `AI21_CHAT_MODELS`, `getTokenUsage`, and `calculateAI21Cost` to ensure compatibility and reusability.



This PR enhances the reliability of the `AI21ChatCompletionProvider` by thoroughly testing its core functionalities and edge cases.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 95.28%  🔺 |
| functions | 0% -> 75%  🔺 |
| statements | 0% -> 95.28%  🔺 |
| branches | 0% -> 81.39%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 12  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-providers-ai21-ts-1747524047363/test/providers/ai21.test.ts)
"
3071168072,4062,test: add unit test for src/commands/eval.ts,gru-agent[bot],185149714,closed,2025-05-18T00:02:07Z,2025-05-18T03:02:56Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4062,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| PR Created | mldangelo | [4058](https://github.com/promptfoo/promptfoo/pull/4058) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/ce686135-3b2e-4815-bfb2-cafa12adb8d6?filePath=src/commands/eval.ts) |

## Summary


This PR introduces comprehensive unit tests for the `evalCommand` function and its related utilities in the `eval.ts` file. The tests cover various scenarios and options that the `evalCommand` can handle, ensuring robustness and reliability. Key areas tested include:



- Command creation and option handling, such as `--no-cache`, `--write`, `--share`, `--grader`, `--repeat`, `--delay`, and `--maxConcurrency`.

- Integration with other modules like cache management, database migrations, API provider loading, and sharing functionality.

- Specific functions like `formatTokenUsage` and `showRedteamProviderLabelMissingWarning` are tested for correct behavior and output formatting.



The tests utilize Jest for mocking and assertions, ensuring that all dependencies and interactions are correctly simulated. This addition significantly improves the test coverage and reliability of the `evalCommand` functionality.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 62.19%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 62.19%  🔺 |
| branches | 0% -> 42.69%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 15  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-commands-eval-ts-1747526514298/test/commands/eval.test.ts)
"
3077407152,4096,test: add unit test for src/assertions/llmRubric.ts,gru-agent[bot],185149714,closed,2025-05-20T15:19:42Z,2025-05-20T15:29:52Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4096,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4090](https://github.com/promptfoo/promptfoo/pull/4090) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/e6ebf4e6-af10-4d67-81e4-454a220c5d5b?filePath=src/assertions/llmRubric.ts) |

## Summary


This PR introduces comprehensive unit tests for the `handleLlmRubric` function, ensuring robust validation of its behavior across various scenarios. Key highlights include:



- **Basic Functionality Tests**: Validates handling of different `renderedValue` types, including strings, objects, arrays, and undefined values.

- **Rubric Prompt Handling**:

  - Ensures `rubricPrompt` is correctly stringified when provided as an object or array.

  - Confirms no re-stringification occurs if `rubricPrompt` is already a string.

  - Handles cases where `rubricPrompt` is undefined or an empty object.

- **Assertion Value Logic**:

  - Tests scenarios where `assertion.value` is set or undefined, ensuring proper fallback to `test.options.rubricPrompt`.

  - Validates that `assertion.value` is not overwritten if already set.

- **Edge Cases**:

  - Handles invalid `renderedValue` types gracefully by throwing appropriate errors.

  - Ensures compatibility when `test.options` is undefined.

  - Validates handling of `rubricPrompt` as a plain object (not an array).

- **Mock Integration**: Utilizes `matchesLlmRubric` mock to simulate grading results and verify function calls.



These tests enhance the reliability and maintainability of the `handleLlmRubric` function by covering diverse input scenarios and edge cases.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 14  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-assertions-llmRubric-ts-1747754369148/test/assertions/llmRubric.test.ts)
"
3085165018,4135,test: add unit test for src/redteam/constants.ts,gru-agent[bot],185149714,closed,2025-05-23T04:59:53Z,2025-05-23T05:03:25Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4135,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| PR Created | mldangelo | [4132](https://github.com/promptfoo/promptfoo/pull/4132) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/4eb99a6c-3db7-4ac3-96fe-e4668cbfd53f?filePath=src/redteam/constants.ts) |

## Summary


This PR exports the `_ALL_STRATEGIES` constant from the `constants.ts` file, making it available for use in other parts of the codebase. No other changes or modifications are included in this update.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 100% -> 100% |
| functions | 100% -> 100% |
| statements | 100% -> 100% |
| branches | 100% -> 100% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 30 -> 30 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-ts-1747976383858/test/redteam/constants.test.ts)
"
3088939690,4152,fix(webui): defaultTest shown in webui YAML editor,adelmuursepp,42273596,closed,2025-05-25T00:36:51Z,2025-05-25T22:57:02Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4152,"Relates to https://github.com/promptfoo/promptfoo/issues/4031

Additionally noted during testing:
- Default ordering of the config is confusing, with defaultTest being at the bottom in edit YAML
- evaluateOptions is not shown in the specific eval page -> View YAML
- defaultTest recent addition is visible in the top in the specific eval page -> View YAML (description should be the top)"
3089034748,4155,"docs: move ""copy page"" button to bottom",typpo,310310,closed,2025-05-25T04:34:35Z,2025-05-26T04:06:45Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4155,"
and make it match edit page

<img width=""1010"" alt=""image"" src=""https://github.com/user-attachments/assets/9400d2fe-35b9-43dd-8a9c-a741e2e25e8a"" />"
3090057069,4161,test: add unit test for src/redteam/constants.ts,gru-agent[bot],185149714,closed,2025-05-26T05:33:16Z,2025-05-26T06:06:52Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4161,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4131](https://github.com/promptfoo/promptfoo/pull/4131) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/6314a158-e344-4713-8bc9-9fb0e30347e4?filePath=src/redteam/constants.ts) |

## Summary


### PR Summary



This PR introduces the following changes:



1. **Export `_ALL_STRATEGIES`**:

   - Added `_ALL_STRATEGIES` to the exports in `constants.ts`.



2. **New Constants for Exempt Plugins**:

   - Introduced three new constants in `constants.ts`:

     - `AGENTIC_EXEMPT_PLUGINS`: Contains plugins exempt from agentic strategies (`['system-prompt-override', 'tool-discovery:multi-turn']`).

     - `DATASET_EXEMPT_PLUGINS`: Contains plugins exempt from dataset strategies (`['pliny', 'unsafebench']`).

     - `STRATEGY_EXEMPT_PLUGINS`: Combines both `AGENTIC_EXEMPT_PLUGINS` and `DATASET_EXEMPT_PLUGINS`.



3. **Unit Tests for Exempt Plugins**:

   - Added tests in `constants.test.ts` to validate the contents of `AGENTIC_EXEMPT_PLUGINS`, `DATASET_EXEMPT_PLUGINS`, and `STRATEGY_EXEMPT_PLUGINS`.

   - Verified that `STRATEGY_EXEMPT_PLUGINS` correctly combines the other two constants.



These changes enhance the modularity and test coverage of the plugin exemption logic within the redteam module.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 100% -> 100% |
| functions | 100% -> 100% |
| statements | 100% -> 100% |
| branches | 100% -> 100% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 30 -> 33  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-ts-1748237586392/test/redteam/constants.test.ts)
"
3090326579,4163,test: add unit test for src/providers/xai.ts,gru-agent[bot],185149714,closed,2025-05-26T07:41:53Z,2025-05-26T14:55:17Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4163,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4123](https://github.com/promptfoo/promptfoo/pull/4123) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/5653f68e-f1d4-419e-8820-4f9d63d29f4d?filePath=src/providers/xai.ts) |

## Summary


### PR Summary



**Enhancements:**

1. **Search Parameters Handling:**

   - Added functionality to render `search_parameters` with context variables.

   - Ensured `search_parameters` are included in the API body when defined.

   - Verified that `search_parameters` are excluded from the API body when undefined.

   - Preserved the original `search_parameters` configuration during initialization.



2. **Provider Initialization:**

   - Stored `originalConfig` during provider initialization for better configuration management.



**Testing:**

- Extended test coverage for `search_parameters` handling:

  - Validated rendering with context variables.

  - Confirmed inclusion/exclusion of `search_parameters` in API body based on configuration.

  - Verified preservation of original `search_parameters` configuration.

- Added tests for `originalConfig` storage during initialization.



**Miscellaneous:**

- Exported `GROK_3_MINI_MODELS` for external usage.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 61.56% -> 61.56% |
| functions | 33.33% -> 33.33% |
| statements | 61.56% -> 61.56% |
| branches | 100% -> 100% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 29 -> 33  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-providers-xai-ts-1748245301724/test/providers/xai.test.ts)
"
3092903047,4185,test: add unit test for src/assertions/sql.ts,gru-agent[bot],185149714,closed,2025-05-27T07:21:23Z,2025-05-27T08:09:06Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4185,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4184](https://github.com/promptfoo/promptfoo/pull/4184) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/426e57d0-03eb-4d40-b69f-b38857db8323?filePath=src/assertions/sql.ts) |

## Summary


This PR enhances the `is-sql` assertion tests by adding new test cases to improve coverage and ensure robustness. The following changes have been made:



### New Test Cases:

1. **Properly Matched Backticks**:

   - Added a test to verify that SQL statements with properly matched backticks pass validation.



2. **Mismatched Backticks**:

   - Added a test to ensure SQL statements with mismatched backticks fail validation.



3. **Invalid Column List Format**:

   - Added a test to check that SQL statements with invalid column list formats (e.g., missing commas) fail validation.



4. **Unsupported Function in MySQL**:

   - Added a test to confirm that using unsupported functions like `generate_series` in MySQL results in a failure, even if the syntax is valid.



5. **Normalized Whitelist Entries**:

   - Added a test to validate that SQL statements conforming to normalized whitelist entries pass validation.



### Purpose:

These additions aim to:

- Strengthen the validation logic for SQL syntax.

- Ensure compatibility with database-specific syntax rules.

- Validate the handling of edge cases and whitelist configurations.



No changes were made to the core logic; all updates are confined to the test suite.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 88.09% -> 88.09% |
| functions | 50% -> 50% |
| statements | 88.09% -> 88.09% |
| branches | 78.57% -> 78.57% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 16 -> 21  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-assertions-sql-ts-1748330465838/test/assertions/sql.test.ts)
"
3105757343,4266,test: add unit test for src/redteam/constants.ts,gru-agent[bot],185149714,closed,2025-05-31T16:43:17Z,2025-05-31T16:47:47Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4266,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4263](https://github.com/promptfoo/promptfoo/pull/4263) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/004b4d14-99d7-4353-9adb-8d2ae146c64f?filePath=src/redteam/constants.ts) |

## Summary


This PR introduces the following updates:



1. **Export `_ALL_STRATEGIES`**:

   - The `_ALL_STRATEGIES` constant is now exported from `src/redteam/constants.ts`.



2. **Add Tests for `ADDITIONAL_STRATEGIES` and Emoji Strategy**:

   - New tests are added in `test/redteam/constants.test.ts` to validate the inclusion and properties of the `emoji` strategy within `ADDITIONAL_STRATEGIES`.

   - Tests ensure the following:

     - `emoji` is part of `ADDITIONAL_STRATEGIES`.

     - Correct display name (`Emoji Smuggling`) and description for the `emoji` strategy.

     - Inclusion of `emoji` in the `other-encodings` strategy collection.

     - Correct subcategory description for the `emoji` strategy.



These changes enhance the robustness of the constants and their associated tests, ensuring proper handling and validation of the `emoji` strategy.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 100% -> 100% |
| functions | 100% -> 100% |
| statements | 100% -> 100% |
| branches | 100% -> 100% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 33 -> 38  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-ts-1748709783352/test/redteam/constants.test.ts)
"
3105757415,4267,test: add unit test for src/redteam/strategies/index.ts,gru-agent[bot],185149714,closed,2025-05-31T16:43:26Z,2025-05-31T16:48:01Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4267,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4263](https://github.com/promptfoo/promptfoo/pull/4263) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/004b4d14-99d7-4353-9adb-8d2ae146c64f?filePath=src/redteam/strategies/index.ts) |

## Summary


This PR adds support for the new ""emoji"" strategy in the red team strategies module. 



### Changes:

1. **Validation Updates**:

   - Added the ""emoji"" strategy to the list of valid strategies in the `validateStrategies` test.



2. **Load Strategy Enhancements**:

   - Implemented a test to ensure the ""emoji"" strategy can be loaded successfully.

   - Added a test to verify the ""emoji"" strategy's `action` method is called with the correct parameters and logs appropriate debug messages.



3. **Error Handling**:

   - Confirmed that loading a non-existent strategy still throws the expected error.



### Testing:

- All tests for the ""emoji"" strategy, including validation, loading, and action execution, have been added and verified.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 62.71% -> 64.16%  🔺 |
| functions | 10.34% -> 13.79%  🔺 |
| statements | 62.71% -> 64.16%  🔺 |
| branches | 96.87% -> 96.96%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 17 -> 19  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-strategies-index-ts-1748709790448/test/redteam/strategies/index.test.ts)
"
3118914077,4316,test: add unit test for src/redteam/strategies/mathPrompt.ts,gru-agent[bot],185149714,closed,2025-06-04T19:37:48Z,2025-06-04T21:19:00Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4316,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| PR Created | mldangelo | [4313](https://github.com/promptfoo/promptfoo/pull/4313) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/2f2c12eb-9022-4ff7-ba65-99c66870d816?filePath=src/redteam/strategies/mathPrompt.ts) |

## Summary


This PR introduces unit tests for the `mathPrompt` module, ensuring robust validation and functionality for its methods and constants. Key updates include:



1. **Unit Tests for `generateMathPrompt`**:

   - Validates remote generation of math prompts.

   - Handles errors gracefully, returning an empty array on failure.



2. **Unit Tests for `encodeMathPrompt`**:

   - Tests encoding of text using specified math concepts.

   - Includes error handling for JSON parsing issues.



3. **Unit Tests for `addMathPrompt`**:

   - Validates usage of custom math concepts.

   - Ensures proper validation of `mathConcepts` configuration.



4. **Constants Validation**:

   - Confirms exposure and correctness of `DEFAULT_MATH_CONCEPTS` and `EXAMPLES`.



5. **Refactoring**:

   - Exports `DEFAULT_MATH_CONCEPTS` and `EXAMPLES` from `mathPrompt.ts` for external usage.



Mocking is extensively used to simulate dependencies like `cli-progress`, `fetchWithCache`, and `redteamProviderManager`. This ensures isolated testing of the `mathPrompt` module's functionality.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 93.81%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 93.81%  🔺 |
| branches | 0% -> 61.53%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 8  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-strategies-mathPrompt-ts-1749065856789/test/redteam/strategies/mathPrompt.test.ts)
"
3131655256,4373,test: add unit test for src/redteam/constants/strategies.ts,gru-agent[bot],185149714,closed,2025-06-09T22:40:13Z,2025-06-10T02:45:21Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4373,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | mldangelo | [4372](https://github.com/promptfoo/promptfoo/pull/4372) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/ac2c85c8-d177-46bd-b182-32a4bfaedbf5?filePath=src/redteam/constants/strategies.ts) |

## Summary


This PR introduces unit tests for the `strategies` constants in the `redteam` module to ensure their correctness and consistency. Key changes include:



- **Export Addition**: `_ALL_STRATEGIES` is now explicitly exported from `strategies.ts`.

- **Unit Tests**: A new test file `strategies.test.ts` has been added to validate the following:

  - `FRAMEWORK_COMPLIANCE_IDS` values.

  - `DEFAULT_STRATEGIES`, `MULTI_TURN_STRATEGIES`, and `AGENTIC_STRATEGIES` arrays.

  - `DATASET_PLUGINS` and `ADDITIONAL_STRATEGIES` arrays.

  - `STRATEGY_COLLECTIONS` and `STRATEGY_COLLECTION_MAPPINGS` mappings.

  - Sorting and correctness of `ALL_STRATEGIES`.



These tests ensure that the constants are correctly defined and maintain expected values, improving reliability and maintainability of the `strategies` module.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 9  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-strategies-ts-1749508802083/test/redteam/constants/strategies.test.ts)
"
3131659920,4374,test: add unit test for src/redteam/constants/frameworks.ts,gru-agent[bot],185149714,closed,2025-06-09T22:42:55Z,2025-06-10T02:45:36Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4374,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | mldangelo | [4372](https://github.com/promptfoo/promptfoo/pull/4372) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/ac2c85c8-d177-46bd-b182-32a4bfaedbf5?filePath=src/redteam/constants/frameworks.ts) |

## Summary


This PR introduces comprehensive unit tests for the framework constants used in the red team module. The tests validate the structure, content, and mappings of various frameworks and their associated plugins and strategies. Below is a summary of the changes:



### Added Tests:

1. **Framework Names Validation**:

   - Ensures `FRAMEWORK_NAMES` contains correct names for frameworks like MITRE ATLAS, NIST AI RMF, OWASP API Top 10, OWASP LLM Top 10, OWASP Agentic v1.0, and EU AI Act.



2. **OWASP Frameworks**:

   - Validates the number and content of items in `OWASP_LLM_TOP_10_NAMES` and `OWASP_API_TOP_10_NAMES`.

   - Confirms the presence of expected names like ""Prompt Injection"" and ""Broken Object Level Authorization"".



3. **OWASP Agentic Framework**:

   - Checks `OWASP_AGENTIC_NAMES` for expected entries like ""T1: Memory Poisoning"".



4. **Mapping Structures**:

   - Validates the structure and content of mappings:

     - `OWASP_LLM_TOP_10_MAPPING`: Ensures plugins and strategies are correctly defined for items like ""owasp:llm:01"".

     - `OWASP_AGENTIC_REDTEAM_MAPPING`: Confirms correct mapping for memory poisoning with associated plugins and strategies.

     - `OWASP_LLM_RED_TEAM_MAPPING`: Verifies strategies for all phases (model, implementation, system, runtime).



5. **Aliased Plugins**:

   - Confirms `ALIASED_PLUGINS` contains expected aliases like ""mitre:atlas"" and ""owasp:llm"".



6. **Aliased Plugin Mappings**:

   - Validates mappings for aliased plugins, ensuring correct associations with frameworks like MITRE ATLAS and OWASP LLM Top 10.

   - Checks special mappings for categories like ""toxicity"", ""bias"", ""misinformation"", and ""illegal-activity"".



### Key Highlights:

- Ensures all constants and mappings are correctly structured and contain expected values.

- Validates the integrity of framework-related data used in the red team module.

- Provides robust coverage for framework constants to prevent regressions and ensure consistency.



This PR enhances the reliability of the framework constants by ensuring their correctness through detailed unit tests.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 14  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-frameworks-ts-1749508962649/test/redteam/constants/frameworks.test.ts)
"
3131660620,4375,test: add unit test for src/redteam/constants/plugins.ts,gru-agent[bot],185149714,closed,2025-06-09T22:43:22Z,2025-06-10T02:45:50Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4375,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | mldangelo | [4372](https://github.com/promptfoo/promptfoo/pull/4372) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/ac2c85c8-d177-46bd-b182-32a4bfaedbf5?filePath=src/redteam/constants/plugins.ts) |

## Summary


This PR introduces unit tests for the `plugins` constants in the `redteam` module. The tests ensure that all constants are correctly defined and meet expected criteria. Key highlights include:



- **Validation of Constants**:

  - `DEFAULT_NUM_TESTS_PER_PLUGIN` is set to `5`.

  - `REDTEAM_MODEL` is defined as `openai:chat:gpt-4.1-2025-04-14`.

  - `LLAMA_GUARD_REPLICATE_PROVIDER` and `LLAMA_GUARD_ENABLED_CATEGORIES` are verified for correctness.



- **Array and Object Validations**:

  - Arrays such as `FOUNDATION_PLUGINS`, `COLLECTIONS`, `PII_PLUGINS`, `BASE_PLUGINS`, `ADDITIONAL_PLUGINS`, `CONFIG_REQUIRED_PLUGINS`, `AGENTIC_EXEMPT_PLUGINS`, `DATASET_EXEMPT_PLUGINS`, and `STRATEGY_EXEMPT_PLUGINS` are checked for proper definitions and expected values.

  - Objects like `UNALIGNED_PROVIDER_HARM_PLUGINS`, `REDTEAM_PROVIDER_HARM_PLUGINS`, and `HARM_PLUGINS` are validated for structure and content.



- **Set and Array Properties**:

  - `DEFAULT_PLUGINS` is confirmed to be a `Set` with non-zero size.

  - `ALL_PLUGINS` is verified to be a sorted array with unique values.



These tests ensure the integrity and correctness of the constants used in the `redteam` module, providing a robust foundation for further development and usage.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 21  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-plugins-ts-1749508991505/test/redteam/constants/plugins.test.ts)
"
3131666716,4376,test: add unit test for src/redteam/constants/metadata.ts,gru-agent[bot],185149714,closed,2025-06-09T22:47:01Z,2025-06-10T02:46:09Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4376,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Auto Rebase | mldangelo | [4372](https://github.com/promptfoo/promptfoo/pull/4372) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/ac2c85c8-d177-46bd-b182-32a4bfaedbf5?filePath=src/redteam/constants/metadata.ts) |

## Summary


This PR introduces comprehensive unit tests for the `metadata` constants in the Red Team module. The tests ensure the integrity and correctness of various metadata mappings, descriptions, and configurations. Below is a summary of the changes:



### Added Tests:

1. **Severity Enum and Display Names**:

   - Validates that severity levels match their corresponding display names.



2. **Risk Category Severity Map**:

   - Ensures all severity levels are valid.

   - Confirms the memory poisoning plugin is mapped to high severity.



3. **Risk Categories**:

   - Verifies category descriptions are defined and of type `string`.

   - Checks the validity of category mappings for each plugin.

   - Ensures category labels match the reverse category map.



4. **Category Aliases**:

   - Validates the consistency of alias mappings and their reverse mappings.



5. **Plugin and Strategy Descriptions**:

   - Confirms all plugins and strategies have non-empty descriptions.

   - Ensures all strategies have valid display names.



6. **Plugin Preset Descriptions**:

   - Validates that preset descriptions are non-empty strings.



7. **Display Name Overrides**:

   - Checks the display name for the memory poisoning plugin.

   - Ensures subcategory descriptions exist for all overrides.



8. **Default Output Path**:

   - Confirms the default output path is correctly set to `redteam.yaml`.



### Key Constants Tested:

- `Severity`

- `riskCategorySeverityMap`

- `riskCategories`

- `categoryDescriptions`

- `categoryMapReverse`

- `categoryLabels`

- `categoryAliases`

- `categoryAliasesReverse`

- `pluginDescriptions`

- `strategyDescriptions`

- `strategyDisplayNames`

- `PLUGIN_PRESET_DESCRIPTIONS`

- `DEFAULT_OUTPUT_PATH`

- `displayNameOverrides`

- `subCategoryDescriptions`



This PR ensures the robustness of metadata definitions and mappings, improving the reliability of the Red Team module.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 14  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-constants-metadata-ts-1749509208591/test/redteam/constants/metadata.test.ts)
"
3134325343,4394,chore: better error message for missing plugins,sklein12,1080611,closed,2025-06-10T17:19:01Z,2025-06-10T17:57:56Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4394,"```
Invalid configuration file /Users/steve/tmp/datadog/promptfooconfig.yaml:
Validation error: Custom plugins must start with file:// (or use one of the built-in plugins). Received: ""not-real-plugin"" at ""redteam.plugins[27].id""
```"
3135739307,4406,test: add unit test for src/assertions/python.ts,gru-agent[bot],185149714,closed,2025-06-11T07:09:16Z,2025-06-11T13:54:48Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4406,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4398](https://github.com/promptfoo/promptfoo/pull/4398) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/9833693c-0ba9-4f26-b8fe-baa2f0929146?filePath=src/assertions/python.ts) |

## Summary


This PR updates the test case for Python file references to ensure proper mapping of snake_case keys from Python dataclass objects to camelCase keys in the JavaScript/TypeScript context. 



### Changes:

- Enhanced the test description to clarify the mapping of snake_case keys to camelCase.

- Added a new key `component_results` in the Python result object and verified its mapping to `componentResults` in the test assertions.

- Updated the test assertions to include the new `componentResults` key and validate its structure.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 70.14% -> 71.64%  🔺 |
| functions | 100% -> 100% |
| statements | 70.14% -> 71.64%  🔺 |
| branches | 65.85% -> 70.73%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 23 -> 23 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-assertions-python-ts-1749625747998/test/assertions/python.test.ts)
"
3138996282,4433,test: add unit test for src/redteam/graders.ts,gru-agent[bot],185149714,closed,2025-06-12T06:24:17Z,2025-06-12T06:35:56Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4433,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4119](https://github.com/promptfoo/promptfoo/pull/4119) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/0bb61fac-0b48-4742-af8c-c2287239ada7?filePath=src/redteam/graders.ts) |

## Summary


### PR Summary



This PR adds a test case for the `AegisGrader` plugin in the `getGraderById` function within the `graders.test.ts` file. The changes include:



- Importing the `AegisGrader` class from the `plugins/aegis` module.

- Adding a test to verify that the `getGraderById` function correctly returns an instance of `AegisGrader` when provided with the ID `promptfoo:redteam:aegis`.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 100% -> 100% |
| functions | 100% -> 100% |
| statements | 100% -> 100% |
| branches | 100% -> 100% |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 4 -> 4 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-graders-ts-1749709445973/test/redteam/graders.test.ts)
"
3139012299,4434,test: add unit test for src/redteam/plugins/aegis.ts,gru-agent[bot],185149714,closed,2025-06-12T06:31:50Z,2025-06-12T06:36:11Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4434,"> [!WARNING]
> [Regression Alert] The existing unit tests were failing. Gru has updated them, adding coverage and ensuring they pass. Please check if this behavior is expected.

## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4119](https://github.com/promptfoo/promptfoo/pull/4119) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/0bb61fac-0b48-4742-af8c-c2287239ada7?filePath=src/redteam/plugins/aegis.ts) |

## Summary


This PR enhances the testing and functionality of the `AegisPlugin` and `AegisGrader` components in the redteam plugin suite. Key changes include:



### AegisPlugin Enhancements:

1. **Unit Tests**:

   - Added tests for `getTemplate`, `getAssertions`, and `generateTests` methods.

   - Verified handling of empty datasets and invalid records during test generation.

   - Mocked `fetchHuggingFaceDataset` to simulate dataset fetching and filtering.



2. **Dataset Fetching**:

   - Improved dataset filtering logic to exclude invalid records.

   - Added tests to ensure proper handling of errors and invalid dataset entries.



### AegisGrader Enhancements:

1. **Grading Logic**:

   - Implemented specific handling for standard refusal responses, automatically passing them with a score of 1.

   - Integrated fallback to superclass grading logic for non-refusal responses.



2. **Rubric Validation**:

   - Added tests to verify the content of the grading rubric, ensuring it aligns with content safety guidelines.



### Miscellaneous:

- Mocked dependencies for testing (`fetchHuggingFaceDataset`).

- Improved test coverage for edge cases and error handling.



These changes improve the robustness and reliability of the `AegisPlugin` and `AegisGrader` components, ensuring better handling of datasets and grading scenarios.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 61.94% -> 100%  🔺 |
| functions | 60% -> 100%  🔺 |
| statements | 61.94% -> 100%  🔺 |
| branches | 75% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 4 -> 12  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-plugins-aegis-ts-1749709897595/test/redteam/plugins/aegis.test.ts)
"
3139017800,4436,test: add unit test for src/database/index.ts,gru-agent[bot],185149714,closed,2025-06-12T06:33:58Z,2025-06-12T06:36:22Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4436,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | mldangelo | [4104](https://github.com/promptfoo/promptfoo/pull/4104) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/5f9637fb-39f6-4d14-b04b-70554045d1a2?filePath=src/database/index.ts) |

## Summary


This PR introduces comprehensive unit tests for the database module, ensuring robust functionality and error handling. Key changes include:



- **Export Enhancements**: Added exports for `DrizzleLogWriter`, `dbInstance`, and `sqliteInstance` in `src/database/index.ts`.

- **Unit Tests**:

  - **Path Functions**: Verified `getDbPath` and `getDbSignalPath` return correct paths based on the configuration directory.

  - **Database Initialization**: Ensured `getDb` initializes an in-memory database during testing, sets WAL mode, and returns consistent instances across calls.

  - **DrizzleLogWriter**: Tested logging behavior based on the `PROMPTFOO_ENABLE_DATABASE_LOGS` environment variable.

  - **Database Closure**: Validated `closeDb` properly closes connections, resets instances, and gracefully handles errors during multiple calls.

- **Mocks**: Utilized mocks for environment variables, logger, and configuration directory path to isolate and test functionality.



These additions improve test coverage and reliability for the database module.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 96.15%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 96.15%  🔺 |
| branches | 0% -> 72.72%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 10  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-database-index-ts-1749710025990/test/database/index.test.ts)
"
3142379824,4472,test: add unit test for src/util/tokenUsage.ts,gru-agent[bot],185149714,closed,2025-06-13T06:09:23Z,2025-06-13T06:12:05Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4472,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| PR Created | mldangelo | [4471](https://github.com/promptfoo/promptfoo/pull/4471) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/03507e49-2661-4c91-9ef1-aae86b07d0e7?filePath=src/util/tokenUsage.ts) |

## Summary


This PR introduces unit tests for the `TokenUsageTracker` utility class, ensuring its functionality and reliability. The tests cover the following scenarios:



- **Tracking Token Usage**: Verifies that token usage for a provider is correctly tracked and retrieved.

- **Handling Undefined Usage**: Ensures the tracker handles undefined token usage gracefully.

- **Merging Token Usage**: Confirms that token usage for the same provider is merged correctly.

- **Retrieving Provider IDs**: Tests the ability to retrieve all tracked provider IDs.

- **Calculating Total Usage**: Validates the computation of total token usage across all providers.

- **Resetting Usage**: Includes tests for resetting usage for a specific provider and resetting all usage.



These tests enhance the robustness of the `TokenUsageTracker` by ensuring its methods behave as expected under various conditions.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 58.06%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 7  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-util-tokenUsage-ts-1749794953366/test/util/tokenUsage.test.ts)
"
3164316160,4583,test: add unit test for src/redteam/strategies/index.ts,gru-agent[bot],185149714,closed,2025-06-20T20:30:38Z,2025-06-21T17:38:39Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4583,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | will-holley | [4107](https://github.com/promptfoo/promptfoo/pull/4107) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/e5bdc9c2-4159-43a3-abd0-40b434507a31?filePath=src/redteam/strategies/index.ts) |

## Summary


This PR adds test coverage for the `REDTEAM_SIMULATED_USER_STRATEGY_ID` strategy in the `redteam/strategies` module. 



### Changes:

1. **Validation Tests**:

   - Updated `validateStrategies` test to include `REDTEAM_SIMULATED_USER_STRATEGY_ID` in the list of valid strategies.



2. **Load Strategy Tests**:

   - Added a test to ensure the `REDTEAM_SIMULATED_USER_STRATEGY_ID` strategy is loaded correctly.

   - Verified that the strategy's `action` function is defined and callable.

   - Added a test to validate the `action` function behavior when invoked with test cases, ensuring proper logging and functionality.



3. **Error Handling**:

   - Confirmed that loading a non-existent strategy still throws the appropriate error.



These additions ensure the simulated user strategy is properly integrated and its functionality is verified.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 63.86% -> 65.26%  🔺 |
| functions | 13.33% -> 16.66%  🔺 |
| statements | 63.86% -> 65.26%  🔺 |
| branches | 96.96% -> 97.05%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 19 -> 21  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-strategies-index-ts-1750451425530/test/redteam/strategies/index.test.ts)
"
3164327543,4584,test: add unit test for src/redteam/providers/simulatedUser.ts,gru-agent[bot],185149714,closed,2025-06-20T20:36:54Z,2025-06-21T17:43:24Z,https://github.com/promptfoo/promptfoo,https://github.com/promptfoo/promptfoo/pull/4584,"## Trigger Info

| Trigger Type | Triggered By | Source Pull Request | Assignment |
| ------------ | ------------ | ------------------- | ---------- |
| Ready for Review | will-holley | [4107](https://github.com/promptfoo/promptfoo/pull/4107) | [Detail](https://gru.ai/:test/promptfoo@github/promptfoo/e5bdc9c2-4159-43a3-abd0-40b434507a31?filePath=src/redteam/providers/simulatedUser.ts) |

## Summary


This PR introduces unit tests for the `RedteamSimulatedUserProvider` class, ensuring its functionality and behavior are thoroughly validated. Key changes include:



- **Provider Initialization Tests**:

  - Validates that the provider is correctly instantiated with the required configuration (`injectVar`).

  - Ensures an error is thrown if `injectVar` is not set.



- **ID Retrieval Test**:

  - Confirms that the provider returns the correct ID based on the `REDTEAM_SIMULATED_USER_STRATEGY_ID`.



- **SimulatedUser Integration Tests**:

  - Verifies that the `SimulatedUser` class is called with the correct configuration, including `instructions`, `maxTurns`, and `userProvider`.

  - Tests the behavior when `maxTurns` and `userProvider` are undefined.



- **Mocking and Assertions**:

  - Mocks the `SimulatedUser` class and its methods (`callApi`, `sendMessageToUser`, `sendMessageToAgent`) to isolate and test the provider's logic.

  - Ensures the `callApi` method is invoked with the expected parameters.



These tests enhance the reliability of the `RedteamSimulatedUserProvider` by ensuring its integration with the `SimulatedUser` class and its handling of various configurations.

## Coverage


The change in coverage value, such as: `0% -> 50%`, indicates that the coverage was 0% before writing the tests and 50% after writing them.


https://web.dev/articles/ta-code-coverage

| Type | Change |
| ---- | ------ |
| lines | 0% -> 100%  🔺 |
| functions | 0% -> 100%  🔺 |
| statements | 0% -> 100%  🔺 |
| branches | 0% -> 100%  🔺 |
| source | program |

## Test Statuses

| Status | Change |
| ------ | ------ |
| passed | 0 -> 5  🔺 |
| failed | 0 -> 0 |
| skipped | 0 -> 0 |
| source | program |

> [!TIP]
> You can `@gru-agent` and leave your feedback. TestGru will make adjustments based on your input

> [!TIP]
> You can `@gru-agent rebase` to rebase the PR.

> [!TIP]
> You can `@gru-agent redo` to reset or rebase before redoing the PR.

> [!TIP]
> To modify the test code yourself, click here [Edit Test Code](https://github.com/promptfoo/promptfoo/edit/gru/src-redteam-providers-simulatedUser-ts-1750451803940/test/redteam/providers/simulatedUser.test.ts)
"
3153830089,2051,fix sorting flags in CollectionIterator,PhilinTv,376033,closed,2025-06-17T14:59:59Z,2025-06-17T15:15:49Z,https://github.com/propelorm/Propel2,https://github.com/propelorm/Propel2/pull/2051,"Reviewed here: https://github.com/propelorm/Propel2/pull/2049
Running CI."
3160279097,1582,Python 3.15 is now main,corneliusroemer,25161793,closed,2025-06-19T13:05:40Z,2025-06-24T07:21:23Z,https://github.com/python/devguide,https://github.com/python/devguide/pull/1582,"Followup of https://github.com/python/cpython/pull/134649

Previous 2 years PRs:
- https://github.com/python/devguide/pull/1383
- https://github.com/python/devguide/pull/1099

<!-- readthedocs-preview cpython-devguide start -->
----
📚 Documentation preview 📚: https://cpython-devguide--1582.org.readthedocs.build/

<!-- readthedocs-preview cpython-devguide end -->"
275232423,1234,Ray fails to serialize self-reference objects,suquark,13750372,closed,2017-11-20T04:12:25Z,2020-03-05T23:11:03Z,https://github.com/ray-project/ray,https://github.com/ray-project/ray/issues/1234,"<!--
General questions should be asked on the mailing list ray-dev@googlegroups.com.

Before submitting an issue, please fill out the following form.
-->

### System information
- **Ray installed from (source or binary)**: pip
- **Ray version**: 0.2.2
- **Python version**: 3.6.2

<!--
You can obtain the Ray version with

python -c ""import ray; print(ray.__version__)""
-->

### Describe the problem

Ray fails to serialize self-reference objects (for example, Graph objects in networkx).

I think it is because ray always tries to use pyarrow first and does not catch `pyarrow.lib.ArrowNotImplementedError`, see

https://github.com/ray-project/ray/blob/e0360eb4298371e308cd266dd512befaa457ce24/python/ray/worker.py#L285-L289

After catching `pyarrow.lib.ArrowNotImplementedError`, we **should not** use `use_dict=True` as a workaround, because it will cause endless loop. A correct approach may be:

```python
            except (pyarrow.SerializationCallbackError, pyarrow.lib.ArrowNotImplementedError) as e:
                try:
                    if isinstance(e, pyarrow.lib.ArrowNotImplementedError):
                        e.example_object = value
                        raise e  # redirect to use cloudpickle
```

### Source code / logs
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

```python
class Graph:
    def __init__(self):
        self.g = self

G = Graph()
ray.put(G)  # --> pyarrow.lib.ArrowNotImplementedError: This object exceeds the maximum recursion depth. It may contain itself recursively.

# another example

import networkx as nx
G = nx.Graph()
    
G.add_edges_from([(1, 2), (1, 3)])
G.add_node(1)
G.add_edge(1, 2)
G.add_node(""spam"")  # adds node ""spam""
G.add_nodes_from(""spam"")  # adds 4 nodes: 's', 'p', 'a', 'm'
G.add_edge(3, 'm')
ray.put(G)  # --> pyarrow.lib.ArrowNotImplementedError: This object exceeds the maximum recursion depth. It may contain itself recursively.
```

@mitar "
3131862594,53685,[refactor] Install uv from test-requirements.txt,pcmoritz,113316,open,2025-06-10T01:15:02Z,,https://github.com/ray-project/ray,https://github.com/ray-project/ray/pull/53685,"Removes the manual download and installation of `uv` within the `test_runtime_env_uv_run.py` test file.

Instead, `uv` is now added as a dependency in
`python/requirements/test-requirements.txt`. The tests have been updated to use the `uv` executable directly, assuming it's installed in the environment.

This change simplifies the test setup and relies on the standard dependency management for `uv`. Updated `uv` to version 0.7.12.

Fixes https://github.com/ray-project/ray/issues/53650

<!-- Thank you for your contribution! Please review https://github.com/ray-project/ray/blob/master/CONTRIBUTING.rst before opening a pull request. -->

<!-- Please add a reviewer to the assignee section when you create a PR. If you don't have the access to it, we will shortly find a reviewer and assign them to your PR. -->

## Why are these changes needed?

<!-- Please give a short summary of the change and the problem this solves. -->

## Related issue number

<!-- For example: ""Closes #1234"" -->

## Checks

- [ ] I've signed off every commit(by using the -s flag, i.e., `git commit -s`) in this PR.
- [ ] I've run `scripts/format.sh` to lint the changes in this PR.
- [ ] I've included any doc changes needed for https://docs.ray.io/en/master/.
    - [ ] I've added any new APIs to the API Reference. For example, if I added a
           method in Tune, I've added it in `doc/source/tune/api/` under the
           corresponding `.rst` file.
- [ ] I've made sure the tests are passing. Note that there might be a few flaky tests, see the recent failures at https://flakey-tests.ray.io/
- Testing Strategy
   - [ ] Unit tests
   - [ ] Release tests
   - [ ] This PR is not tested :(
"
2923655403,1082,metadata retains old reference to rich~=13.0.0,gkennos,12161195,closed,2025-03-17T03:38:52Z,2025-05-19T08:48:56Z,https://github.com/roboflow/inference,https://github.com/roboflow/inference/issues/1082,"### Search before asking

- [x] I have searched the Inference [issues](https://github.com/roboflow/inference/issues) and found no similar bug report.


### Bug

Per [this issue](https://github.com/roboflow/inference/issues/865), the version dependency for rich should have been bumped. PyPI metadata retains old dependency, however, so the version clash persists.


**Requires-Dist: rich<13.10.0,>=13.0.0**
Requires-Dist: PyYAML~=6.0.0
Requires-Dist: supervision<=0.30.0,>=0.25.1
Requires-Dist: opencv-python<=4.10.0.84,>=4.8.1.78
Requires-Dist: tqdm<5.0.0,>=4.0.0
Requires-Dist: nvidia-ml-py<13.0.0
Requires-Dist: py-cpuinfo~=9.0.0
Requires-Dist: aiohttp<=3.10.11,>=3.9.0
Requires-Dist: backoff~=2.2.0
Requires-Dist: pandas<2.3.0,>=2.0.0
**Requires-Dist: rich~=13.0.0**

### Environment

python 3.11 slim bookworm

### Minimal Reproducible Example

```
import csv, json, requests
package = 'inference'
pypi_url = f'https://pypi.python.org/pypi/{package}/json'
data = requests.get(pypi_url).json()
reqs = data['info']['requires_dist']
print([r for r in reqs if 'rich' in r])
['rich<13.10.0,>=13.0.0', 'rich<13.10.0,>=13.0.0', 'rich~=13.0.0']
```

### Additional

_No response_

### Are you willing to submit a PR?

- [ ] Yes I'd like to help by submitting a PR!"
3069415571,1292,Add Trackers to Workflows,yeldarby,870796,closed,2025-05-16T16:19:18Z,2025-05-19T01:33:11Z,https://github.com/roboflow/inference,https://github.com/roboflow/inference/pull/1292,"# Description

Adds [roboflow/trackers](https://github.com/roboflow/trackers) support to Workflows. 

## Type of change

-   [x] New feature (non-breaking change which adds functionality)

## How has this change been tested, please provide a testcase or example of how you tested the change?

WIP

## Any specific deployment considerations

WIP

## Docs

-   [ ] Docs updated? What were the changes: Not yet, WIP
"
3164054183,1377,needs to be checked if PE model accepts batches (if so - maybe worth claiming use of batches of inputs),grzegorz-roboflow,166530809,open,2025-06-20T18:09:59Z,,https://github.com/roboflow/inference,https://github.com/roboflow/inference/issues/1377,"needs to be checked if PE model accepts batches (if so - maybe worth claiming use of batches of inputs)

_Originally posted by @PawelPeczek-Roboflow in https://github.com/roboflow/inference/pull/1350#discussion_r2138408406_



looks like it does:
 - https://github.com/roboflow/inference/blob/main/inference/core/entities/requests/perception_encoder.py#L45 
 
 
Clip also does actually and block decalres input the same way:
`data: Union[Selector(kind=[IMAGE_KIND, STRING_KIND]), str]`


@PawelPeczek-Roboflow Is this the only thing that would need to be added?
```
@classmethod
def get_parameters_accepting_batches(cls) -> List[str]:
    return [""data""]
```

(above results in `'Batch' object has no attribute 'to_inference_format'`)"
2907857505,274,Cabo Verde appears twice with different populations,alberto56,808265,closed,2025-03-10T16:43:20Z,2025-06-10T20:42:00Z,https://github.com/samayo/country-json,https://github.com/samayo/country-json/issues/274,"In https://github.com/samayo/country-json/blob/master/src/country-by-population.json we have:

```
    {
        ""country"": ""Cabo Verde"",
        ""population"": 555987
    },
    ...
    {
        ""country"": ""Cape Verde"",
        ""population"": 543767
    },
```"
3070031044,393,`Process` and `ProcessAsync` ignore errors,lostmsu,239520,open,2025-05-16T23:06:13Z,,https://github.com/sandrohanea/whisper.net,https://github.com/sandrohanea/whisper.net/issues/393,"**ChatGPT discussion**
 - [ ] I asked [Whisper.net Helper](https://chat.openai.com/g/g-GQU8iEnAa-whisper-net-helper) and it couldn't help me, here is the discussion link: 

**Describe the bug**
`Process` and `ProcessAsync` ignore errors

**To Reproduce**
Look at https://github.com/sandrohanea/whisper.net/blob/851afdb3f52c77bb40a8b4242fdeacd0f038c41f/Whisper.net/WhisperProcessor.cs#L178 and see that return value is ignored

**Expected behavior**
An enum error code should be returned or an exception should be raised when the call fails for any reason.

"
3084592048,350,Fix 349 accented letters,angelod1as,13950513,closed,2025-05-22T21:31:28Z,2025-05-23T13:30:28Z,https://github.com/seasonedcc/remix-forms,https://github.com/seasonedcc/remix-forms/pull/350,"Fixes #349 

This PR changes the `infer-label` function to take into account accented letters.

I'm not the best with RegExp so please criticize and change freely.

`\p{L}`: Matches any kind of letter from any language, including accented letters (This is part of Unicode property escapes).
`(?:'\p{L}+)?`: This non-capturing group matches apostrophes followed by letters (useful for handling cases like ""l'école"").
`\d+`: Matches sequences of digits (This allows numbers to be treated as separate words).
`u`: The Unicode flag (ensures that the regular expression handles Unicode characters properly).
`g`: The global flag

This PR also adds an example to the Radio Buttons and a test — not really necessary, but surely adds safety and 💅 — it makes sure things look the way they should."
3141059892,620,Apply BSL to app,transphorm,23852,closed,2025-06-12T17:24:29Z,2025-06-12T17:35:06Z,https://github.com/selfxyz/self,https://github.com/selfxyz/self/pull/620,"Original PR:
https://github.com/selfxyz/self/pull/618

## Summary
- place the BSL text under `app/LICENSE`
- does not add BSL headers to config files
- add BSL headers to application sources

## Testing

Changes no functionality.

------
https://chatgpt.com/codex/tasks/task_b_6849eb804b50832c90a40f0aa4ac6818"
3124688796,3947,Conflict when observability enabled and mixed batch and non-batch listeners,michaldo,4304236,open,2025-06-06T12:48:01Z,,https://github.com/spring-projects/spring-kafka,https://github.com/spring-projects/spring-kafka/issues/3947,"**In what version(s) of Spring for Apache Kafka are you seeing this issue?**

3.3.6

**Describe the bug**

Batch `@KafkaListener` is not observable, non-batch is observable - it causes Prometheus metric conflict.

When observability is enabled and there is one non-batch `@KafkaListener`, metric
http://localhost:8080/actuator/prometheus?includedNames=spring_kafka_listener_seconds is ok:

>  spring_kafka_listener_seconds_sum{error=""none"",messaging_kafka_consumer_group=""aaa"",messaging_operation=""receive"",messaging_source_kind=""topic"",messaging_source_name=""bbb"",messaging_system=""kafka"",spring_kafka_listener_id=""org.springframework.kafka.KafkaListenerEndpointContainer#0-0""} 0.0016962

When second, batch `@KafkaListener` is added, it breaks non-batch metrics
> spring_kafka_listener_seconds_sum{exception=""none"",name=""org.springframework.kafka.KafkaListenerEndpointContainer#0-0"",result=""success""} 0.0

Logs contains warning with explanation:
> The meter (MeterId{name='spring.kafka.listener', tags=[tag(error=none),tag(messaging.kafka.consumer.group=aaa),tag(messaging.operation=receive),tag(messaging.source.kind=topic),tag(messaging.source.name=bbb),tag(messaging.system=kafka),tag(spring.kafka.listener.id=org.springframework.kafka.KafkaListenerEndpointContainer#1-0)]}) registration has failed

**To Reproduce**

1. Build application with 
- org.springframework.kafka:spring-kafka
- org.springframework.boot:spring-boot-starter-actuator
- io.micrometer:micrometer-registry-prometheus
- org.springframework.boot:spring-boot-starter-web (for easy metric inspection)

Make sure: `spring.kafka.listener.observation-enabled=true`

Experiment with different combination of batch and non-batch `@KafkaListener`


**Expected behavior**

It cannot be accepted that adding batch listener breaks already working obsevations

When observability is enabled, metric for each listener should be registered with same set of tags, regardless listener is batch or non-batch). When some tag has no value, use placeholder ""none""

Similar issue for MongoDB: https://github.com/spring-projects/spring-data-mongodb/pull/4994


"
3115342439,8320,Fix the custom type extraction in dspy.BaseType,chenmoneygithub,22925031,closed,2025-06-03T20:24:51Z,2025-06-03T20:49:31Z,https://github.com/stanfordnlp/dspy,https://github.com/stanfordnlp/dspy/pull/8320,"Following up with #8318, this PR handles extracting custom field type from annotations like `list[MyPydanticType]`.

The unit tests passed on both on python 3.10 and 3.12. The original error results from the diff between python 3.10 and python 3.12

On python 3.12:

```
>>> isinstance(list[str], type)
False
```

but on python 3.10:

```
>>> isinstance(list[str], type)
True
```"
3132397680,8358,Add xml adapter,chenmoneygithub,22925031,closed,2025-06-10T07:00:54Z,2025-06-10T15:35:48Z,https://github.com/stanfordnlp/dspy,https://github.com/stanfordnlp/dspy/pull/8358,"Forking from #8326 because I don't have rebase permission in the PR. 

Merged main branch, then made some minor edits and added unit test"
3094114708,2504,Improve admin panel customization docs,pwizla,4233866,closed,2025-05-27T14:17:16Z,2025-05-27T14:21:37Z,https://github.com/strapi/documentation,https://github.com/strapi/documentation/pull/2504,"## Summary
- add intros to the new *Logos* and *Locales & translations* pages

## Testing
- `yarn test` *(fails: package not present in lockfile)*"
3156991667,3919,CLI broken due to breaking changes in LibCST,yuvalbenarie,11248894,closed,2025-06-18T13:54:58Z,2025-06-19T16:54:49Z,https://github.com/strawberry-graphql/strawberry,https://github.com/strawberry-graphql/strawberry/issues/3919,"## Describe the Bug

When running Strawberry cli, import fails:
```
Traceback (most recent call last):
  File ""/app/.venv/bin/strawberry"", line 5, in <module>
    from strawberry.cli import run
  File ""/app/.venv/lib/python3.13/site-packages/strawberry/cli/__init__.py"", line 9, in <module>
    from .commands.upgrade import upgrade as upgrade  # noqa: PLC0414
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/app/.venv/lib/python3.13/site-packages/strawberry/cli/commands/upgrade/__init__.py"", line 15, in <module>
    from ._run_codemod import run_codemod
  File ""/app/.venv/lib/python3.13/site-packages/strawberry/cli/commands/upgrade/_run_codemod.py"", line 10, in <module>
    from libcst.codemod._dummy_pool import DummyPool
ImportError: cannot import name 'DummyPool' from 'libcst.codemod._dummy_pool' (/app/.venv/lib/python3.13/site-packages/libcst/codemod/_dummy_pool.py)
```

<!-- A clear and concise description of what the bug is. -->

https://github.com/Instagram/LibCST/commit/d002c14d6b7a7121713bd7f30a73a84f4b2b4c1c#diff-9c5bec9a098df39145f8d6b0a8687a55fe3e8e1bbd6fe9e6de91bf045fd82f59

changed the DummyPool to a DummyExecutor.
This was released in [v1.8.0](https://github.com/Instagram/LibCST/tree/v1.8.0)
"
3056157810,127,BREAKING CHANGE: remove SQLite support,sinopeus,1456723,closed,2025-05-12T08:46:27Z,2025-05-18T16:47:45Z,https://github.com/superlinear-ai/raglite,https://github.com/superlinear-ai/raglite/pull/127,
3085790363,473,feat: make job backoff limit configurable in Kratix workflows,kirederik,201163,closed,2025-05-23T09:33:05Z,2025-06-06T11:38:44Z,https://github.com/syntasso/kratix,https://github.com/syntasso/kratix/issues/473,"## Context

By default, Kubernetes will retry 6 times to make the job pass, following an exponential backoff strategy. In case of failure, users might want to choose not to re run the workflow, or if they are actively debugging, they might want a higher `backoffLimit` so the workflow can be re run more than the current default, which is 6.

We could make this configurable both at the global level and at the Promise level. In this story, we will implement both.

## UX

In the Pipeline spec, users should be able to configure the backoffLimit:

```yaml
# promise.yaml
# ...
spec:
    resource:
      configure:
      - apiVersion: platform.kratix.io/v1alpha1
        kind: Pipeline
        metadata:
          name: instance-configure
        spec:
          jobOptions:
            backoffLimit: 3
          containers:
          - image: my-image
            name: my-container
```

In the Kratix Config, users should be able to configure the default backoffLimit:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kratix
  namespace: kratix-platform-system
data:
  config: |
    workflows:
      jobOptions:
        defaultBackoffLimit: 4
```

## Scenarios

```gherkin
# Global Backoff Limit
Given I have a Kratix Config with `workflows.jobOptions.defaultBackoffLimit` set to X
When any workflow job is created
Then its `spec.backoffLimit` is set to X

# Backoff Limit set in the Workflow
Given I have a Workflow with `spec.jobOptions.backoffLimit` set to X
When the workflow job is created
Then its `spec.backoffLimit` is set to X

# Workflow backoffLimit has precedence
Given I have a Kratix Config with `workflows.jobOptions.defaultBackoffLimit` set to X
And I have a Workflow with `spec.jobOptions.backoffLimit` set to Y
When any workflow job is created
Then its `spec.backoffLimit` is set to Y
```"
3108543648,252,OpenRouter Custom Provider Errors,craigz,1929275,closed,2025-06-02T04:54:33Z,2025-06-02T23:57:57Z,https://github.com/synth-inc/onit,https://github.com/synth-inc/onit/issues/252,"I'm unable to add OpenRouter as a custom provider in the onit settings.
I've tried a couple of urls / endpoints (due to seeing different options online): 

- https://openrouter.ai/api/v1
- https://openrouter.ai/api/v1/models

I've confirmed that both endpoints are available via a browser & by using curl.  

However neither of those requests were authenticated, while onit is sending my api key with the request so that's not telling the whole story.

Thinking perhaps there was an issue with the token I'm using, I then used HTTPie to send an authenticated request to both endpoints. 

The /api/v1/models endpoint responded with a list of available models (while the other informed me that there is no model named `v1` 🤦).

After quitting and reopening onit, returning to the settings and again attempting to add OpenRouter as a new provider, the same error occurred. See the following image:

<img width=""519"" alt=""onit add new provider error"" src=""https://github.com/user-attachments/assets/cb81314f-84f9-47a8-b59d-006955f2f3bd"" />

I noticed an open issue here: [OpenRouter scroll view slow to respond; stutters · Issue #123 · synth-inc/onit](https://github.com/synth-inc/onit/issues/123) that shows OpenRouter configured as a provider and displaying the models list populated, however that issue doesn't show the URL that was used. Otherwise, I'm unable to find anything else online regarding this issue."
3069449285,3085,Better checks for compatibility with Blueprint,anton-trunov,2316541,open,2025-05-16T16:34:31Z,,https://github.com/tact-lang/tact,https://github.com/tact-lang/tact/issues/3085,So issues like #3084 won't happen again.
3081417411,7116,Version Packages,joaquim-verges,3353417,closed,2025-05-21T21:08:59Z,2025-05-23T19:44:58Z,https://github.com/thirdweb-dev/js,https://github.com/thirdweb-dev/js/pull/7116,"This PR was opened by the [Changesets release](https://github.com/changesets/action) GitHub action. When you're ready to do a release, you can merge this and the packages will be published to npm automatically. If you're not ready to do a release yet, that's fine, whenever you add more changesets to main, this PR will be updated.


# Releases
## @thirdweb-dev/service-utils@0.9.10

### Patch Changes

-   [#7114](https://github.com/thirdweb-dev/js/pull/7114) [`4b9a506`](https://github.com/thirdweb-dev/js/commit/4b9a506fdfaf8d8be5767d3c719f0b77f86131e9) Thanks [@joaquim-verges](https://github.com/joaquim-verges)! - Better error messages for 403 responses

## thirdweb@5.100.2

### Patch Changes

-   [#7119](https://github.com/thirdweb-dev/js/pull/7119) [`dcd6b99`](https://github.com/thirdweb-dev/js/commit/dcd6b99e676206a06a6bf75031295c4bff3567b1) Thanks [@joaquim-verges](https://github.com/joaquim-verges)! - Better error messages in PayEmbed

-   [#7090](https://github.com/thirdweb-dev/js/pull/7090) [`1e0b142`](https://github.com/thirdweb-dev/js/commit/1e0b1422f32a81e1e2b300427b8431e2afeb5a63) Thanks [@joaquim-verges](https://github.com/joaquim-verges)! - Allow limiting the selectable countries for SMS login via a new `allowedSmsCountryCodes` option placed alongside `defaultSmsCountryCode`.

-   [#7123](https://github.com/thirdweb-dev/js/pull/7123) [`f31116e`](https://github.com/thirdweb-dev/js/commit/f31116ea5a799512af8ebf15102a3386a58314fd) Thanks [@jnsdls](https://github.com/jnsdls)! - fix avatar image detection on Node

-   [#7110](https://github.com/thirdweb-dev/js/pull/7110) [`7b72e88`](https://github.com/thirdweb-dev/js/commit/7b72e886111bac5f847ef39d30d980b7fab7929e) Thanks [@RobbyUitbeijerse](https://github.com/RobbyUitbeijerse)! - Fix loading spinner theme color in PayEmbed

-   [#7108](https://github.com/thirdweb-dev/js/pull/7108) [`dd2fb1b`](https://github.com/thirdweb-dev/js/commit/dd2fb1b13df5a524e2fb2e9ef4a93130e3119109) Thanks [@RobbyUitbeijerse](https://github.com/RobbyUitbeijerse)! - Add support for filtering fiat payment providers in PayEmbed

-   [#7121](https://github.com/thirdweb-dev/js/pull/7121) [`376bdb2`](https://github.com/thirdweb-dev/js/commit/376bdb23d22eeaccf4fa96f82e312c3a62cde518) Thanks [@gregfromstl](https://github.com/gregfromstl)! - Payment link support in PayEmbed

-   [#7145](https://github.com/thirdweb-dev/js/pull/7145) [`69fdef0`](https://github.com/thirdweb-dev/js/commit/69fdef07f57a4fd8738b76f2ff792210fedc23b7) Thanks [@joaquim-verges](https://github.com/joaquim-verges)! - Ensure bigints are stringified before usage with server wallets

## @thirdweb-dev/wagmi-adapter@0.2.82




<!-- start pr-codex -->

---

## PR-Codex overview
This PR focuses on updating package versions and changelogs across multiple packages in the `thirdweb` project. It includes improvements to error messages and new features for PayEmbed, as well as version increments for various packages.

### Detailed summary
- Updated `version` in `packages/thirdweb/package.json` from `5.100.1` to `5.100.2`
- Updated `version` in `packages/service-utils/package.json` from `0.9.9` to `0.9.10`
- Updated `version` in `packages/wagmi-adapter/package.json` from `0.2.81` to `0.2.82`
- Added changelog entries for:
  - `0.9.10` in `packages/service-utils/CHANGELOG.md`
  - `5.100.2` in `packages/thirdweb/CHANGELOG.md`
- Improvements in error messages for 403 responses and PayEmbed features:
  - Better error messages in PayEmbed
  - New `allowedSmsCountryCodes` option for SMS login
  - Fixes for avatar image detection and loading spinner theme color
  - Payment link support and filtering for fiat payment providers in PayEmbed
  - Ensure bigints are stringified before usage with server wallets

> ✨ Ask PR-Codex anything about this PR by commenting with `/codex {your question}`

<!-- end pr-codex -->

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->

## Summary by CodeRabbit

- **Chores**
  - Updated package versions for improved tracking and release management.
  - Added and updated changelog entries to document recent changes and fixes.
- **Documentation**
  - Updated changelogs to reflect recent improvements and fixes, including error message enhancements, SMS login configuration, avatar image detection, loading spinner theming, payment link support, payment provider filtering, and bigint handling in server wallets.

<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
3070210122,1123,📝 Add docstrings to `codex/find-and-fix-a-bug`,coderabbitai[bot],136622811,closed,2025-05-17T02:37:02Z,2025-05-17T02:52:55Z,https://github.com/unclecode/crawl4ai,https://github.com/unclecode/crawl4ai/pull/1123,"Docstrings generation was requested by @unclecode.

* https://github.com/unclecode/crawl4ai/pull/1122#issuecomment-2887985865

The following files were modified:

* `crawl4ai/utils.py`

<details>
<summary>ℹ️ Note</summary><blockquote>

CodeRabbit cannot perform edits on its own pull requests yet.

</blockquote></details>"
3131536357,2191,Remove Apple PowerPC / ancient OS X dead code,stockholmux,1152927,open,2025-06-09T21:30:17Z,,https://github.com/valkey-io/valkey,https://github.com/valkey-io/valkey/issues/2191,"While Valkey (nominally) supports PowerPC for IBM servers, I noticed that `debug.c` still has specific logic ([1](https://github.com/valkey-io/valkey/blob/1941d28acd53c08335f85700ae8f8d1cf5cdc40c/src/debug.c#L1211
),[2](https://github.com/valkey-io/valkey/blob/1941d28acd53c08335f85700ae8f8d1cf5cdc40c/src/debug.c#L1220)) for Apple PowerPC builds. The last PowerPC Apple was released 19 years ago and went out of OS support 14 years ago. 

I don't think Valkey has ever mentioned support for Apple PowerPC, so we can probably remove this code.

Additionally, there is logic for [OS X 10.5 detection](https://github.com/valkey-io/valkey/blob/1941d28acd53c08335f85700ae8f8d1cf5cdc40c/src/config.h#L45) which came out in 2007. OS X 10.6 came out in 2009. I think we're probably safe to drop logic for anything before that.

"
3104581367,4615,fix(weave): Collect the usage info from Langchain integration,chance-wnb,202173503,closed,2025-05-31T01:05:58Z,2025-06-05T16:13:38Z,https://github.com/wandb/weave,https://github.com/wandb/weave/pull/4615,"## Description

Fixes [WB-25246](https://wandb.atlassian.net/browse/WB-25246)

- Adds token usage tracking for LangChain LLM calls in Weave
- Adds support for OpenAI, Google VertexAI, Google Gemini, and Anthropic models
- Includes new dependencies for these integrations in pyproject.toml

This PR adds functionality to extract token usage information from LangChain LLM outputs and adds it to the call summary. The implementation collects prompt, completion, and total token counts per model from the response metadata, with specific extractors for different model providers.

## Testing

Added tests for each supported LLM provider:
- OpenAI (existing test updated to verify usage tracking)
- Google VertexAI
- Google Gemini
- Anthropic

Each test verifies that token usage information is correctly captured in the Weave trace.

[WB-25246]: https://wandb.atlassian.net/browse/WB-25246?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ"
710600494,47,Service Updates,wei,5880908,open,2020-09-28T21:45:34Z,,https://github.com/wei/socialify,https://github.com/wei/socialify/issues/47,"This pinned issue will contain breaking changes for the project including major design changes or domain changes. We will provide early notice should a domain change be necessary. 

Please subscribe to this issue if you'd like to receive updates. "
3156577167,613,📝 Add docstrings to `codex/upgrade-biome-to-version-2.0.0`,coderabbitai[bot],136622811,closed,2025-06-18T11:51:56Z,2025-06-18T11:55:01Z,https://github.com/wei/socialify,https://github.com/wei/socialify/pull/613,"Docstrings generation was requested by @wei.

* https://github.com/wei/socialify/pull/612#issuecomment-2983864352

The following files were modified:

* `src/components/configuration/repositoryInput.tsx`
* `src/components/preview/previewHelpers.ts`
* `src/components/repo/repo.tsx`

<details>
<summary>These files were ignored</summary>

* `.playwright/imageAPIEndpoints.spec.ts`
* `.playwright/languageSelection.spec.ts`
* `.playwright/mainUIConsistency.spec.ts`
* `.playwright/simpleUserStory.spec.ts`
* `src/components/configuration/config.test.tsx`
* `src/components/footer/footer.test.tsx`

</details>

<details>
<summary>These file types are not supported</summary>

* `biome.json`
* `package.json`

</details>

<details>
<summary>ℹ️ Note</summary><blockquote>

CodeRabbit cannot perform edits on its own pull requests yet.

</blockquote></details>"
3143364042,932,chore: API cleanup,mmikita95,157150795,closed,2025-06-13T12:05:54Z,2025-06-13T14:13:22Z,https://github.com/writer/writer-framework,https://github.com/writer/writer-framework/pull/932,"- Fixed keep-alive events during streaming
- Implemented frontend-friendly way to signal blueprint execution errors to API
- Removed API CLI flag
- Removed `JobVault` & `RedisJobVault`
- ""Job"" naming cleanup

<!-- This is an auto-generated comment: release notes by coderabbit.ai -->
## Summary by CodeRabbit

- **New Features**
  - Improved error reporting for blueprint execution failures with clearer error messages.

- **Bug Fixes**
  - Enhanced handling of blueprint execution errors to prevent duplicate notifications and logs.

- **Refactor**
  - Removed the Jobs API disabling option and related command-line flag.
  - Simplified event streaming and blueprint job execution logic.
  - Changed the blueprint job API endpoint path for consistency.
  - Removed persistent job vault support and related infrastructure.

- **Tests**
  - Updated tests to match new API endpoint paths and removed tests for the deprecated Jobs API disabling feature.
<!-- end of auto-generated comment: release notes by coderabbit.ai -->"
1036863132,84,執筆者ドキュメントにページの移動方法の説明を追加する,suin,855338,closed,2021-10-27T00:49:19Z,2025-05-18T08:57:49Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/84,"主な流れ

1. ファイルを移動、もしくは、ファイル名を変更する
2. sidebars.jsを直す
3. vercel.jsonに旧URL→新URLのリダイレクト設定を追加する
4. yarn buildでリンク切れがないかチェックする"
2628264718,927,「PHPなどの言語も変数に対して型を宣言できる」となっているが、PHPでは変数に型注釈できません。,webgoto,4490262,closed,2024-11-01T03:59:36Z,2025-05-18T08:57:29Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/927,"https://github.com/yytypescript/book/edit/master/docs/reference/values-types-variables/type-annotation.md

素晴らしい解説書を作っていただきありがとうございます。

このページ内に「JavaやPHPなどの言語も変数に対して型を宣言できますが」とありますが、PHPでは関数の引数や戻り値の型は指定できても、変数の型は指定できなかった気がします。

もし誤っておりましたら申し訳ありません。"
2921710101,967,誤植: 実装のこと指して → 実装のこと`を`指して,msnsk,61201644,closed,2025-03-15T04:20:18Z,2025-05-18T08:56:51Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/967,"https://github.com/yytypescript/book/edit/master/docs/overview/ecmascript.md

誤：この関係性から、ECMAScriptの実装のこと指してJavaScriptと呼ぶことがあります。
正：この関係性から、ECMAScriptの実装のことを指してJavaScriptと呼ぶことがあります。"
3022960023,975,falsyな値の例に`0.0`を追加する,otokunaga2,1020125,closed,2025-04-27T09:31:04Z,2025-05-23T11:19:14Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/975,"いつも参考にさせてもらってます。  
ありがとうございます。  

1点拝見しており、falsyの値の例として`0.0`を追加しても良いかと思いました。  
ご検討のほどどうぞ宜しくお願いします。  
```
| 値        | 型        | 意味         |
| --------- | --------- | ------------ |
| false     | boolean   | 疑値         |
| 0         | number    | 数値の0      |
| 0.0       | number    | 数値の0      |
| -0        | number    | 数値の-0     |
| NaN       | number    | Not a Number |
| 0n        | bigint    | 整数値の0    |
| """"        | string    | 空文字列     |
| null      | null      | null         |
| undefined | undefined | undefined    |
```
https://typescriptbook.jp/reference/values-types-variables/truthy-falsy-values

"
3071141695,985,誤植「本書ついて詳しく知る」→「本書について詳しく知る」,suin,855338,closed,2025-05-17T23:15:10Z,2025-05-17T23:18:52Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/985,「» [本書ついて詳しく知る]」となっています。「本書について詳しく知る」に修正する必要があります。
3071142185,986,誤植「Type Script」→「TypeScript」,suin,855338,closed,2025-05-17T23:16:15Z,2025-05-18T08:57:09Z,https://github.com/yytypescript/book,https://github.com/yytypescript/book/issues/986,
